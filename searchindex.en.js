var relearn_searchindex = [
  {
    "breadcrumb": "",
    "content": "A Theory about Dishonored and Prey 13 Jun 2025 - 2600 Words\nGiven a fair dice, how many rolls are needed, on average, to observe all the sides? From this simple question, this article explores basic probability theory and statistics in Scala 3, the upcoming major release of the Scala programming language. It shows the new features, their use and benefits.\nRead more ‚Üí Playing with Probability in Scala 3 11 Jul 2020 - 5700 Words\nGiven a fair dice, how many rolls are needed, on average, to observe all the sides? From this simple question, this article explores basic probability theory and statistics in Scala 3, the upcoming major release of the Scala programming language. It shows the new features, their use and benefits.\nRead more ‚Üí Les GADTs Par l'Exemple 27 Oct 2019 - 7900 Words\nD√©couvrez les ADT g√©n√©ralis√©s en vous amusant.\nRead more ‚Üí GADTs By Use Cases 26 Oct 2019 - 7400 Words\nDiscover Generalized ADT through lots of practical examples.\nRead more ‚Üí Proving Primality with GADTs 01 Oct 2019 - 1100 Words\nLet's do a bit of logic in Scala's type system.\nRead more ‚Üí Recursion Schemes: the high-school introduction 22 Mar 2019 - 3600 Words\nPresentation of recursion schemes from simple examples without the complex vocabulary in the way.\nRead more ‚Üí Demystifying GADTs 20 Feb 2019 - 3200 Words\nIntroduction to catamorphisms on Algebraic Data Types\nRead more ‚Üí Let's meet the charming fold family 30 Nov 2018 - 1800 Words\nIntroduction to catamorphisms on Algebraic Data Types\nRead more ‚Üí How to make game in the browser thanks to ScalaJS 18 Sep 2018 - 200 Words\nScalaIO.2018 Workshop\nRead more ‚Üí JSON to XML: the probably a tiny bit over engineered way 18 Sep 2018 - 2200 Words\nConversion from/to JSON and XML using advanced concepts\nRead more ‚Üí F-Algebra talk at ScalaIO 2017: Mod√©liser astucieusement vos donn√©es 18 Sep 2017 - 100 Words\nScalaIO.2017 Talk\nRead more ‚Üí",
    "description": "Articles about programming, gaming and maths.",
    "tags": [],
    "title": "Posts",
    "uri": "/posts/index.html"
  },
  {
    "breadcrumb": "Posts",
    "content": "Dishonored is the third game released by Arkane Studios after Arx Fatalis and Dark Messiah of Might and Magic. It is often described as a stealth game with combat options. You can complete it without ever engaging in any fight, or by slashing your way through. Its combat mechanics are praised for being fun and for letting players express their creativity in unseen ways. It gives you a lot of tools such as stopping time, possessing non playable characters (NPC), including animals, summoning rats, mines, grenades, guns, etc. Combining these tools in combat is a never ending source of delight.\nDishonored also implements a brilliant mechanics called the chaos system. The idea is simple: the more you resort to violence, the more violent the world becomes. There will be more dead bodies in the streets, more rats, more and stronger guards, etc. The interactions with other characters, and the end, will be darker and more violent.\nSome players voiced their frustration with this design. Dishonored allowed them to choose between stealth and combat, but they felt judged and punished by the chaos system for choosing the later. They found it contradictory that the game offered such a large and fun set of lethal options while punishing them for using it. At first, we can understand why they felt that way: by choosing combat, other characters reproached them, and they got what is generally considered the bad ending. It does sound like a punishment. But is it?\nWhat is a Role Playing Game? These days, we call any game with unlockable skills a Role Playing Game. Some even argue that any game in which we control a character is, technically, a role-playing game. By that logic, even the original Sonic would qualify as an RPG.\nDishonored puts us in the role of Corvo, the royal protector of Empress Jessamine Kaldwin. Unlike most games, Dishonored allows players to decide how to interpret Corvo. You can play him as a loyal protector, sparing the lives of innocents. But you can also play him as a rage-consumed assassin, killing any one who dares cross his path. Or you can also play him as a psychopath, testing his new powers on innocents. The choice is yours.\nWhile sandbox games are about giving players total freedom in a fake world without consequences, role-playing is about pretending it is real. A role player acts as if they were really there, as Corvo, in this very real world of Dunwall. What would you feel if you were actually there? How would you behave? How would you treat others? What would motivate you? Role-playing means letting go of the idea that you‚Äôre just playing a game, and responding to the world as if it was real.\nThe chaos system neither judges nor punishes; it honors your interpretation of Corvo, shaping the world around your choices. It is one of the ingredients that make the role-playing experience so intense. If you decided to play Corvo as wrath-driven avenger, it offers you the delight of watching the world be consumed by your rage. This is not a punishment, it‚Äôs a reward. If you decided to spare as many innocent lives at possible, don‚Äôt reload when you‚Äôre spotted but accept the consequences of this failure. If it forces you to kill someone, feel the guilt; it will make your next infiltration even more intense. The more you act as if it was real, the more powerful the role-playing experience is.\nUnfortunately, the role-playing side of Dishonored seems to have been mostly unnoticed. To be fair, what we call RPG currently is more about customizable builds, skill trees, experience points and unlockable perks than role-playing. How many games, even acclaimed RPGs, make the efforts of reflecting player choices in the world? Only a tiny bit. How would you design a game to teach players how to role-play?\nTeaching Role-Playing Dishonored was developed by the teams at Arkane Lyon and Akarne Austin, the American branch. The french team went to develop Dishonored 2, which is even better than the first one. If you have never played it, stop reading and install it üòâ It contains, among other things, what is very probably the best level ever made in a video game: the clockwork mansion. The whole game is excellent, but this level is just unbelievably good.\nIn the meantime, the Austin team was developing the best and most role-playing game ever made: Prey (2017). Prey‚Äôs introduction is probably the best in the whole gaming history. I know, I‚Äôm using a lot of superlatives, but they totally deserve it. If you have never played Prey, go play it! Let me give you an advice: don‚Äôt take it as an usual First-Person Shooter but immerse yourself in its world. Put yourself completely in Morgan‚Äôs shoes. Prey‚Äôs experience is all about how much you can role-play. So, the more you do, the better the experience is. And watch the credits, developers need love!\nI am going to spoil every bit of Prey, so don‚Äôt continue reading if you have not completed the game yet.\nPrey puts you in the role of Morgan You. You wake up in your appartement. The clock tells you its Monday, March 15th, 2032. Outside your patio doors: a bright, sunny San Francisco. You‚Äôre about to begin to work with your brother abroad the family-owned space station, Talos I. But first, you have to take some tests, just standard procedure. One of these tests asks you to answer the question: ‚ÄúYou‚Äôve been sentenced to death for your actions. How does this make you feel?‚Äù. The next one is the famous ethical dilemma known as the trolley problem: ‚ÄúA runaway train is bearing down on five people who are tied to the track. You can cause the train to switch tracks, but there is one person tied to the second track.‚Äù Switching means saving four lives, but also causing the death of one person who would have otherwise lived. If you chose to switch tracks, could you face that person‚Äôs family? If you didn‚Äôt, could you face the families of the five who died? There is no objectively-better choice. There are good arguments on both sides. You need to go with what you believe is the right outcome, based to your own values.\nThen comes an even more interesting question: what if the person to sacrifice was you? Would you kill yourself to save five others? It‚Äôs easy to answer ‚Äúyes‚Äù in a thought experiment, but remember that role-playing means acting as it it was real. Would you truly have the courage to do it if you were actually in that situation? And if you chose to switch tracks because saving more lives felt right, would you still feel that way if the life at stake was your own?\nDon‚Äôt worry, this is the last time the game will ask you to fill out a form. From here on, Prey will put you into many such situations, often without even announcing a decision point. You will probably never realize you could have acted differently. The most unbiased test is the one you‚Äôre not aware taking. Prey never forces you to do anything. It sets the stage, and let you act freely. It follows a simple but rarely applied rule: player freedom is when everything that should be possible, given the rules of the universe, truly is. Try it! You‚Äôll be surprised how permissive and cohesive it is. How could you role-play if your were not free to interpret the role as you want?\nThe next day, you realize all of this was a simulation. You‚Äôre not on earth in 2032, but aboard the Talos I space station in 2035. Many decades ago, aliens with extraordinary powers were discovered in space. The station was built to experiment on aliens, and non-voluntary humans, to find out how to transfer these abilities to humans. You actually volunteered many months ago to have your memory reset times and times again for these tests. Those aliens, called typhons, are extremely dangerous, completely lack empathy and just broke free. If they ever reach Earth, humankind is very likely to go extinct. Typhons don‚Äôt see humans as individuals but just as resources. When they arrive somewhere, they consume all the sentient life forms and move to the next place. The rest of the game is about finding a way to prevent typhons from reaching Earth. You are humanity‚Äôs last hope.\nThe bridge between players and game characters At the end, Prey let you choose how to neutralize the typhon threat, then launch a different ending based on your choices, and finally shows the credits. Congratulations, you‚Äôve just finished the game! You can now stop it and return to your real life. Keep these two sentences in mind for later.\nThere is one more detail though: it does not stop there. The credits are abruptly interrupted, just like when a game stops and returns to the operating system. Then what looks like a VR headset is removed from your head and you see Alex, with four operators. You are not Morgan Yu; you were a typhon all along. One who played the role of Morgan Yu in an immersive game simulating Talos I. By immersive I mean both you, the player, and the typhon thought it was real. You saw the experience as the real game, while it was actually a game within the game and the typhon experienced this game as if all of it was real.\nIt‚Äôs time to share my theory: the typhons are an allegory of us, players. More specifically, I think they symbolize players who didn‚Äôt understand yet that Dishonored was a role-playing game, that they could engage emotionally, that the experience was even greater when you empathize with characters, that its whole design was made to offer them the rare opportunity to live the experience as if it was real. Don‚Äôt get me wrong! Arkane don‚Äôt blame these players. I think Arkane developers loves role-playing and wanted to share their passion. Prey is like a role-playing tutorial to introduce you to this wonderful world. It‚Äôs not a critic, it‚Äôs an invitation.\nSome think it is the usual ‚Äúit was just a dream‚Äù trope, but it‚Äôs not. Prey is a video game essay about what role-playing really means. The game keeps asking the same questions again and again: can you empathize with simulated characters? Can you act as if it was real? Remember the trolley problem in the tutorial. The only reason that makes this choice so hard is lives are at stakes. If you don‚Äôt engage emotionally, if you don‚Äôt consider this thought experiment as real, then nothing matters. Likewise, the choices you made in the game only matter if you engaged emotionally, if you acted as it it was real, if you role-played.\nThink for a moment about the experience the typhon had. It played a game thinking it was real. While playing it pretended to be Morgan Yu. At the end it saw the ending and the credits. After that the game stopped and returned to the operating system of its gaming platform. It removed its gaming device and returned to its real life. How is it different from what we experienced? We did launch the game. We did pretend to be Morgan Yu. We did see the endings and the credits. After that we did stop the game, returning to the main interface of our gaming platform. We put out gaming device down and returned to our real life. The only difference is: the typhon thought it was real while you knew it was a game. But role-playing mean acting as it was real, so if you did role-play, then you had the exact same experience as the typhon.\nIn the last scene, Alex says: ‚ÄúIt probably thinks it was dreaming. That nothing mattered.‚Äù Indeed, some argue that the fact it was simulation all along means nothing mattered because nothing was real. But aren‚Äôt all games like that? Game worlds aren‚Äôt real! The choices you make in your games don‚Äôt alter the real world, don‚Äôt they? Does it mean none of your gaming experience matter? Why are you playing games if nothing matters? It matters to you! Firstly, when you are playing, it feels very real. And secondly, the experiences you lived in games left a mark on you.\nAlex continues by: ‚ÄúYou‚Äôre the bridge between our species. I need to know if you see us. I mean really see us.‚Äù I think it has a deeper meaning. The whole game is an experiment conducted by Alex to make typhons empathize with the humans of this world. If the typhons symbolize players, then the two species are players and game characters. I think Alex asking the typhon if it ‚Äúreally sees‚Äù humans is Prey‚Äôs developers asking us if we ‚Äúreally see‚Äù characters. The bridge between players and game character is the role-player, because when you do, you see two worlds as real: our own and the game‚Äôs world. When you role-play, you ‚Äúreally see‚Äù characters as real humans in this imaginary universe.\nAs a side node, I‚Äôve heard some say Prey is very good representation of eldritch horror. Sure it is! Imagine for a second that a game‚Äôs world is real. How we, gamers, would be seen by its inhabitants? Aren‚Äôt we very close to Lovecraftian deities for them?\nConclusion Games aren‚Äôt just games. They are also pieces of art, imaginary worlds, stories, opportunities to live amazing experiences, etc. Engaging emotionally with a game can be very rewarding. We are so used to game-design formulas that we forget why they were created in the first place. Role-playing is not only about classes, skill points and dices; it‚Äôs about how you decide to interpret the role and act as if it was real.\nIn an interview Warren Spector was asked ‚ÄúWhat would you say makes an immersive sim distinct from so many other RPGs?‚Äù. He replied ‚ÄúI think it‚Äôs a variety of things. One is it doesn‚Äôt count on character stats to define the character. It‚Äôs not about roll playing, it‚Äôs about the role-playing. It‚Äôs about how you interact with the world which is different from most RPGs. It has nothing to do with arbitrary character classes. It‚Äôs about how you behave and interact with the world.‚Äù\nDishonored and Prey clearly do not look like usual Role-Playing Games. There is no classes, no skill points, to dice rolls, no armor to equip, no elves, etc. But if you make the effort to emotionally engage with their worlds, acting as if they were real, they will very likely offer you the best role-playing experiences of your whole game life.\nOne of my favorite gaming moment was playing Prey. I had been asked to do something, but it felt off. There was no dialog option, no explicit choices stated in the the quest, nothing that would have told me there were choices to make. But Prey is a simulation, which means it lets me do everything that would be possible if it was real, and makes its best to reflect my actions on the world. Unlike many games that would have forced me to follow a scripted path, it let me disobey. That‚Äôs the beauty of simulations: at every instant, you‚Äôre free to do whatever you want. Every second is an opportunity to make a choice. This feeling of freedom is so delightful.\nI would like to conclude by warmly thanking everyone who poured so much passion into crafting these wonderful experiences.",
    "description": "Given a fair dice, how many rolls are needed, on average, to observe all the sides? From this simple question, this article explores basic probability theory and statistics in Scala 3, the upcoming major release of the Scala programming language. It shows the new features, their use and benefits.",
    "tags": [],
    "title": "A Theory about Dishonored and Prey",
    "uri": "/posts/prey_typhons_theory/index.html"
  },
  {
    "breadcrumb": "Posts",
    "content": "Here is a simple experiment: take a fair dice (or a coin) and roll it until every side of the dice has been observed at least once. Write down the number of rolls and repeat the operation several times. On average, how many rolls does it take to observe every side of the dice at least once? This is precisely the question we are about to answer together.\nSolving Maths puzzle is fun. Solving them using the shiniest features of Scala 3 is even amazingly funnier! If you do not have Scala 3 installed yet:\non Arch Linux, as usual there is an AUR package : aur/scala-dotty. Install it via yay -S aur/scala-dotty or any other AUR helper. on other Linux distributions, download https://github.com/lampepfl/dotty/releases/download/0.25.0-RC2/dotty-0.25.0-RC2.tar.gz , extract it and make sure the executables are in your $PATH. on other systems, follow the instructions here. You should now be able to run the Scala 3 REPL via the command:\n[shell prompt]$ dotr -new-syntax -Yexplicit-nulls -Yerased-terms -indent -version Starting dotty REPL... Dotty compiler version 0.25.0-RC2 -- Copyright 2002-2020, LAMP/EPFL scala\u003e An Important Note: Please refrain from starting your favourite IDE or starting a new project. It will only make experimenting harder and painful. All you need is the Scala 3 REPL, any basic text editor and knowing how to copy-paste on your system.\nUnderstanding the Problem Let us start by modelling a dice. The sides of a dice will be numbered starting from 1. We consider a coin as a 2-sided dice whose sides are 1 and 2. The sides of an usual 6-sided dice are 1, 2, 3, 4, 5 and 6.\nfinal case class Dice(sides: Int) { def roll(): Int = scala.util.Random.nextInt(sides) + 1 } val d2 = Dice(2) val d6 = Dice(6) val d10 = Dice(10) val d20 = Dice(20) val d100 = Dice(100) d2 models a coin, d6 models a usual 6-sided dice, etc. The method roll , as its name suggest, simulates rolling the dice. On each invocation it gives a random side (its number). The first question to answer is: is such a dice fair ? Remember that a fair dice is one for which every side is equally likely to be observed. For a coin, it means getting 1 is as likely as getting 2. To check empirically that a dice is fair, or at least not loaded, we will roll it many times and count how often we observe its sides:\ndef (dice: Dice) frequencies(rolls: Long): Map[Int, Double] = // Stores how many times we observed each side val arr = Array.fill(dice.sides)(0) for i \u003c- 1L to rolls do arr(dice.roll() - 1) += 1 // Transforms counters into ratio val probability: IndexedSeq[(Int, Double)] = for i \u003c- 1 to dice.sides yield i -\u003e arr(i-1).toDouble / rolls probability.toMap scala\u003e d2.frequencies(1000000000L) val res0: Map[Int, Double] = Map(1 -\u003e 0.499985517, 2 -\u003e 0.500014483) scala\u003e d6.frequencies(1000000000L) val res1: Map[Int, Double] = HashMap( 1 -\u003e 0.166669596, 2 -\u003e 0.166660131, 3 -\u003e 0.166664591, 4 -\u003e 0.166654524 5 -\u003e 0.166665811, 6 -\u003e 0.166685347) This extension method can be called like any method of Dice. As you can see, the frequencies are very close to each other. In addition, the more rolls we perform, the closer they are. We can conclude that these dice are fair enough. We are finally ready for our big adventure: finding the so desired average! We call an experiment the action of rolling the dice until every side has been observed at least once and the length of the experiment its number of rolls. The method rollUntilAllSeen simulates an experiment and return its length.\ndef (dice: Dice) rollUntilAllSeen(): Int = var rolls = 0 val seen = Array.fill(dice.sides)(false) var remaining = dice.sides while remaining \u003e 0 do val outcome = dice.roll() rolls += 1 if !seen(outcome-1) then seen(outcome-1) = true remaining -= 1 rolls scala\u003e d6.rollUntilAllSeen() val res2: Int = 12 scala\u003e d6.rollUntilAllSeen() val res3: Int = 15 scala\u003e d6.rollUntilAllSeen() val res4: Int = 8 scala\u003e d6.rollUntilAllSeen() val res5: Int = 9 Based on the four experiments above, we get the impression that the average should be close to 11, but four experiments are not a lot to get an accurate estimation of the real average. Fortunately, the more experiments we run, the closer we get to it. We need to compute the average over a large number of experiments. We will actually be a bit smarter. Instead of limiting ourselves to computing the average, we will count, for every observed length, the number of its experiments. It will give us how often a length is observed, i.e. its frequency.\nfinal case class Histogram[A](values: Map[A, BigInt]) { def average(using Accumulable[A], Ratio[A]): A = var acc : A = summon[Accumulable[A]].zero var total : BigInt = BigInt(0) for (a,count) \u003c- values do acc += a*count total += count acc / total def frequencies(using Ratio[A]): Map[A, BigDecimal] = val total = values.values.sum values.map { case (a, count) =\u003e a -\u003e BigDecimal(count) / BigDecimal(total) } def map[B](f: A =\u003e B): Histogram[B] = var histoB = scala.collection.mutable.Map.empty[B, BigInt] for (a, count) \u003c- values do val b = f(a) histoB.update(b, histoB.getOrElse(b, BigInt(0)) + count) new Histogram[B](histoB.toMap) } object Histogram { def apply[A](iterations: Long)(value : =\u003e A): Histogram[A] = var histo = scala.collection.mutable.Map.empty[A, BigInt] for i \u003c- 1L to iterations do val a = value histo.update(a, histo.getOrElse(a, BigInt(0)) + 1) new Histogram(histo.toMap) } The class Histogram[A] is essentially a key-value store where the value is the number of times the key has been observed, also known as its multiplicity. You may also wonder how Scala can accept adding two values of type A and multiplying/dividing a value of type A by a BigInt in average. It works thanks to the magic of Type Classes in Scala 3. Accumulable and Ratio are two type classes defined by:\ntrait Accumulable[A] { def zero: A def (x:A)+(y:A): A def (x:A)*(m: BigInt): A } trait Ratio[A] { def (x:A) / (m: BigInt): A } Note that, unlike Scala 2, no weird implicit conversion is required to support infix syntax for +, * and /. These methods are just defined as extension methods.\nscala\u003e val h6 = Histogram(100000000L)(d6.rollUntilAllSeen()) val h6: Histogram[Int] = Histogram(HashMap(73 -\u003e 202, 69 -\u003e 385, 88 -\u003e 17, 10 -\u003e 8298014, 56 -\u003e 4403, 42 -\u003e 56557, 24 -\u003e 1462064, 37 -\u003e 140975, ...)) scala\u003e h6.average 1 |h6.average | ^ |no implicit argument of type Accumulable[Int] was found for parameter x$1 of method average in class Histogram If your first reaction is to implement an instance of Accumulable for Int, ask yourself how you could be confident that the computed values are correct when adding two positive numbers can result into a negative one:\nscala\u003e val x = 1990000000 val x: Int = 1990000000 scala\u003e x + x val res0: Int = -314967296 I am well aware that most use cases using Int is perfectly fine, because they never have numbers big enough to reach this limit. After all, 10 digits ought to be enough for anybody, right? In the next sections, you will see that we will reach this limit very often! Writing an instance of Accumulable for Int is a catastrophic idea. Instead we will write instances for BigInt and BigDecimal.\ngiven Accumulable[BigInt] { def zero: BigInt = BigInt(0) def (x:BigInt)+(y:BigInt): BigInt = x+y def (x:BigInt)*(m:BigInt): BigInt = x*m } given Accumulable[BigDecimal] with Ratio[BigDecimal] { def zero: BigDecimal = BigDecimal(0) def (x:BigDecimal)+(y:BigDecimal): BigDecimal = x+y def (x:BigDecimal)*(m:BigInt): BigDecimal = x*BigDecimal(m) def (x:BigDecimal)/(m:BigInt): BigDecimal = x/BigDecimal(m) } Now we can get out much awaited average:\nscala\u003e h6.map(BigDecimal(_)).average val res0: BigDecimal = 14.69830127 scala\u003e Histogram(10000000L)(BigDecimal(d6.rollUntilAllSeen())).average val res1: BigDecimal = 14.6949955 As you can see, the average is never far from 14.69. Knowing the average is nice but it does not tell us much about how the length is distributed among the experiments. This is precisely the reason why we kept counters! To visualize this data, we can export the histogram as a CSV file.\ndef (histogram: Histogram[Int])toCSV(fileName: String): Unit = import java.io._ val pw = new PrintWriter(new File(fileName)) pw.println(\"value,count\") for length \u003c- 0 to histogram.values.keySet.max do pw.println(s\"$length,${histogram.values.getOrElse(length, BigInt(0))}\") pw.close() scala\u003e h6.toCSV(\"d6.csv\") Opening the file d6.csv with LibreOffice and plotting the data as a XY Chart using the value column as X and count as Y gives this chart:\nAs you can see, after length 15, there is a huge decrease in the number of experiments. And after length 50, the number of experiment is almost neglectable. The situation is similar for other dice. For example, here is the curve for d100:\nBy running enough experiment, we can get an pretty close estimation of the average. But an experiment is by nature random, every measure we perform is very likely to give a (close but still) different estimation of the average. We need a more reliable way to approximate the average.\nModelling the Problem To get a more reliable approximation of the average, or the exact value, we can not rely on random experiments. We need to use maths! Remember that an experiment is a sequence of dice rolls such that, as soon as every side of the dice have been observed at least once, the sequence is over. Given a dice, we will call a sequence of sides valid when it follows these rules.\nUsing a 3-sided dice:\nThe sequence 2‚Üí2‚Üí1‚Üí2 is invalid because the side 3 has not been observed. The sequence 2‚Üí2‚Üí1‚Üí2‚Üí3‚Üí3 is invalid because the sequence needs to stop as soon as every side has been observed so the last roll is not required. The sequence 2‚Üí2‚Üí1‚Üí2‚Üí3 is valid: every side has been observed and it was not possible to stop earlier. Note that the validity depends on the dice used! The sequence 2‚Üí2‚Üí1‚Üí2‚Üí3 is valid for a 3-sided dice but invalid for a 4-sided dice. To compute the average, we will: (1) enumerate all valid sequences (up to a certain length), then (2) sum their length and finally (3) divide by the number of values in the sum.\ndef enumerate(sides: Int, depth: Int): LazyList[List[Int]] = def aux(revSeq: List[Int]): LazyList[List[Int]] = if revSeq.length \u003e depth then LazyList.empty else if revSeq.toSet.size == sides then LazyList(revSeq.reverse) else LazyList.range(1, sides+1).flatMap { next =\u003e aux(next :: revSeq) } aux(List.empty) def average(sides: Int, depth: Int): Double = val validSequences = enumerate(sides, depth) validSequences.map(_.length.toDouble).sum / validSequences.size For a 3-sided dice, the list of all valid sequences up to length 5 is:\nscala\u003e enumerate(3,5).map(_.mkString(\"‚Üí\")).toList val res26: List[String] = List( 1‚Üí1‚Üí1‚Üí2‚Üí3, 1‚Üí1‚Üí1‚Üí3‚Üí2, 1‚Üí1‚Üí2‚Üí1‚Üí3, 1‚Üí1‚Üí2‚Üí2‚Üí3, 1‚Üí1‚Üí2‚Üí3, 1‚Üí1‚Üí3‚Üí1‚Üí2, 1‚Üí1‚Üí3‚Üí2, 1‚Üí1‚Üí3‚Üí3‚Üí2, 1‚Üí2‚Üí1‚Üí1‚Üí3, 1‚Üí2‚Üí1‚Üí2‚Üí3, 1‚Üí2‚Üí1‚Üí3, 1‚Üí2‚Üí2‚Üí1‚Üí3, 1‚Üí2‚Üí2‚Üí2‚Üí3, 1‚Üí2‚Üí2‚Üí3, 1‚Üí2‚Üí3, 1‚Üí3‚Üí1‚Üí1‚Üí2, 1‚Üí3‚Üí1‚Üí2, 1‚Üí3‚Üí1‚Üí3‚Üí2, 1‚Üí3‚Üí2, 1‚Üí3‚Üí3‚Üí1‚Üí2, 1‚Üí3‚Üí3‚Üí2, 1‚Üí3‚Üí3‚Üí3‚Üí2, 2‚Üí1‚Üí1‚Üí1‚Üí3, 2‚Üí1‚Üí1‚Üí2‚Üí3, 2‚Üí1‚Üí1‚Üí3, 2‚Üí1‚Üí2‚Üí1‚Üí3, 2‚Üí1‚Üí2‚Üí2‚Üí3, 2‚Üí1‚Üí2‚Üí3, 2‚Üí1‚Üí3, 2‚Üí2‚Üí1‚Üí1‚Üí3, 2‚Üí2‚Üí1‚Üí2‚Üí3, 2‚Üí2‚Üí1‚Üí3, 2‚Üí2‚Üí2‚Üí1‚Üí3, 2‚Üí2‚Üí2‚Üí3‚Üí1, 2‚Üí2‚Üí3‚Üí1, 2‚Üí2‚Üí3‚Üí2‚Üí1, 2‚Üí2‚Üí3‚Üí3‚Üí1, 2‚Üí3‚Üí1, 2‚Üí3‚Üí2‚Üí1, 2‚Üí3‚Üí2‚Üí2‚Üí1, 2‚Üí3‚Üí2‚Üí3‚Üí1, 2‚Üí3‚Üí3‚Üí1, 2‚Üí3‚Üí3‚Üí2‚Üí1, 2‚Üí3‚Üí3‚Üí3‚Üí1, 3‚Üí1‚Üí1‚Üí1‚Üí2, 3‚Üí1‚Üí1‚Üí2, 3‚Üí1‚Üí1‚Üí3‚Üí2, 3‚Üí1‚Üí2, 3‚Üí1‚Üí3‚Üí1‚Üí2, 3‚Üí1‚Üí3‚Üí2, 3‚Üí1‚Üí3‚Üí3‚Üí2, 3‚Üí2‚Üí1, 3‚Üí2‚Üí2‚Üí1, 3‚Üí2‚Üí2‚Üí2‚Üí1, 3‚Üí2‚Üí2‚Üí3‚Üí1, 3‚Üí2‚Üí3‚Üí1, 3‚Üí2‚Üí3‚Üí2‚Üí1, 3‚Üí2‚Üí3‚Üí3‚Üí1, 3‚Üí3‚Üí1‚Üí1‚Üí2, 3‚Üí3‚Üí1‚Üí2, 3‚Üí3‚Üí1‚Üí3‚Üí2, 3‚Üí3‚Üí2‚Üí1, 3‚Üí3‚Üí2‚Üí2‚Üí1, 3‚Üí3‚Üí2‚Üí3‚Üí1, 3‚Üí3‚Üí3‚Üí1‚Üí2, 3‚Üí3‚Üí3‚Üí2‚Üí1 ) That‚Äôs awesome! We just have to average all the lengths:\nscala\u003e average(3,5) val res27: Double = 4.545454545454546 scala\u003e average(3,10) val res32: Double = 9.071713147410359 scala\u003e average(3,14) val res36: Double = 13.00953778429934 scala\u003e average(3,16) val res39: Double = 15.003205911089399 Apparently, computing the average for sequences up to length 16 does not converge yet. Unfortunately our implementation is to slow for large sequences. The number of valid sequences grows exponentially over length. We need a much faster algorithm.\ndef aggregate[A:Accumulable](sides: Int, depth: Int)(f: Int =\u003e A): A = var current : Array[BigInt] = Array.fill(sides+1)(BigInt(0)) var next : Array[BigInt] = Array.fill(sides+1)(BigInt(0)) var agg : A = summon[Accumulable[A]].zero var length : Int = 0 current(0) = BigInt(1) // The empty sequence is the unique sequence where 0 sides have been seen while length \u003c= depth do agg += f(length) * current(sides) for seen \u003c- 0 to sides - 1 do next(seen) += current(seen) * seen next(seen + 1) += current(seen) * (sides - seen) length += 1 current = next next = Array.fill(sides+1)(BigInt(0)) agg This is a generic aggregation function that, given a sides-sided dice, gives to every valid sequence a value that depends only on its length (via f) and aggregate them over all valid sequences up to a certain length called the depth. We can use it to compute the average for sequences up to length 100000).\nscala\u003e val depth = 100000 val depth: Int = 100000 scala\u003e val sides = 3 val sides: Int = 3 scala\u003e val sumOfLengths = aggregate(sides,depth)(length =\u003e BigInt(length)) val sumOfLengths: BigInt = A 30109 digits positive integer scala\u003e val numberOfSeqs = aggregate(sides,depth)(length =\u003e BigInt(1)) val numberOfSeqs: BigInt = A 30104 digits positive integer scala\u003e val avegrageUpTo100000 = (BigDecimal(sumOfLengths)/numberOfSeqs).toDouble val avegrageUpTo100000: Double = 99999.0 The average does not seem to converge. Have a look at previous estimations of the averages for depths 5, 10, 14 and 16. The average seem very close to depth - 1. It seem to indicate that, on average, you need to roll a 3-sided dice an infinity of times to obverse every side at least once. It means that, regardless the number of rolls you perform, it is almost certain that you will never see at least once side. Let‚Äôs confirm that using the methods of the previous section:\nscala\u003e val d3 = Dice(3) val d3: Dice = Dice(3) scala\u003e val h3 = Histogram(100000000L)(d3.rollUntilAllSeen()) val h3: Histogram[Int] = Histogram(HashMap(...)) scala\u003e h3.map(BigDecimal(_)).average val res6: BigDecimal = 5.5003517 The experience shows that, on average, 5.5 rolls are enough to see every side of a 3-sided dice. The only possible conclusion is that our modeling is very wrong. The problem is we consider every sequence to be equally likely. But the sequence 1‚Üí2‚Üí3 is much likelier to happen than 1‚Üí2‚Üí2‚Üí1‚Üí2‚Üí1‚Üí2‚Üí1‚Üí1‚Üí2‚Üí1‚Üí3. We can plot the h3 histogram to check that the longer a sequence is, the less likely it is to happen:\nOur real big mistake is our mathematical modeling does not model the real problem. This is a very important rule in modeling: models much match closely the things they are supposed to model.\nUnderstanding the Experiment To get a mathematical model that closely match the experience, we need to have a deeper understanding of the problem. When we perform 10000000 experiments, we get as many valid sequences of sides. But taking the hypothesis that theses sequences are all distinct is wrong. An experiment is a random process, you may get the same sequence several times. We need to take into account how often a sequence is likely to happen.\nGiven a \\(n\\)-sided fair dice, by definition of fairness, every time we roll the dice, for any side, there is exactly \\(\\frac{1}{n}\\) chance to observe this side. Each roll being independent from other ones, for every sequence of \\(m\\) rolls, there is \\((\\frac{1}{n})^m\\) chance to observe this sequence.\nDo not jump on the conclusion that the probability of a valid sequence of length \\(m\\) in our problem is \\((\\frac{1}{n})^m\\) yet! If we change the problem slightly by requiring that every side is observed exactly once (ignoring sequences where one side is observed several times). Then for a coin there is only 2 valid sequences 1‚Üí2 and 2‚Üí1, each equally likely so they both have probability \\(\\frac{1}{2}\\), not \\(\\frac{1}{4}\\). The good way to proceed is finding a probability space that models correctly the problem.\nRemember that the dice used has been fixed as a \\(n\\)-sided fair dice. The first step in defining a probability space is defining the outcomes. Outcomes are the results of statistical experiments. It our problem, outcomes are the valid sequences of dice rolls. Then we need to define the set of events. Events are the things whose likelihood we want to measure! For example: what is the probability that a valid sequence starts with 1, or what is the probability that a valid sequence is a palindrome (i.e. the reverse of the sequence is the sequence itself),etc. It feels natural, in our situation, to consider as event, any set of valid sequences. Last but not least, we need the probability function. Its purpose is to give, for any event, the likelihood of this event. Informally, a probability function must satisfy 3 properties:\nthe likelihood of any event must be positive or null but never negative! the likelihood of distinct events is the sum of the likelihood of every event. the likelihood of the set of all valid sequences must be 1. This is where things get complicated. We can decide to give to any valid sequence of size \\(m\\) the the probability (\\((\\frac{1}{n})^m\\)), but we need to prove that this function satisfies all the conditions above to be a probability function. In addition, the set of valid sequences is not that trivial to work with (at least for me!). Fortunately working in this probability space is not mandatory. We can work in more comfortable probability space as long as we are able to transpose results into this one.\nRemember that the dice being used is a \\(n\\)-sided fair dice. Let us start by some definitions:\nLet \\(\\mathcal{C}_n=\\{1,\\dots,n\\}\\) be the set of the dice‚Äôs sides.\nThe set of countably infinite sequences of sides is written \\(\\Omega\\).\nThe set of finite sequences of sides is written \\(\\mathcal{F}\\).\nFor any finite sequence of sides \\(f \\in \\mathcal{F}\\), its length is written \\(|f|\\).\nFor any sequence \\(s \\in \\mathcal{F} \\cup \\Omega\\) of sides (finite or infinite), let \\(\\diamond s\\) be the set of sides observed in \\(s\\) and \\(\\sharp s\\) be the number of distinct sides observed in \\(s\\), i.e. \\(\\sharp s = |\\diamond s|\\).\nFor any sequence \\(s \\in \\mathcal{F} \\cup \\Omega\\) of sides (finite or infinite), and any \\(i \\in \\{1,\\dots,|s]\\}\\), let \\(s_{[i]}\\) be the sides observed at the \\(i\\)-th roll of \\(s\\), i.e. \\(s=(s_{[1]},\\dots,s_{[|s|]})\\).\nFor any \\(f \\in \\mathcal{F}\\) and \\(f' \\in \\mathcal{F}\\cup\\Omega\\), where \\(f = (s_1,\\dots,s_i)\\) and \\(f' = (s'_1,\\dots)\\), we write \\(f \\cdot f' \\in \\mathcal{F}\\cup\\Omega\\) the concatenation of \\(f\\) and \\(f'\\), i.e. the sequence \\((s_1,\\dots,s_i,s'_1,\\dots)\\). Furthermore, for any set of prefix \\(F \\subset \\mathcal{F}\\), and any set set of (finite or infinite) sequences \\(S\\subset \\mathcal{F}\\cup\\Omega\\), we write \\(F\\cdot S = \\{f\\cdot s\\mid f\\in F,\\ s\\in S\\}\\) the set of sequences made of concatenations of \\(F\\) and \\(S\\).\nFor the new probability space, we can take as outcomes \\(\\Omega\\), the set of all infinite (but countable) sequence of sides. Given a finite sequence of sides \\(f \\in \\mathcal{F}\\) (possibly empty), the set of all outcomes (infinite sequences) that start with \\(f\\) is called a prefix event and written \\(\\mathcal{E}(f)\\). The finite sequence \\(f \\in \\mathcal{F}\\) is called a prefix. Note that the set of all outcomes, \\(\\Omega\\), is an event because it is the prefix event of the empty sequence \\(\\epsilon\\). The set of all prefix events is written \\(\\mathcal{E}\\). We will take as events the the œÉ-field \\(\\sigma(\\mathcal{E})\\) generated from prefix events, i.e. the smallest œÉ-field containing prefix events that is closed under complement, countable unions and intersections. It means that any countable union or intersection of events is an event and the complement of any event is an event. Let \\(F\\subset \\mathcal{F}\\) be a finite or countable set of prefixes, we write \\(\\mathcal{E}(F)\\) the event \\(\\bigcup_{f\\in F} \\mathcal{E}(f)\\).\nThe class of sets \\(\\mathcal{R} = \\mathcal{E} \\cup \\{\\emptyset\\} \\) is a semiring of sets. It comes from two facts. Let \\(f_1, f_2\\in \\mathcal{F}\\) be two prefixes. Either \\(\\mathcal{E}(f_1)\\) and \\(\\mathcal{E}(f_2)\\) are disjoint, or one is contained in the other. It proves that \\(\\mathcal{R}\\) is table by finite intersection. If \\(\\mathcal{E}(f_2) \\subset \\mathcal{E}(f_1)\\) then there exists \\(f_3\\in \\mathcal{F}\\) such that \\(f_2 = f_1 \\cdot f_3\\) and \\(\\mathcal{E}(f) = \\bigcup_{f_4\\in \\mathcal{F}, |f_4|=|f_3|} \\mathcal{E}(f \\cdot f_4)\\). It proves that \\(\\mathcal{E}(f_1) \\setminus \\mathcal{E}(f_2)\\) can be written as a finite union of disjoint element of \\(\\mathcal{R}\\).\nInstead of defining the probability function \\(p\\) directly over \\(\\sigma(\\mathcal{E})\\), \\(p\\) is defined over \\(\\mathcal{R}\\) first and then extended to \\(\\sigma(\\mathcal{E})\\) using Carath√©odory‚Äôs extension theorem. \\(p\\) is defined on \\(\\mathcal{R}\\) by\n$$\\begin{aligned} p(\\emptyset) \u0026 = 0 \\\\ \\forall f \\in \\mathcal{F}\\quad p(\\mathcal{E}(f)) \u0026 = (\\frac{1}{n})^{|f|} \\end{aligned}$$\\(p\\) is additive and œÉ-subadditive because the only way for the union of two disjoint elements of \\(\\mathcal{R}\\) to be in \\(\\mathcal{R}\\) is if one of the two is the empty set. It is also œÉ-finite because \\(p(\\Omega) = p(\\mathcal{E}(\\epsilon)) = (\\frac{1}{n})^{0} = 1\\). The function \\(p\\) can then be uniquely extended into a probability function over \\(\\sigma(\\mathcal{E})\\).\nNote that:\n$$\\begin{aligned} \\forall f_1,f_2\\in \\mathcal{F},\\quad p(\\mathcal{E}(f_1\\cdot f_2)) \u0026 = p(\\mathcal{E}(f_1)) \\times p(\\mathcal{E}(f_2)) \\\\ \\forall f\\in \\mathcal{F},\\quad p(\\mathcal{E}(f)) \u0026 = \\prod_{i=1}^{|f|}p(\\mathcal{E}(f_{[i]})) \\end{aligned}$$The probability space \\((\\Omega,\\sigma(\\mathcal{E}),p)\\) has the very pleasing property that the probability of a prefix event \\(\\mathcal{E}(f)\\) is exactly the probability of getting the sequence \\(f\\) with \\(|f|\\) dice rolls. There is a problem though: there are outcomes for which not every side has been observed at least once. The infinite sequence \\((1,\\dots)\\) is such an outcome.\nLet \\(M\\) the subset of outcomes such that at least one side has not been observed, i.e. \\( M = \\{ \\omega \\in \\Omega \\mid \\sharp \\omega \u003c n \\} \\). We want to know how likely \\(M\\) is. For any \\(i \\in \\mathbb{N} \\), let \\(M_i\\) the set of outcomes such at least one side has not been observed up to the \\(i\\)-th roll, i.e. \\(M_i = \\mathcal{E}(\\{f \\in \\mathcal{F}\\mid |f|=i,\\ \\sharp f \u003c n\\})\\).\nFor any \\(i\\in \\mathbb{N}\\), \\(M_i\\) is an event because it is a finite union of events. Not observing at least one side with an infinity of rolls is equivalent to not observing this side for every \\(i\\)-th roll, so \\(M = \\bigcap_{i\\in\\mathbb{N}} M_i\\). From the last equation, we can conclude that \\(M\\) is an event because it is a countable intersection of events. Furthermore, given \\(i\\) dice rolls, the probability of not observing a given side is \\((\\frac{n-1}{n})^i\\) so \\(p(M_i) \\le n \\times (\\frac{n-1}{n})^i\\). Note that \\(M_{i+1} \\subset M_i\\), so \\(\\bigcap_{j=0}^i M_j = M_i\\). We can conclude that the probability, given an infinity of dice rolls, of never observing one side (anyone) is \\(0\\):\n$$ p(M) = p(\\bigcap_{i\\in\\mathbb{N}} M_i) = \\lim_{i\\rightarrow\\infty} p(M_i) \\le \\lim_{i\\rightarrow\\infty} n \\times \\Bigl(\\frac{n-1}{n}\\Bigr)^i = 0 $$Note that it does not mean these outcome are impossible. In theory, if you flip a coin endlessly, it is possible to always get head (resp. tail), but this is incredibly unlikely. Let \\(\\Omega' = \\overline{M}\\) be set of outcomes such that every side has been observed at least once. \\(\\Omega'\\) is the complement of \\(M\\), written \\(\\overline{M}\\). Its probability is then \\(p(\\Omega') = 1\\). So for any event \\(E\\in\\sigma(\\mathcal{E})\\), \\(p(E) = p(E\\cap\\Omega') + p(E\\cap M)\\), but \\(p(E\\cap M) \\le p(M) = 0\\), so\n$$\\forall E\\in\\sigma(\\mathcal{E})\\quad p(E) = p(E\\cap\\Omega')$$Informally, it means we can assume that, in every outcome, every side of the dice are observed at least once. More precisely, we take as probability space, the restriction of \\((\\Omega,\\sigma(\\mathcal{E}),p)\\) to \\(\\Omega'\\), written \\((\\Omega',\\sigma(\\mathcal{E})|_{\\Omega'},p)\\).\nHow does the problem translates into this probability space? Remember that an outcome \\(\\omega \\in \\Omega'\\) is an infinite sequence \\((s_1,s_2,\\dots)\\) of sides \\(s_i \\in \\mathcal{C}_n\\) such that every every side is observed at some point. For any \\(m \\in \\{0,\\dots,n\\}\\) we define the random variable \\(X_m\\) as the function, from \\(\\Omega'\\) to \\(\\mathbb{R}\\), that maps any outcome \\(\\omega \\in \\Omega' = (s_1,s_2,\\dots)\\) to the first \\(i\\) such that \\(m\\) side has been observed at least once.\n$$\\forall \\omega = (s_i)_{i\\ge 1}\\in \\Omega', \\quad X_m(\\omega) = \\inf_i \\bigl\\{ i \\mid \\sharp (s_1,\\dots,s_i) = m \\bigr\\}$$Note that \\(X_n(\\omega)\\) is the number of rolls needed to observe every side of the chosen dice at least once. The average we are looking for is actually the expected value of \\(X_n\\). But for the expected value to defined, \\(X_m\\) has to be a measurable function from \\((\\Omega',\\sigma(\\mathcal{E})|_{\\Omega'})\\) to \\((\\mathbb{R},\\mathcal{B}(\\mathbb{R}))\\). Let \\(F_{m,l}\\) be the set of prefixes \\(f=(s_1,\\dots,s_l)\\) of length \\(l\\) such that \\(l\\) is the first roll for which exactly \\(m\\) sides have been observed at least once, i.e. \\(l = \\inf_i\\{i \\mid \\sharp (s_1,\\dots,s_i) = m \\}\\). Then $$ X_m = \\sum_{l\\in\\mathbb{N}} \\sum_{f \\in F_{m,l}} l \\times \\mathbb{1}_{\\mathcal{E}(f)\\cap \\Omega'} $$ and so \\(X_m\\) is indeed measurable. The expected value is:\n$$\\begin{aligned} \\mathbb{E}(X_m) \u0026 = \\sum_{l\\in\\mathbb{N}} l\\times p(X_m^{-1}(l)) \\\\ \u0026 = \\sum_{l\\in\\mathbb{N}} \\sum_{f \\in F_{m,l}} l \\times p(\\mathcal{E}(f)) \\\\ \u0026 = \\sum_{l\\in\\mathbb{N}} \\sum_{f \\in F_{m,l}} l \\times \\Bigl(\\frac{1}{n}\\Bigr)^l \\\\ \u0026 = \\sum_{l\\in\\mathbb{N}} |F_{m,l}| \\times l \\times \\Bigl(\\frac{1}{n}\\Bigr)^l \\end{aligned}$$The mistake we did in the last section is now clear. We computed \\(\\sum_{l\\in\\mathbb{N}} |F_{m,l}| \\times l\\) instead of \\(\\sum_{l\\in\\mathbb{N}} |F_{m,l}| \\times l \\times (\\frac{1}{n})^l\\). We just have to fix the function used in the aggregation to compute the right value:\ndef forOneValidPrefix(sides: Int)(length: Int): BigDecimal = (BigDecimal(1) / sides).pow(length) * length scala\u003e val depth = 100000 val depth: Int = 100000 scala\u003e val sides = 3 val sides: Int = 3 scala\u003e val expectedValueFor100000 = aggregate(sides,depth)(forOneValidPrefix(sides)) val expectedValueFor100000: BigDecimal = 5.499999999999999999999999999999999 This time the computed value match what we observed with random experiments, a value around \\(5.5\\). It also match the average we got for a 6-sided fair dice:\nscala\u003e val depth = 10000 val depth: Int = 10000 scala\u003e val sides = 6 val sides: Int = 6 scala\u003e val expectedValueFor100000 = aggregate(sides,depth)(forOneValidPrefix(sides)) val expectedValueFor100000: BigDecimal = 14.70000000000000000000000000000001 We can actually go a bit deeper by observing that for any \\(m \\in \\{1,\\dots,n\\}\\), \\(\\mathbb{E}(X_m) = \\mathbb{E}(X_{m-1}) + \\mathbb{E}(X_m - X_{m-1})\\):\n$$\\begin{aligned} \\mathbb{E}(X_m) \u0026 = \\sum_{i=0}^{m-1} \\mathbb{E}(X_{i+1} - X_i) \\\\ \\mathbb{E}(X_{i+1}-X_i) \u0026 = \\sum_{d\\in\\mathbb{N}^*} d \\times p((X_{i+1}-X_i)^{-1}(d)) \\\\ p((X_{i+1}-X_i)^{-1}(d)) \u0026 = \\sum_{k\\in\\mathbb{N}} p(\\mathcal{E}(F_{i+1,k+d}) \\cap \\mathcal{E}(F_{i,k})) \\\\p(\\mathcal{E}(F_{i+1,k+d})\\cap \\mathcal{E}(F_{i,k})) \u0026 = p(\\mathcal{E}(\\{f \\cdot f' \\cdot c \\mid f\\in F_{i,k},\\quad |f'|=d-1,\\ \\diamond f' \\subset \\diamond f,\\quad c\\in \\mathcal{C}_n\\setminus\\diamond f \\})) \\\\\u0026 = \\sum_{f\\in F_{i,k}} \\Biggl( \\sum_{|f'|=d-1,\\ \\diamond f' \\subset \\diamond f} \\Biggl( \\sum_{c\\in \\mathcal{C}_n\\setminus \\diamond f} p(\\mathcal{E}(f \\cdot f' \\cdot c)) \\Biggr)\\Biggr) \\\\\u0026 = \\sum_{f\\in F_{i,k}} \\Biggl( p(\\mathcal{E}(f)) \\times \\sum_{|f'|=d-1,\\ \\diamond f' \\subset \\diamond f} \\Biggl( p(\\mathcal{E}(f')) \\times \\sum_{c\\in \\mathcal{C}_n\\setminus \\diamond f} p(\\mathcal{E}(c)) \\Biggr)\\Biggr) \\\\\u0026 = \\sum_{f\\in F_{i,k}} \\Biggl( p(\\mathcal{E}(f)) \\times |\\{f'\\in \\mathcal{F} \\mid |f'|=d-1,\\ \\diamond f' \\subset \\diamond f\\}| \\times \\Bigl(\\frac{1}{n}\\Bigr)^{d-1} \\times \\frac{n-i}{n} \\Biggr) \\\\\u0026 = \\Bigl(\\frac{i}{n}\\Bigr)^{d-1} \\times \\frac{n-i}{n} \\times p(\\mathcal{E}(F_{i,k})) \\end{aligned}$$So \\(p(\\mathcal{E}(F_{i+1,k+d}) | \\mathcal{E}(F_{i,k})) = (\\frac{i}{n})^{d-1}\\times \\frac{n-1}{n} \\). So \\(p(\\mathcal{E}(F_{i+1,k+d}) | \\mathcal{E}(F_{i,k})) = (\\frac{i}{n})^{d-1}\\times \\frac{n-1}{n} \\). So \\(\\mathbb{E}(X_{i+1} - X_i) = \\sum_{d\\in\\mathbb{N}^*} d \\times \\frac{n-1}{n}\\times (\\frac{i}{n})^{d-1} \\).\nWe recognize a Geometric Distribution whose probability of success is \\(p' = \\frac{n-i}{n}\\). Its expected value is known to be \\(\\frac{1}{p'} = \\frac{n}{n-i}\\). It can be computed by\n$$\\begin{aligned} \\mathbb{E}(X_{i+1} - X_i) \u0026 = \\sum_{d\\in\\mathbb{N}^*} d \\times \\frac{n-i}{n}\\times \\Bigl(\\frac{i}{n}\\Bigr)^{d-1} \\\\\u0026 = \\frac{n-i}{n} \\times \\sum_{d\\in\\mathbb{N}^*} d \\times \\Bigl(\\frac{i}{n}\\Bigr)^{d-1} \\\\\u0026 = \\frac{n-i}{n} \\times \\sum_{d\\in\\mathbb{N}^*} d \\times \\Bigl(\\frac{i}{n}\\Bigr)^{d-1} \\end{aligned}$$But $$\\begin{aligned} \\sum_{d\\in\\mathbb{N}^\\star} d \\times x^{d-1} \u0026 = \\sum_{d\\in\\mathbb{N}^\\star} (x^d)^\\prime \\\\\u0026 = \\Bigl(\\sum_{d\\in\\mathbb{N}^\\star} x^d\\Bigr)^\\prime \\\\\u0026 = \\Bigl(\\frac{x}{1 - x}\\Bigr)^\\prime \\\\\u0026 = \\frac{1}{(1 - x)^2} \\end{aligned}$$So $$\\begin{aligned} \\mathbb{E}(X_{i+1} - X_i) \u0026 = \\frac{n-i}{n} \\times \\frac{1}{(1 - \\frac{i}{n})^2} \\\\\u0026 = \\frac{n-i}{n} \\times \\Bigl(\\frac{n}{n - i}\\Bigr)^2 \\\\\u0026 = \\frac{n}{n - i} \\end{aligned}$$Finally we can give the formula for the expected value and check that it gives the expected values:\n$$ \\mathbb{E}(X_n) = \\sum_{i=0}^{n-1} \\frac{n}{n-i} $$def expectedValue(sides: Int): Double = (1 to sides).map(sides.toDouble / _).sum scala\u003e expectedValue(6) val res0: Double = 14.7 scala\u003e expectedValue(3) val res1: Double = 5.5 Understanding the Probability Still given a \\(n\\)-sided fair dice \\(n\u003e0\\). Let \\(C \\subset \\mathcal{C}_n\\) be a subset of the sides of the dice and \\(l \\in \\mathbb{N}\\) a non-negative integer. The event of all outcomes whose prefixes of length \\(l\\) do not contain any side in \\(C\\) is written\n$$M_{n,l,C} = \\mathcal{E}(\\{ f\\in \\mathcal{F} \\mid |f|=l,\\quad \\diamond f \\cap C = \\emptyset \\}$$Note that for any subsets \\(C_1\\) and \\(C_2\\) of \\(\\mathcal{C}_n\\) and \\(l\\in\\mathbb{N}\\), the property \\(M_{n,l,C_1}\\cap M_{n,l,C_1} = M_{n,l,C_1\\cup C_2}\\) holds and \\(p(M_{n,l,C}) = (\\frac{n - |C|}{n})^l = (1 - \\frac{|C|}{n})^l\\). Let \\(A_{n,l}\\) be the event of all outcomes whose prefixes of size \\(l\\) contain every side of the dice at least once:\n$$\\begin{aligned} A_{n,l} \u0026 = \\mathcal{E}(\\{ f\\in \\mathcal{F} \\mid |f|=l,\\quad \\diamond f = C_n \\} \\\\ \u0026 = \\bigcap_{c\\in \\mathcal{C}_n} \\overline{M_{n,l,\\{c\\}}} \\\\ \u0026 = \\overline{\\bigcup_{c\\in C} M_{n,l,\\{c\\}}} \\end{aligned}$$$$\\begin{aligned} p(A_{n,l}) \u0026 = 1 - p(\\bigcup_{c \\in C_n} M_{n,l,\\{c\\}}) \\\\ \u0026 = 1 - \\Biggl[\\sum_{C \\subset C_n,C\\neq\\emptyset} -(-1)^{|C|} \\times p(\\bigcap_{c\\in C} M_{n,l,\\{c\\}})\\Biggr] \\\\ \u0026 = 1 - \\Biggl[\\sum_{C \\subset C_n,C\\neq\\emptyset} -(-1)^{|C|} \\times p(M_{n,C,l})\\Biggr] \\\\ \u0026 = 1 + \\Biggl[\\sum_{C \\subset C_n,C\\neq\\emptyset} (-1)^{|C|} \\times \\biggl(\\frac{1-|C|}{n}\\biggr)^{l}\\Biggr] \\\\ \u0026 = 1 + \\sum_{k=1}^{n} \\binom{n}{k} \\times (-1)^k \\times \\biggl(1 - \\frac{k}{n}\\biggr)^{l} \\end{aligned}$$We can generalize this result: given a \\(n\\)-sided fair dice and \\(C \\subset \\mathcal{C}_n\\) a subset of the sides of the dice. Let \\(A_{n,l,C}\\) be the set of outcomes whose prefixes of length \\(l\\) do contain only sides of \\(C\\) and every side of \\(C\\):\n$$\\begin{aligned} A_{n,l,C} \u0026 = \\mathcal{E}(\\{f\\in \\mathcal{F} \\mid |f|=n, \\quad \\diamond f = C\\}) \\\\p(A_{n,l,C}\\mid M_{n,l,\\overline{C}}) \u0026 = p(A_{l,|C|}) \\\\\\ \u0026 = 1 + \\sum_{k=1}^{|C|} \\binom{|C|}{k} \\times (-1)^k \\times \\biggl(1 - \\frac{k}{|C|}\\biggr)^{l} \\end{aligned}$$We found the probability of observing, in \\(l\\) dice rolls or less, a subset of all the sides. But \\(A_{n,l,C}\\) is not in general \\(X_n^{-1}(\\{l\\})\\) because outcomes in \\(X_n^{-1}(\\{l\\})\\) reach the last observed side at roll \\(l\\) while outcomes in \\(A_{n,l}\\) may have observed every side much before the \\(l\\)-th roll. But we can relate the two. For any side \\(c \\in \\mathcal{C}_n\\) and any non-negative integer \\(i\\in\\mathbb{N}\\), let \\(R_{n,i,c}\\) the event of observing the side \\(c\\) at roll \\(i\\). Let \\(l\\in\\mathbb{N}^*\\):\n$$\\begin{aligned} X_n^{-1}(\\{l\\}) \u0026 = \\bigcup_{c=1}^n A_{n,l-1,C_n\\setminus\\{c\\}} \\cap M_{n,l-1,\\{c\\}} \\cap R_{n,l,c} \\\\p(X_n^{-1}(\\{l\\})) \u0026 = \\sum_{c=1}^n p(A_{n,l-1,C_n\\setminus\\{c\\}} \\cap M_{n,l-1,\\{c\\}} \\cap R_{n,l,c}) \\\\ \u0026 = \\sum_{c=1}^n p(A_{n,l-1,C_n\\setminus\\{c\\}} \\mid M_{n,l-1,\\{c\\}}) \\times p(M_{n,l-1,\\{c\\}}) \\times \\frac{1}{n} \\\\ \u0026 = \\sum_{c=1}^n p(A_{n-1,l-1}) \\times \\biggl(\\frac{n-1}{n}\\biggr)^{l-1} \\times \\frac{1}{n} \\\\ \u0026 = \\biggl(\\frac{n-1}{n}\\biggr)^{l-1} \\times p(A_{n-1,l-1}) \\\\ \u0026 = \\biggl(\\frac{n - 1}{n}\\biggr)^{l-1} \\times \\Biggl[ 1 + \\sum_{k=1}^{n-1} \\binom{n-1}{k} \\times (-1)^k \\times \\biggl(\\frac{n - 1 - k}{n-1}\\biggr)^{l-1} \\Biggr] \\\\ \u0026 = \\biggl(1 - \\frac{1}{n}\\biggr)^{l-1} + \\sum_{k=1}^{n-1} \\binom{n-1}{k} \\times (-1)^k \\times \\biggl(1 - \\frac{k+1}{n}\\biggr)^{l-1} \\end{aligned}$$We need to be careful when translating this formula to avoid computation approximations to lead to very wrong answers:\ndef probabilityForLength(sides: Int, length: Int): BigDecimal = def cnk(k: Int, f: Int): BigInt = def dfact(n: Int, k: Int, res: BigInt = BigInt(1L)): BigInt = if k \u003c= 0 then res else dfact(n-1, k-1, res*n) dfact(f,k) / dfact(k,k-1) if sides == 0 || length == 0 then if sides == 0 \u0026\u0026 length == 0 then BigDecimal(1) else BigDecimal(0) else ((BigDecimal(sides - 1)/sides).pow(length - 1) + BigDecimal( (1 to (sides-1)).map { (k: Int) =\u003e ( cnk(k,sides-1) * (if k % 2 == 0 then 1 else -1) * BigInt(sides - 1 - k).pow(length-1) ) }.sum ) / BigDecimal(sides).pow(length - 1) ) We can check that the probability of observing all the sides of a 120-sided dice in less than 120 rolls is indeed 0:\nscala\u003e probabilityForLength(120, 13) val res0: BigDecimal = 4E-34 scala\u003e probabilityForLength(120, 42) val res1: BigDecimal = 8.751991852311394833964673845157515E-34 scala\u003e probabilityForLength(120, 99) val res2: BigDecimal = 1.468941911574859178966522092677385E-33 scala\u003e probabilityForLength(120, 119) val res3: BigDecimal = 1.529470021201154499656736868919480E-33 Note that the very small numbers we get for 42, 99 and 119 rolls instead of 0 are due approximations in computing with so big and small numbers. To get a better idea of how the probability behaves we can, as usual, export it as a CSV file. Let us start by defining the probability for every length using a stream:\nscala\u003e val probaD120 = LazyList .iterate(0)(_ + 1) .map(length =\u003e length -\u003e probabilityForLength(120, length)) val probaD120: LazyList[(Int, BigDecimal)] = LazyList(\u003cnot computed\u003e) And write this stream up to some length into a CSV file:\ndef (self: LazyList[(Int, BigDecimal)]) plot(depth: Int, file: String): Unit = import java.io._ val pw = new PrintWriter(new File(file)) pw.println(\"length;probability\") for (length, proba) \u003c- self.take(depth) do pw.printf(\"%d;%f\\n\", length, proba.toDouble) pw.close scala\u003e probaD120.plot(1500, \"/tmp/d120.csv\") There is a lot of things we can do thanks to this probability like asking how many rolls we need to observe all the sides of dice 9 times out of 10. The probability of observing all the sides of the dice in exactly or less than \\(l\\) rolls is given by\n$$p(X_n \\le l) = \\sum_{l'=0}^{l} p(X_n = l')$$All we need to do is transform the stream probaD120:\ndef [A,B,C](ll: LazyList[A])foldP(z: B)(f: (B,A) =\u003e (B,C)): LazyList[C] = LazyList.unfold((ll,z)) { case (l0, z0) =\u003e if l0.isEmpty then None else val (z1,c0) = f(z0,l0.head) Some((c0, (l0.tail,z1))) } def (self: LazyList[(Int, BigDecimal)]) cumul: LazyList[(Int, BigDecimal)] = self.foldP(BigDecimal(0)) { case (s, (l,p)) =\u003e (s+p, l -\u003e (s+p)) } scala\u003e val distribD120 = probaD120.cumul val distribD120: LazyList[(Int, BigDecimal)] = LazyList(\u003cnot computed\u003e) scala\u003e distribD120.dropWhile(_._2 \u003c 0.9).head._1 val res5: Int = 842 There is 90% chance that we observe all sides of the 120-sided fair dice with 842 rolls. Once again, we can get a better idea of how the distribution behaves by plotting it\nscala\u003e distribD120.plot(1500, \"/tmp/d120_cumul.csv\") Conclusion The initial question was simple:\nhow many rolls are needed, on average, with a \\(n\\) sided fair dice, to observe all of its sides.\nBut the answer was not! We have seen how to check, empirically, that the Scala Random.nextInt function correctly simulates a fair dice. From there we run (many) experiments to get an approximation of the answer. We experienced how easy but disastrous it can be to build a model disconnected from reality. We learned that building a valid model requires a deep understanding of the problem and the experiments. We had to put a lot of care into the construction of the model to be sure it is a valid formalization of the problem. The maths were not easy, but they were right. And in the end, maths lead us to a very simple formula. Was all this formal brutality useful? Yes, it was. The simple formula gives the exact answer and is by far the most efficient implementation. Going deeper we found how to answer more questions like the chance we have to observe all sides in \\(l\\) rolls or less. We even were able to get a precise idea of how the probability behaves by plotting it.\nAll along this journey, we used many of the new Scala 3 features among which extensions methods and Type Classes. We saw how easy they were to use and the great benefits they offer. Extensions methods let us add methods to objects without any boilerplate, Type Classes let us write generic function, etc.\nI hope you enjoyed this journey as much as I loved writing it. Have a look at all the Scala 3 features. Many of them are not covered here but are truly amazing (Polymorphic Functions, Dependent Function Types, Match Types, Intersection and Union Types, etc). The list is pretty large.",
    "description": "Given a fair dice, how many rolls are needed, on average, to observe all the sides? From this simple question, this article explores basic probability theory and statistics in Scala 3, the upcoming major release of the Scala programming language. It shows the new features, their use and benefits.",
    "tags": [],
    "title": "Playing with Probability in Scala 3",
    "uri": "/posts/probability_in_scala_3_all_sides/index.html"
  },
  {
    "breadcrumb": "Posts",
    "content": "Soyez les bienvenu¬∑e¬∑s! Cette session a le dessein de vous pr√©senter un outil de programmation tr√®s puissant. Alors que la plupart des introductions sur le sujet commencent par une pr√©sentation de ses fondements th√©oriques d‚Äôune mani√®re tr√®s formelle, nous avons choisi de vous le pr√©senter √† travers de courts exemples et des cas d‚Äôutilisation concrets.\nCet atelier est compos√© de trois parties. La derni√®re pr√©sente trois des cas d‚Äôutilisation des plus utiles. Ils forment les usages majeurs en pratique. Mais ne vous y aventurez pas sans pr√©paration! Cette partie est la derni√®re pour une bonne raison: elle s‚Äôappuie massivement sur les le√ßons des parties pr√©c√©dentes. Commencez par Premier Contact, elle vous exposera, via les plus simples exemples, les id√©es clefs. Son but est d‚Äôouvrir votre esprit √† des mani√®res d‚Äôutiliser les types et donn√©es que vous n‚Äôavez vraisemblablement jamais soup√ßonn√©es. Arpentez ensuite Cas d‚Äôutilisation simples et utiles: relations sur les types, pour un premier d√©fi devant un usage pratique. Apr√®s cela seulement vous serez pr√™t¬∑e pour Cas d‚ÄôUtilisation Plus Avanc√©s.\nAssurez vous de lire LISEZ-MOI, cette section contient de pr√©cieuses astuces pour faciliter votre parcours.\nRemerciements Nous tenons √† remercier Laure Juglaret pour ses nombreuses relectures, ses pr√©cieuses remarques et corrections.\nLISEZ-MOI Durant toute cette pr√©sentation, nous consid√©rerons que:\nnull n‚Äôexiste pas! La r√©flexion au runtime n‚Äôexiste pas! (c.-√†-d. isInstanceOf, getClass, etc) Cette pr√©sentation consid√®re que ces fonctionnalit√©s n‚Äôexistent pas du tout!.\nLeur utilisation n‚Äôam√®nera jamais √† une r√©ponse correcte aux questions..\nPour faire cet atelier vous devez disposez du n√©cessaire pour √©crire, compiler et ex√©cuter rapidement du code Scala. Le meilleur moyen est d‚Äôouvrir une session interactive (R.E.P.L.). Si vous avez Scala d‚Äôinstall√© sur votre syst√®me, vous pouvez facilement en d√©marrer une via la ligne de commande en ex√©cutant le programme scala:\nsystem-command-line# scala Welcome to Scala 2.13.1 (OpenJDK 64-Bit Server VM, Java 1.8.0_222). Type in expressions for evaluation. Or try :help. scala\u003e Pour rappel, dans une session interactive (R.E.P.L.), la commande :paste permet de copier du code dans la session et la commande :reset de repartir d‚Äôun environnement vierge.\nSi vous n‚Äôavez pas Scala d‚Äôinstall√©, vous pouvez utiliser le site https://scastie.scala-lang.org/ .\n√âchauffements Cette section est un bref rappel de quelques d√©finitions et propri√©t√©s sur les types et les valeurs.\nValeurs et Types? Les valeurs sont les donn√©es concr√®tes que vos programmes manipulent comme l‚Äôentier 5, le bool√©en true, la cha√Æne \"Hello World!\", la fonction (x: Double) =\u003e x / 7.5, la liste List(1,2,3), etc. Il est souvent pratique de classer les valeurs en groupes. Ces groupes sont appel√©s des types. Par exemple:\nInt est le groupe des valeurs enti√®res, c.-√†-d. les valeurs telles que 1, -7, 19, etc. Boolean est le groupe contenant exactement les valeurs true et false (ni plus, ni moins!). String est le groupe dont les valeurs sont \"Hello World!\", \"\", \"J' ‚ù§Ô∏è les GADTs\", etc. Double =\u003e Double est le groupe dont les valeurs sont les fonctions prenant en argument n‚Äôimporte quel Double et renvoyant √©galement un double Double. Pour indiquer que la valeur v appartient au type (c.-√†-d. groupe de valeurs) T, la notation est v : T. En Scala, tester si une valeur v appartient au type T est tr√®s simple: il suffit de taper v : T dans la session interactive (REPL):\nscala\u003e 5 : Int res7: Int = 5 Si Scala l‚Äôaccepte, alors v appartient bien au type T. Si Scala r√¢le, ce n‚Äôest probablement pas le cas:\nscala\u003e 5 : String ^ error: type mismatch; found : Int(5) required: String Combien de types? Cr√©ons maintenant quelques types et quelques unes de leurs valeurs (quand cela est possible!).\nclass UnType Question 1: Combien de types la ligne class UnType d√©finit-elle?\nSolution (cliquer pour d√©voiler) Comme son nom le sugg√®re, la ligne class UnType d√©finit seulement un type, nomm√© UnType.\nPassons maintenant √†:\nclass UnTypePourChaque[A] Question 2: Combien de types la ligne class UnTypePourChaque[A] d√©finit-elle?\nSolution (cliquer pour d√©voiler) Comme son nom le sugg√®re, chaque type concret A donne lieu √† un type distinct UnTypePourChaque[A].\nPar exemple, une liste d‚Äôentiers n‚Äôest ni une liste de bool√©ens, ni une liste de cha√Æne de caract√®res, ni une liste de fonctions, ni ‚Ä¶ En effet les types List[Int], List[Boolean], List[Int =\u003e Int], etc sont tous des types distincts.\nla ligne class UnTypePourChaque[A] d√©finit un type distinct pour chaque type concret A. Il y a une infinit√© de types concrets A, donc une infinit√© de de types distincts UnTypePourChaque[A].\nQuestion 3: Donnez une valeur qui appartient √† la fois aux types UnTypePourChaque[Int] et UnTypePourChaque[Boolean].\nPour rappel, null n‚Äôexiste pas!\nSolution (cliquer pour d√©voiler) C‚Äôest en fait impossible. Chaque type concret A donne lieu √† un type distinct UnTypePourChaque[A] qui n‚Äôa aucune valeur en commun avec les autres types de la forme UnTypePourChaque[B] avec B ‚â† A.\nCombien de valeurs? En consid√©rant le type suivant:\nfinal abstract class PasDeValeurPourCeType Question 1: Donnez une valeur appartenant au type PasDeValeurPourCeType? Combien de valeurs appartiennent au type PasDeValeurPourCeType?\nAstuce (cliquer pour d√©voiler) Qu‚Äôest ce qu‚Äôune classe final? En quoi est-ce qu‚Äôelle diff√®re d‚Äôune classe normale (non finale)? Qu‚Äôest ce qu‚Äôune classe abstract? En quoi est-ce qu‚Äôelle diff√®re d‚Äôune classe concr√®te? Solution (cliquer pour d√©voiler) La classe PasDeValeurPourCeType est d√©clar√©e comme abstract. Cela signifie qu‚Äôil est interdit de cr√©er des instances directes de cette classe:\nscala\u003e new PasDeValeurPourCeType ^ error: class PasDeValeurPourCeType is abstract; cannot be instantiated La seule mani√®re de cr√©er une instance d‚Äôune classe abstraite est de cr√©er une une sous-classe concr√®te. Mais le mot clef final interdit la cr√©ation de telles sous-classes:\nscala\u003e class SousClasseConcrete extends PasDeValeurPourCeType ^ error: illegal inheritance from final class PasDeValeurPourCeType Il n‚Äôexiste aucun moyen de cr√©er une instance pour PasDeValeurPourCeType.\nPrenons un autre exemple:\nsealed trait ExactementUneValeur case object LaSeuleValeur extends ExactementUneValeur Question 2: Donnez une valeur appartenant au type ExactementUneValeur?\nSolution (cliquer pour d√©voiler) Par d√©finition, LaSeuleValeur est une valeur du type ExactementUneValeur.\nQuestion 3: Combien de valeurs appartiennent √† ExactementUneValeur?\nSolution (cliquer pour d√©voiler) Comme ci-dessus, ExactementUneValeur, √©tant un trait, est abstrait. √âtant sealed, l‚Äô√©tendre en dehors de son fichier source est interdit. Donc LaSeuleValeur est la seule valeur du type ExactementUneValeur.\nPremier Contact Cette partie pr√©sente les id√©es clefs. Il y a en fait seulement deux id√©es! Vous trouverez ici des exemples √©pur√©s illustrant chacune de ces deux id√©es.\nCas d‚ÄôUtilisation: Preuve d‚Äôune propri√©t√© D√©finissons un simple sealed trait:\nsealed trait ATrait[A] case object AValue extends ATrait[Char] Question 1: Donnez une valeur du type ATrait[Char].\nSolution (cliquer pour d√©voiler) Par d√©finition, AValue est une valeur du type ATrait[Char].\nQuestion 2: Donnez une valeur du type ATrait[Double].\nSolution (cliquer pour d√©voiler) Il n‚Äôexiste aucun moyen d‚Äôobtenir une instance du type ATrait[Double]. Il n‚Äôexiste en fait aucun moyen d‚Äôobtenir une instance de ATrait[B] pour B ‚â† Char parce que la seule valeur possible est AValue qui est de type ATrait[Char].\nQuestion 3: Que pouvez vous conclure sur le type A si vous avez une valeur ev de type ATrait[A] (c.-√†-d. ev: ATrait[A])?\nSolution (cliquer pour d√©voiler) La seule valeur possible est AValue, donc ev == AValue. De plus AValue est de type ATrait[Char] donc A = Char.\nQuestion 4: Dans la session interactive (REPL), entrez le code suivant:\ndef f[A](x: A, ev: ATrait[A]): Char = x Question 5: Essayez maintenant en utilisant un filtrage par motif (pattern matching) sur ev: ATrait[A]\ndef f[A](x: A, ev: ATrait[A]): Char = ev match { case AValue =\u003e x } Le filtrage par motif (pattern-matching) est il exhaustif?\nSolution (cliquer pour d√©voiler) Le filtrage par motif est exhaustif parce la seule et unique valeur possible pour ev est en fait AValue. De plus AValue est de type ATrait[Char] ce qui signifie que ev : ATrait[Char] parce que ev == AValue. Donc A = Char et x : Char.\nQuestion 6: Appelez f avec x = 'w' : Char.\nSolution (cliquer pour d√©voiler) scala\u003e f[Char]('w', AValue) res0: Char = w Question 7: Appelez f avec x = 5.2 : Double.\nSolution (cliquer pour d√©voiler) C‚Äôest impossible parce que cela demenderait de fournir une valeur ev : ATrait[Double], ce qui n‚Äôexiste pas!\nscala\u003e f[Double](5, AValue) ^ error: type mismatch; found : AValue.type required: ATrait[Double] Remarque pour les personnes √† l'aise en Scala (cliquer pour d√©voiler) En utilisant toutes les chouettes fonctionnalit√©s syntaxiques de Scala, la version satisfaisante en production du code ci-dessus est:\nsealed trait IsChar[A] object IsChar { implicit case object Evidence extends IsChar[Char] def apply[A](implicit evidence: IsChar[A]): IsChar[A] = evidence } def f[A: IsChar](x: A): Char = IsChar[A] match { case IsChar.Evidence =\u003e x } Cas d‚ÄôUtilisation: La seule chose que je sais, est qu‚Äôil existe Que feriez vous si vous vouliez que votre application tienne un journal d‚Äô√©v√®nements (c.-√†-d. un log), mais que vous vouliez √™tre sur qu‚Äôelle ne d√©pende d‚Äôaucun d√©tail d‚Äôimpl√©mentation de la m√©thode de journalisation (c.-√†-d. du logger), de telle mani√®re que vous puissiez changer son impl√©mentation sans risquer de casser votre application?\nEn consid√©rant le type suivant, UnknownLogger, des m√©thodes de journalisation:\nsealed trait UnknownLogger final case class LogWith[X](logs : X, appendMessage: (X, String) =\u003e X) extends UnknownLogger La premi√®re m√©thode (c.-√†-d. *logger) que nous cr√©ons stocke les messages dans une String:\nval loggerStr : UnknownLogger = LogWith[String](\"\", (logs: String, message: String) =\u003e logs ++ message) La seconde m√©thode les stocke dans une List[String]:\nval loggerList : UnknownLogger = LogWith[List[String]](Nil, (logs: List[String], message: String) =\u003e message :: logs) La troisi√®me m√©thode de journalisation imprime directement les messages sur la sortie standard:\nval loggerStdout : UnknownLogger = LogWith[Unit]((), (logs: Unit, message: String) =\u003e println(message)) Notez que ces trois m√©thodes de journalisation ont toutes le m√™me type (c.-√†-d. UnknownLogger) mais qu‚Äôelles stockent les messages en utilisant diff√©rents types X (String, List[String] et Unit).\nQuestion 1: Soit v une valeur de type UnknownLogger. Clairement v doit √™tre une instance de la classe LogWith[X] pour un certain X. Que pouvez vous dire sur le type X? Pouvez-vous deviner quel type concret est X?\nPour rappel, il est interdit d‚Äôutiliser la r√©flexion au runtime! (c.-√†-d. isInstanceOf, getClass, etc)\nSolution (cliquer pour d√©voiler) Nous ne savons presque rien sur X. La seule chose que nous avons est qu‚Äôil existe au moins une valeur (v.logs) de type X. √Ä part cela, X peut √™tre n‚Äôimporte quel type.\nNe pas savoir quel type concret est X est tr√®s utile pour garantir que le code qui utilisera v : UnknownLogger ne d√©pendra pas de la nature de X. Si ce code savait que X √©tait String par exemple, il pourrait ex√©cuter des op√©rations que nous voulons interdir comme inverser la liste, ne retenir que les n premiers caract√®res, etc. En cachant la nature deX, nous for√ßons notre application √† ne pas d√©pendre du type concret derri√®reX mais de n‚Äôutiliser que la fonnction fournie v.appendMessage. Ainsi changer l‚Äôimpl√©mentation r√©elle de la m√©thode de journalisation ne cassera aucun code.\nQuestion 2: √âcrivez la fonction def log(message: String, v: UnknownLogger): UnknownLogger qui utilise v.appendMessage pour ajouter le message au journal v.logs et retourne un nouvel UnknownLogger contenant le nouveau journal (c.-√†-d. le nouveau log).\nPour rappel, en Scala, le motif (c.-√†-d. pattern) case ac : AClass[t] =\u003e est possible dans les expressions de type match/case comme alternative au motif case AClass(v) =\u003e :\nfinal case class AClass[A](value : A) def f[A](v: AClass[A]): A = v match { case ac : AClass[t] =\u003e // La variable `t` is une variable de type // Le type `t` est `A` val r : t = ac.value r } Son principal avantage est d‚Äôintroduire la variable de type t. Les variables de type se comportent comme des variables de motif classiques (c.-√†-d. pattern variables) √† l‚Äôexception pr√©s qu‚Äôelles repr√©sentent des types et non des valeurs. Avoir t sous la main nous permet d‚Äôaider le compilateur en donnant explicitement certains types (comme ci-dessus, expliciter que r est de type t).\nSolution (cliquer pour d√©voiler) def log(message: String, v: UnknownLogger): UnknownLogger = v match { case vx : LogWith[x] =\u003e LogWith[x](vx.appendMessage(vx.logs, message), vx.appendMessage) } Question 3: Ex√©cutez log(\"Hello World\", loggerStr) et log(\"Hello World\", loggerList) et log(\"Hello World\", loggerStdout)\nSolution (cliquer pour d√©voiler) scala\u003e log(\"Hello World\", loggerStr) res0: UnknownLogger = LogWith(Hello World,$$Lambda$988/1455466014@421ead7e) scala\u003e log(\"Hello World\", loggerList) res1: UnknownLogger = LogWith(List(Hello World),$$Lambda$989/1705282731@655621fd) scala\u003e log(\"Hello World\", loggerStdout) Hello World res2: UnknownLogger = LogWith((),$$Lambda$990/1835105031@340c57e0) Remarque pour les personnes √† l'aise en Scala (cliquer pour d√©voiler) Une fois encore, en utilisant toutes les chouettes fonctionnalit√©s syntaxiques de Scala, la version satisfaisante en production du code ci-dessus est:\nsealed trait UnknownLogger { type LogsType val logs : LogsType def appendMessage(presentLogs: LogsType, message: String): LogsType } object UnknownLogger { final case class LogWith[X](logs : X, appendMessage_ : (X, String) =\u003e X) extends UnknownLogger { type LogsType = X def appendMessage(presentLogs: LogsType, message: String): LogsType = appendMessage_(presentLogs, message) } def apply[X](logs: X, appendMessage: (X, String) =\u003e X): UnknownLogger = LogWith[X](logs, appendMessage) } Conclusion Interm√©diaire Les GADTs ne sont en fait que ceci: de simples sealed trait avec quelques case object (possiblement aucun) et quelques final case class (√©galement possiblement aucune!). Dans les parties suivantes, nous explorerons quelques un des cas d‚Äôutilisation majeurs des GADTs.\nCas d‚Äôutilisation simples et utiles: relations sur les types Une facult√© simple mais tr√®s utile des GADTs est l‚Äôexpression de relations sur les types telles que:\nLe type A est-il √©gal au type B? Le type A est-il un sous-type de B? Notez bien que, par d√©finition, tout type A est sous-type de lui-m√™me (c.-√†-d. A \u003c: A), tout comme tout entier x est √©galement inf√©rieur ou √©gal √† lui-m√™me x ‚â§ x.\nCas d‚ÄôUtilisation: T√©moin d‚Äô√âgalit√© entre Types sealed trait EqT[A,B] final case class Evidence[X]() extends EqT[X,X] Question 1: Donnez une valeur de type EqT[Int, Int]\nSolution (cliquer pour d√©voiler) scala\u003e Evidence[Int]() : EqT[Int, Int] res0: EqT[Int,Int] = Evidence() Question 2: Donnez une valeur de type EqT[String, Int]\nSolution (cliquer pour d√©voiler) La classe Evidence est l‚Äôunique sous-classe conctr√®te du trait EqT et il est impossible d‚Äôen cr√©er une autre parce que EqT est sealed. Donc une valeur v : EqT[A,B] ne peut √™tre qu‚Äôune instance de Evidence[X] pour un certain type X, qui elle-m√™me est de type EqT[X,X]. Ainsi il n‚Äôy a aucun moyen d‚Äôobtenir une valeur de type EqT[String, Int]\nQuestion 3: Soient A et B deux types (inconnus). Si je vous donne une valeur de type EqT[A,B], que pouvez-vous en d√©duire sur A et B?\nSolution (cliquer pour d√©voiler) Si je vous donne une valeur v : EqT[A,B], alors vous savez que v est une instance de Evidence[X] pour un certain type X (inconnu). En effet la classe Evidence est la seule et unique sous-classe concr√®te du sealed trait EqT. En fait, Evidence[X] est un sous-type de EqT[X,X]. Donc v : EqT[X,X]. Les types EqT[A,B] et EqT[X,X] n‚Äôont aucune valeur en commun si A ‚â† X ou B ‚â† X, donc A = X et B = X. Et donc A = B. CQFD.\nRemarque pour les personnes √† l'aise en Scala (cliquer pour d√©voiler) En production, il est pratique de d√©finir EqT de la mani√®re suivante, qui est bien entendu √©quivalente:\nsealed trait EqT[A,B] object EqT { final case class Evidence[X]() extends EqT[X,X] implicit def evidence[X] : EqT[X,X] = Evidence[X]() def apply[A,B](implicit ev: EqT[A,B]): ev.type = ev } Passer d‚Äôun type √©gal √† l‚Äôautre Si A et B sont en fait le m√™me type, alors List[A] est √©galement le m√™me type que List[B], Option[A] est √©galement le m√™me type que Option[B], etc. De mani√®re g√©n√©rale, pour n‚Äôimporte quel F[_], F[A] est √©galement le m√™me type que F[B].\nQuestion 4: √âcrivez la fonction def coerce[F[_],A,B](eqT: EqT[A,B])(fa: F[A]): F[B].\nSolution (cliquer pour d√©voiler) def coerce[F[_],A,B](eqT: EqT[A,B])(fa: F[A]): F[B] = eqT match { case _ : Evidence[x] =\u003e fa } La biblioth√®que standard de Scala d√©finit d√©j√† une classe, nomm√©e =:=[A,B] (son nom est bel et bien =:=), repr√©sentant l‚Äô√©galit√© entre types. Je vous recommande vivement de jeter un ≈ìil √† sa documentation (cliquez ici). Fort heureusement, pour plus de lisibilit√©, Scala nous permet d‚Äô√©crire A =:= B le type =:=[A,B].\n√âtant donn√© deux types A et B, avoir une instance (c.-√†-d. objet) de A =:= B prouve que A et B sont en r√©alit√© le m√™me type, tout comme pour EqT[A,B]. Pour rappel, A =:= B n‚Äôest que du sucre syntaxique pour d√©signer le type =:=[A,B].\nDes instances de A =:= B peuvent √™tres cr√©es en utilisant la fonction (\u003c:\u003c).refl[X]: X =:= X (cliquer pour voir la documentation). Le ‚Äúsymbole‚Äù \u003c:\u003c est en effet un nom d‚Äôobjet valide.\nQuestion 5: En utilisant la fonction coerce ci-dessus, √©crivez la fonction def toScalaEq[A,B](eqT: EqT[A,B]): A =:= B.\nAstuce (cliquer pour d√©voiler) def toScalaEq[A,B](eqT: EqT[A,B]): A =:= B = { /* Trouver une d√©finition pour: - le constructeur de type `F` - la valeur `fa : F[A]` */ type F[X] = ??? val fa : F[A] = ??? /* Telles que cet appel: */ coerce[F,A,B](eqT)(fa) // soit de type `F[B]` } Solution (cliquer pour d√©voiler) def toScalaEq[A,B](eqT: EqT[A,B]): A =:= B = { type F[X] = A =:= X val fa: F[A] = (\u003c:\u003c).refl[A] coerce[F,A,B](eqT)(fa) } Question 6: En utilisant la m√©thode substituteCo[F[_]](ff: F[A]): F[B] des objets de la classe A =:= B, dont la documentation est ici, √©crivez la fonction def fromScalaEq[A,B](scala: A =:= B): EqT[A,B].\nAstuce (cliquer pour d√©voiler) def fromScalaEq[A,B](scala: A =:= B): EqT[A,B] = { /* Trouver une d√©finition pour: - le constructeur de type `F` - la valeur `fa : F[A]` */ type F[X] = ??? val fa : F[A] = ??? /* Telles que cet appel: */ scala.substituteCo[F](fa) // soit de type `F[B]` } Solution (cliquer pour d√©voiler) def fromScalaEq[A,B](scala: A =:= B): EqT[A,B] = { type F[X] = EqT[A,X] val fa: F[A] = Evidence[A]() scala.substituteCo[F](fa) } Cas d‚ÄôUtilisation: T√©moin de Sous-Typage Dans cette section, nous voulons cr√©er les types SubTypeOf[A,B] dont les valeurs prouvent que le type A est un sous-type de B (c.-√†-d. A \u003c: B). Une classe similaire, mais diff√©rente, est d√©j√† d√©finie dans la biblioth√®que standard de Scala. Il s‚Äôagit de la classe \u003c:\u003c[A,B], qui est le plus souvent √©crite A \u003c:\u003c B. Sa documentation est ici. Cette section √©tant d√©di√©e √† l‚Äôimpl√©mentation d‚Äôune variante de cette classe, veuillez ne pas utiliser \u003c:\u003c[A,B] pour impl√©menter SubTypeOf.\nQuestion 1: En utilisant uniquement des bornes sup√©rieures (c.-√†-d. A \u003c: B) ou bornes inf√©rieures (c.-√†-d. A \u003e: B) et aucune annotation de variance (c.-√†-d. [+A] et [-A]), cr√©ez le trait SubTypeOf[A,B] (et tout ce qui est n√©cessaire) tel que:\nIl existe une valeur de type SubType[A,B] si et seulement si A est un sous-type de B (c.-√†-d. A \u003c: B).\nPour rappel, par d√©finition, un type A est un sous-type de lui-m√™me (c.-√†-d. A \u003c: A).\nPour rappel, n‚Äôutilisez pas la classe \u003c:\u003c[A,B].\nSolution (cliquer pour d√©voiler) sealed trait SubTypeOf[A,B] final case class SubTypeEvidence[A \u003c: B, B]() extends SubTypeOf[A,B] Remarque pour les personnes √† l'aise en Scala (cliquer pour d√©voiler) En production, il est pratique de d√©finir SubTypeOf de la mani√®re √©quivalente suivante:\nsealed trait SubTypeOf[A,B] object SubTypeOf { final case class Evidence[A \u003c: B, B]() extends SubTypeOf[A,B] implicit def evidence[A \u003c: B, B]: SubTypeOf[A,B] = Evidence[A,B]() def apply[A,B](implicit ev: SubTypeOf[A,B]): ev.type = ev } Cas d‚ÄôUtilisation: √âviter les messages d‚Äôerreur de scalac √† propos des bornes non respect√©es Dans cet exemple, nous voulons mod√©liser le r√©gime alimentaire de certains animaux. Commen√ßons par d√©finir le type Food (c.-√†-d. nourriture) et quelques-uns de ces sous-types:\ntrait Food class Vegetable extends Food class Fruit extends Food et maintenant la classe repr√©sentant les animaux mangeant de la nourriture de type A (c.-√†-d. Vegetable, Fruit, etc):\nclass AnimalEating[A \u003c: Food] val elephant : AnimalEating[Vegetable] = new AnimalEating[Vegetable] D√©finissons une fonction comme il en existe tant en Programmation Fonctionnelle et passons lui elephant comme argument:\ndef dummy[F[_],A](fa: F[A]): String = \"Ok!\" scala\u003e dummy[List, Int](List(1,2,3)) res0: String = Ok! scala\u003e dummy[Option, Boolean](Some(true)) res1: String = Ok! scala\u003e dummy[AnimalEating, Vegetable](elephant) ^ error: kinds of the type arguments (AnimalEating,Vegetable) do not conform to the expected kinds of the type parameters (type F,type A). AnimalEating's type parameters do not match type F's expected parameters: type A's bounds \u003c: Food are stricter than type _'s declared bounds \u003e: Nothing \u003c: Any Question 1: Pourquoi scalac se plaint il?\nSolution (cliquer pour d√©voiler) La fonction dummy requiert que son argument F, qui est un constructeur de type comme le sont List, Option, Future, etc, accepte n‚Äôimporte quel type en argument afin qu‚Äôil soit toujours possible d‚Äô√©crire F[A] pour n‚Äôimporte quel type A. Hors AnimalEating impose que son argument soit un sous-type de Food. Donc AnimalEating ne peut √™tre utilis√© comme argument F de dummy.\nLe probl√®me est que, en d√©finissant class AnimalEating[A \u003c: Food], nous avons impos√© √† A d‚Äô√™tre un sous-type de Food. Donc Scala, tout comme Java, nous interdit de donner √† AnimalEating, en tant qu‚Äôargument A, autre chose qu‚Äôun sous-type de Food (en incluant Food lui-m√™me):\nscala\u003e type T1 = AnimalEating[Int] ^ error: type arguments [Int] do not conform to class AnimalEating's type parameter bounds [A \u003c: Food] scala\u003e type T2 = AnimalEating[Food] defined type alias T2 Nous sommes face √† un dilemme: afin d‚Äôutiliser la fonction dummy, que nous tenons beaucoup √† utiliser parce c‚Äôest une fonction tr√®s utile, il nous faut supprimer la contrainte A \u003c: Food de la d√©finition class AnimalEating[A \u003c: Food]. Mais nous tenons √©galement au fait que les animaux ne mangent que de la nourriture (Food) et pas des entiers, ni des bool√©ens et encore moins des cha√Ænes de caract√®res!\nQuestion 2: Comment pouvez vous adapter la d√©finition de AnimalEating telle que:\nIl soit possible d‚Äôappeler dummy avec comme argument elephant! Nous voulons:\nscala\u003e dummy[AnimalEating, Vegetable](elephant) res0: String = Ok! Si A n‚Äôest pas un sous-type de Food (Food lui-m√™me inclus), alors il doit √™tre impossible de cr√©er une instance de AnimalEating[A].\nLa classe AnimalEating doit rester une classe ouverte (c.-√†-d. non sealed ou final)! Il doit toujours √™tre possible pour n‚Äôimporte qui, n‚Äôimporte quand, de cr√©er librement des sous-classes de AnimalEating. Bien √©videmment, ces sous-classes doivent respecter les deux contraintes ci-dessus.\nAstuce (cliquer pour d√©voiler) En Scala, Nothing est un type ne contenant aucune valeur. Pouvez vous cr√©er une valeur de type (Nothing, Int)? Pourquoi?\nSolution (cliquer pour d√©voiler) Si, afin de cr√©er une instance de AnimalEating[A], nous for√ßons chaque m√©thode cr√©ant des valeurs √† prendre un param√®tre suppl√©mentaire de type SubTypeOf[A, Food], alors il sera uniquement possible de cr√©er une instance de AnimalEating[A] quand A sera un sous-type de Food:\nclass AnimalEating[A](ev : SubTypeOf[A, Food]) val elephant : AnimalEating[Vegetable] = new AnimalEating[Vegetable](SubTypeEvidence[Vegetable, Food]) Pour cr√©er une valeur de type AnimalEating[A], nous avons besoin d‚Äôappeler le constructeur d‚ÄôAnimalEating. Pour appeler ce constructeur, il nous faut fournir ev : SubTypeOf[A, Food].\nIl nous est d√©sormais possible d‚Äôappeler la fonction dummy sur elephant:\nscala\u003e dummy[AnimalEating, Vegetable](elephant) res0: String = Ok! En pratique, en utilisant des implicites, le compilateur peut fournir de lui-m√™me le param√®tre ev : SubTypeOf[A, Food].\nNotez qu‚Äôil est d√©sormais possible d‚Äô√©crire le type AnimalEating[Int] mais vous ne pourrez jamais cr√©er une valeur de ce type.\nCas d‚ÄôUtilisation: Fournir les bonnes donn√©es au bon diagramme Ce cas d‚Äôutilisation traite des m√©thodes pour garantir, √† la compilation, que seulement les valeurs du bon type peuvent √™tre donn√©es √† une fonction donn√©e. L‚Äôexemple choisi est celui de la conception d‚Äôune biblioth√®que de graphiques. Afin de simplifier l‚Äôexemple, nous consid√®rerons que notre biblioth√®que n‚Äôimpl√©mente que deux types de graphique: des camemberts (c.-√†-d. pie charts) et des graphiques dit XY (c.-√†-d. XY charts). Cela s‚Äô√©crit en Scala via l‚Äô√©num√©ration:\nsealed trait ChartType case object PieChart extends ChartType case object XYChart extends ChartType Bien √©videmment les camemberts (Pie) et graphiques XY s‚Äôappuient sur des jeux de donn√©es de nature diff√©rente. Encore une fois, pour simplifier, nous consid√®rerons que les deux types de donn√©es sont PieData pour les camemberts et XYData pour les graphiques XY:\nclass PieData class XYData Un camembert (PieChart) n‚Äôaffiche que des donn√©es PieData, alors qu‚Äôun graphique XY (XYChart) n‚Äôaffiche que des donn√©es XYData. Voici, grandement simplifi√©e, la fonction d‚Äôaffichage draw:\ndef draw[A](chartType: ChartType)(data: A): Unit = chartType match { case PieChart =\u003e val pieData = data.asInstanceOf[PieData] // Faire des trucs pour tracer les donn√©es pieData () case XYChart =\u003e val xyData = data.asInstanceOf[XYData] // Faire des trucs pour tracer les donn√©es xyData () } Cette fonction repose sur l‚Äôhypoth√®se que l‚Äôutilisateur¬∑rice n‚Äôappellera la fonction draw que sur le bon type de donn√©es. Quand chartType vaut PieChart, la fonction pr√©suppose, via data.asInstanceOf[PieData] que data est en fait du type PieData. Et quand chartType vaut XYChart, elle pr√©suppose que data est en fait de type XYData.\nLe probl√®me est que ces suppositions reposent sur l‚Äôid√©e que les utilisateurs¬∑rices et/ou d√©veloppeurs¬∑euses s‚Äôassureront toujours que ces hypoth√®ses soient bien respect√©es. Mais rien n‚Äôemp√™che quelqu‚Äôun¬∑e d‚Äôappeler draw sur un camembert (PieChart) avec des donn√©es de type XYData (ou le contraire), faisant planter le syst√®me mis√©rablement en production!\nscala\u003e draw(PieChart)(new XYData) java.lang.ClassCastException: XYData cannot be cast to PieData at .draw(\u003cpastie\u003e:11) ... 28 elided En tant que d√©veloppeurs¬∑euses, nous savons que les erreurs, √ßa arrive! Nous voulons un moyen d‚Äôemp√™cher ces bogues ennuyeux de survenir en production! Nous voulons imposer, √† la compilation, que seulement deux scenarii soit possibles:\nQuand draw est appel√©e avec chartType == PieChart: l‚Äôargument data doit √™tre de type PieData Quand draw est appel√©e avec chartType == XYChart: l‚Äôargument data doit √™tre de type XYData. Pour rappel, ces deux contraintes doivent √™tre v√©rifi√©es √† la compilation!\nQuestion 1: Adaptez les d√©finitions de ChartType, PieChart, XYChart et draw telles que:\nTout scenario diff√©rent des deux ci-dessus fera √©chouer la compilation sur une erreur de type.\nChartType doit toujours √™tre un sealed trait. Mais il est autoris√© √† prendre des param√®tres de type (c.-√†-d. generics).\nPieChart et XYChar doivent toujours √™tre des case object et ils doivent toujours √©tendre ChartType.\nLes d√©clarations de ChartType, PieChart et XYChar ne doivent pas avoir de corps du tout (c.-√†-d. il ne doit pas y avoir d‚Äôaccolades { ... } dans leurs d√©clarations);\nAstuce (cliquer pour d√©voiler) Le code ressemble √† ceci:\nsealed trait ChartType[/*METTRE LES GENERICS ICI*/] case object PieChart extends ChartType[/*Il y a quelque chose √† √©crire ici*/] case object XYChart extends ChartType[/*Il y a quelque chose √† √©crire ici aussi*/] def draw[A](chartType: ChartType[/*Ecrire quelque chose ici*/])(data: A): Unit = chartType match { case PieChart =\u003e val pieData : PieData = data () case XYChart =\u003e val xyData: XYData = data () } Solution (cliquer pour d√©voiler) sealed trait ChartType[A] case object PieChart extends ChartType[PieData] case object XYChart extends ChartType[XYData] def draw[A](chartType: ChartType[A])(data: A): Unit = chartType match { case PieChart =\u003e val pieData : PieData = data () case XYChart =\u003e val xyData: XYData = data () } Vous pouvez maintenant dormir sur vos deux oreilles avec l‚Äôassurance que votre code en production ne plantera pas √† cause d‚Äôune entr√©e non conforme √† cet endroit üòâ\nCas d‚ÄôUtilisation Plus Avanc√©s Maintenant que vous avez vu ce que sont les GADTs et comment les utiliser dans la vie de tous les jours, vous √™tes pr√™t¬∑e pour les cas d‚Äôutilisations plus cons√©quents ci-dessous. Il y en a trois. Chacun illustre une mani√®re diff√©rente d‚Äôutiliser la puissance des GADTs. Le premier traite de l‚Äôexpression d‚Äôeffets, ce qui est tr√®s largement utilis√© dans chaque monade IO populaire ou effets alg√©briques. Ne vous inqui√©tez pas de ne pas savoir ce que sont ces derniers, cette section l‚Äôexpliquera. Le second s‚Äôattache √† montrer comment garantir des propri√©t√©s dans le syst√®me de types. Ce point est illustr√© √† travers l‚Äôexemple de l‚Äôaccommodation des techniques issues de la programmation fonctionnelle aux contraintes issues des bases de donn√©es. Le troisi√®me offre une mani√®re plus simple de travailler avec des implicites.\nCas d‚ÄôUtilisation: Les Effets! Ce qui est appel√© un effet est parfois juste une interface d√©clarant quelques fonctions d√©pourvues d‚Äôimpl√©mentation. Par exemple nous pouvons d√©finir le trait ci-dessous. Notez qu‚Äôaucune de ces fonctions n‚Äôa d‚Äôimpl√©mentation.\ntrait ExampleEffectSig { def echo[A](value: A): A def randomInt : Int def ignore[A](value: A): Unit } Les impl√©mentations de ces interfaces (traits) sont donn√©es ailleurs, et il peut en avoir beaucoup! Cela est utile quand il est d√©sirable de changer facilement d‚Äôimpl√©mentation:\nobject ExampleEffectImpl extends ExampleEffectSig { def echo[A](value: A): A = value def randomInt : Int = scala.util.Random.nextInt() def ignore[A](value: A): Unit = () } Une mani√®re √©quivalente de d√©finir ExampleEffectSig est via un sealed trait muni de quelques final case class (peut-√™tre aucune!) et/ou quelques case object (peut-√™tre aucun!):\nsealed trait ExampleEffect[A] final case class Echo[A](value: A) extends ExampleEffect[A] final case object RandomInt extends ExampleEffect[Int] final case class Ignore[A](value: A) extends ExampleEffect[Unit] De nouveau, nous avons des d√©clarations ne fournissant aucune impl√©mentation! De nouveau, leurs impl√©mentations peuvent √™tre fournies ailleurs et il peut en avoir beaucoup:\ndef runExampleEffect[A](effect: ExampleEffect[A]): A = effect match { case Echo(value) =\u003e value case RandomInt =\u003e scala.util.Random.nextInt() case Ignore(_) =\u003e () } Prenons un effet plus r√©aliste ainsi qu‚Äôune de ses impl√©mentations possibles:\ntrait EffectSig { def currentTimeMillis: Long def printLn(msg: String): Unit def mesure[X,A](fun: X =\u003e A, arg: X): A } object EffectImpl extends EffectSig { def currentTimeMillis: Long = System.currentTimeMillis() def printLn(msg: String): Unit = println(msg) def mesure[X,A](fun: X =\u003e A, arg: X): A = { val t0 = System.currentTimeMillis() val r = fun(arg) val t1 = System.currentTimeMillis() println(s\"Took ${t1 - t0} milli-seconds\") r } } Question 1: Tout comme ExampleEffect est l‚Äô√©quivalent de ExampleEffectSig via la d√©finition d‚Äôun sealed trait muni de quelques final case class et case object, √©crivez l‚Äô√©quivalent de EffectSig de la m√™me mani√®re. Appelez ce trait Effect.\nSolution (cliquer pour d√©voiler) sealed trait Effect[A] final case object CurrentTimeMillis extends Effect[Long] final case class PrintLn(msg: String) extends Effect[Unit] final case class Mesure[X,A](fun: X =\u003e A, arg: X) extends Effect[A] Question 2: √âcrivez la fonction def run[A](effect: Effect[A]): A qui reproduit l‚Äôimpl√©mentation de EffectImpl tout comme runExampleEffect reproduit celle de ExampleEffectImpl.\nSolution (cliquer pour d√©voiler) def run[A](effect: Effect[A]): A = effect match { case CurrentTimeMillis =\u003e System.currentTimeMillis() case PrintLn(msg) =\u003e println(msg) case Mesure(fun, arg) =\u003e val t0 = System.currentTimeMillis() val r = fun(arg) val t1 = System.currentTimeMillis() println(s\"Took ${t1 - t0} milli-seconds\") r } Le type Effect[A] d√©clare des effets int√©ressants (CurrentTimeMillis, PrintLn et Mesure) mais pour √™tre r√©ellement utile, il doit √™tre possible de cha√Æner ces effets! Pour ce faire, nous voulons pouvoir disposer des deux fonctions suivantes:\ndef pure[A](value: A): Effect[A] def flatMap[X,A](fx: Effect[X], f: X =\u003e Effect[A]): Effect[A] De nouveau, nous ne nous int√©ressons pas √† leurs impl√©mentations. Tout ce que nous voulons, pour le moment, est d√©clarer ces deux op√©rations de la m√™me mani√®re que nous avons d√©clar√© CurrentTimeMillis, PrintLn et Mesure.\nQuestion 3: Ajoutez deux final case classes, Pure et FlatMap, √† Effect[A] d√©clarant ces deux op√©rations.\nSolution (cliquer pour d√©voiler) sealed trait Effect[A] final case object CurrentTimeMillis extends Effect[Long] final case class PrintLn(msg: String) extends Effect[Unit] final case class Mesure[X,A](fun: X =\u003e A, arg: X) extends Effect[A] final case class Pure[A](value: A) extends Effect[A] final case class FlatMap[X,A](fx: Effect[X], f: X =\u003e Effect[A]) extends Effect[A] Question 4: Adaptez la fonction run pour g√©rer ces deux nouveaux cas.\nSolution (cliquer pour d√©voiler) def run[A](effect: Effect[A]): A = effect match { case CurrentTimeMillis =\u003e System.currentTimeMillis() case PrintLn(msg) =\u003e println(msg) case Mesure(fun, arg) =\u003e val t0 = System.currentTimeMillis() val r = fun(arg) val t1 = System.currentTimeMillis() println(s\"Took ${t1 - t0} milli-seconds\") r case Pure(a) =\u003e a case FlatMap(fx, f) =\u003e val x = run(fx) val fa : Effect[A] = f(x) run(fa) } Question 5: Ajoutez les deux m√©thodes suivantes au trait Effect[A] pour obtenir:\nsealed trait Effect[A] { final def flatMap[B](f: A =\u003e Effect[B]): Effect[B] = FlatMap(this, f) final def map[B](f: A =\u003e B): Effect[B] = flatMap[B]((a:A) =\u003e Pure(f(a))) } Et ex√©cutez le code suivant pour voir s‚Äôil fonctionne:\nval effect1: Effect[Unit] = for { t0 \u003c- CurrentTimeMillis _ \u003c- PrintLn(s\"The current time is $t0\") } yield () run(effect1) Solution (cliquer pour d√©voiler) sealed trait Effect[A] { final def flatMap[B](f: A =\u003e Effect[B]): Effect[B] = FlatMap(this, f) final def map[B](f: A =\u003e B): Effect[B] = flatMap[B]((a:A) =\u003e Pure(f(a))) } final case object CurrentTimeMillis extends Effect[Long] final case class PrintLn(msg: String) extends Effect[Unit] final case class Mesure[X,A](fun: X =\u003e A, arg: X) extends Effect[A] final case class Pure[A](value: A) extends Effect[A] final case class FlatMap[X,A](fx: Effect[X], f: X =\u003e Effect[A]) extends Effect[A] def run[A](effect: Effect[A]): A = effect match { case CurrentTimeMillis =\u003e System.currentTimeMillis() case PrintLn(msg) =\u003e println(msg) case Mesure(fun, arg) =\u003e val t0 = System.currentTimeMillis() val r = fun(arg) val t1 = System.currentTimeMillis() println(s\"Took ${t1 - t0} milli-seconds\") r case Pure(a) =\u003e a case FlatMap(fx, f) =\u003e val x = run(fx) val fa : Effect[A] = f(x) run(fa) } val effect1: Effect[Unit] = for { t0 \u003c- CurrentTimeMillis _ \u003c- PrintLn(s\"The current time is $t0\") } yield () En ex√©cutant run(effect1) on obtient:\nscala\u003e run(effect1) The current time is 1569773175010 F√©licitations! Vous venez d‚Äô√©crire votre premi√®re monade IO! Il y a de nombreux noms scientifiques au sealed trait Effect[A]: vous pouvez l‚Äôappeler un effet alg√©brique, une monade libre, une IO, etc. Mais au bout du compte, ce n‚Äôest qu‚Äôun simple et banal sealed trait pour lequel nous avons d√©fini quelques final case class et case object afin de repr√©senter les fonctions dont nous voulions disposer sans fournir leurs impl√©mentations (CurrentTimeMillis, PrintLn, Mesure, Pure et FlatMap). Vous pouvez les appeler des m√©thodes virtuelles si vous voulez. Ce qui importe r√©ellement est d‚Äôavoir isol√© la d√©finition de ces fonctions de leurs impl√©mentations. Rappelez vous qu‚Äôun trait est juste une interface apr√®s tout.\nCas d‚ÄôUtilisation: S‚Äôassurer que les types sont pris en charge par la Base De Donn√©es. Les bases de donn√©es sont formidables. Nous pouvons y stocker des tables, des documents, des paires clef/valeur, des graphes, etc. Mais, pour n‚Äôimporte quelle base de donn√©es, il y a malheureusement seulement un nombre limit√© de types pris en charge. Prenez la base de donn√©es que vous voulez, je suis s√ªr de pouvoir trouver des types qu‚Äôelle ne prend pas en charge.\nDans cette section, nous allons nous int√©resser au cas des structures des donn√©es et du code qui ne marche pas pour tout les types, mais seulement certains! Ce cas d‚Äôusage ne se limite pas aux bases de donn√©es mais concerne chaque interface de programmation qui ne supporte qu‚Äôun nombre limit√© de types (la vaste majorit√© des interfaces de programmation). Comment s‚Äôassurer du respect de ces contraintes? Comment adapter les techniques que nous aimons afin qu‚Äôelles travaillent sous ces contraintes? Voil√† ce dont il s‚Äôagit dans cette section.\nNous consid√©rerons une base de donn√©es fictive qui ne prend en charge que les types suivants:\nString Double (A,B) o√π A et B sont √©galement des types pris en charge par la base de donn√©es. Cela signifie que les valeurs stock√©es dans la base de donn√©es (dans des tables, des paires clef/valeur, etc) doivent respecter les r√®gles ci-dessus. Elle peut stocker \"Hello World\" parce que c‚Äôest une String, qui est est un type pris en charge par la base de donn√©es en vertu de la r√®gle 1. Pour les m√™mes raisons, elle peut stocker 5.2 parce que c‚Äôest un Double, mais elle ne peut pas stocker l‚Äôentier 5 parce que c‚Äôest unInt. Elle peut stocker (\"Hello World\", 5.2) gr√¢ce √† la r√®gle 3 ainsi que ((\"Hello World\", 5.2) , 8.9), de nouveau gr√¢ce √† la r√®gle 3.\nQuestion 1: D√©finissez le type DBType[A] tel que:\nIl existe une valeur de type DBType[A] si et seulement si A est un type pris en charge par la base de donn√©es.\nSolution (cliquer pour d√©voiler) La version simple est:\nsealed trait DBType[A] final case object DBString extends DBType[String] final case object DBDouble extends DBType[Double] final case class DBPair[A,B](first: DBType[A], second: DBType[B]) extends DBType[(A,B)] Remarque pour les personnes √† l'aise en Scala (cliquer pour d√©voiler) En utilisant toutes les chouettes fonctionnalit√©s syntaxiques de Scala, la version satisfaisante en production du code ci-dessus est:\nsealed trait DBType[A] object DBType { final case object DBString extends DBType[String] final case object DBDouble extends DBType[Double] final case class DBPair[A,B](first: DBType[A], second: DBType[B]) extends DBType[(A,B)] implicit val dbString : DBType[String] = DBString implicit val dbDouble : DBType[Double] = DBDouble implicit def dbPair[A,B](implicit first: DBType[A], second: DBType[B]): DBType[(A,B)] = DBPair(first, second) def apply[A](implicit ev: DBType[A]): ev.type = ev } En utilisant DBType, nous pouvons coupler une valeur de type A avec une valeur de type DBType[A], fournissant ainsi la preuve que le type A est pris en charge par la base de donn√©es:\nfinal case class DBValue[A](value: A)(implicit val dbType: DBType[A]) Notez que le param√®tre dbType n‚Äôa nullement besoin d‚Äô√™tre implicite! Ce qui compte est que pour cr√©er une valeur de type DBValue[A], nous devons fournir une valeur de type DBType[A] ce qui force A √† √™tre un type pris en charge par la base de donn√©es.\nUn foncteur est, de mani√®re informelle et approximative, un constructeur de typeF, comme List, Option, DBValue, etc, pour lequel il est possible de fournir une instance du trait:\ntrait Functor[F[_]] { def map[A,B](fa: F[A])(f: A =\u003e B): F[B] } o√π map(fa)(f) applique la fonction f √† chaque valeur de type A contenue dans fa. Par exemple:\nimplicit object OptionFunctor extends Functor[Option] { def map[A,B](fa: Option[A])(f: A =\u003e B): Option[B] = fa match { case Some(a) =\u003e Some(f(a)) case None =\u003e None } } Question 2: √âcrivez une instance de Functor[DBValue].\nSolution (cliquer pour d√©voiler) C‚Äôest en fait impossible! Si nous tentions de compiler le code suivant:\nobject DBValueFunctor extends Functor[DBValue] { def map[A,B](fa: DBValue[A])(f: A =\u003e B): DBValue[B] = DBValue[B](f(fa.value)) } Scala r√¢lerait: could not find implicit value for parameter dbType: DBType[B]. En effet, les bool√©ens ne sont pas un type pris en charge par la base de donn√©es: ils ne sont ni des cha√Ænes de caract√®res, ni des nombres flottants, ni des paires de types pris en charge.\nSupposons que nous puissions d√©finir une instance de Funcor pour DBValue (c.-√†-d. que nous puissions d√©finir une fonction map pour DBValue), alors nous pourrions √©crire:\nval dbValueString : DBValue[String] = DBValue(\"A\")(DBString) val dbValueBoolean : DBValue[Boolean] = dbValueString.map(_ =\u003e true) val dbTypeBoooean : DBType[Boolean] = dbValueBoolean.dbType Nous obtiendrions une valeur (dbTypeBoooean) de type DBType[Boolean] ce qui signifirait que le type Boolean est pris en charge par la base de donn√©es. Mais il ne l‚Äôest pas! Hors par d√©finition:\nIl existe une valeur de type DBType[A] si et seulement si A est un type pris en charge par la base de donn√©e.\nDonc il est impossible d‚Äôobtenir une valeur de type DBType[Boolean] et donc il est impossible d‚Äô√©crire une fonction map pout DBValue. Ainsi il n‚Äôy a aucun moyen de d√©finir une instance de Functor pour DBValue. CQDF.\nUn Foncteur G√©n√©ralis√© est tr√®s similaire √† un Functor classique, √† la diff√©rence pr√®s que la fonction map ne doit pas obligatoirement √™tre applicable √† n‚Äôimporte quels types A et B mais peut n‚Äô√™tre applicable qu‚Äô√† certains types A et B particuliers:\ntrait GenFunctor[P[_],F[_]] { def map[A,B](fa: F[A])(f: A =\u003e B)(implicit evA: P[A], evB: P[B]): F[B] } Par exemple, Set (plus pr√©cis√©ment TreeSet) n‚Äôest pas un foncteur! En effet il n‚Äôy a aucun moyen d‚Äô√©crire une fonction map qui fonctionne pour n‚Äôimporte quel type B (parce qu‚Äôil est n√©cessaire d‚Äôavoir une relation d‚Äôordre sur B). Mais si l‚Äôon restreint map aux seuls types B disposant d‚Äôune relation d‚Äôordre, alors il devient possible d‚Äô√©crire:\nimport scala.collection.immutable._ object TreeSetFunctor extends GenFunctor[Ordering, TreeSet] { def map[A,B](fa: TreeSet[A])(f: A =\u003e B)(implicit evA: Ordering[A], evB: Ordering[B]): TreeSet[B] = TreeSet.empty[B](evB) ++ fa.toSeq.map(f) } Question 3: √âcrivez une instance de GenFunctor[DBType, DBValue].\nSolution (cliquer pour d√©voiler) object DBValueGenFunctor extends GenFunctor[DBType, DBValue] { def map[A,B](fa: DBValue[A])(f: A =\u003e B)(implicit evA: DBType[A], evB: DBType[B]): DBValue[B] = DBValue[B](f(fa.value))(evB) } Ce que nous avons fait ici avec Functor peut √™tre fait avec de nombreuses structures de donn√©es et techniques de programmation. Il est souvent possible de restreindre la plage des types sur lesquels la structure de donn√©e ou la classe de types (type class) peut op√©rer en ajoutant un param√®tre suppl√©mentaire comme ev : DBType[A] aux constructeurs et m√©thodes.\nCas d‚ÄôUtilisation: Simplifier les Implicites Ce cas d‚Äôutilisation est l‚Äôun des plus int√©ressants, mais malheureusement, pas l‚Äôun des plus simples. Il montre comment il est possible d‚Äôutiliser les GADTs pour simplifier la cr√©ation de valeurs implicites.\nDes listes de valeurs dont les √©l√©ments peuvent √™tre de types diff√©rents sont appel√©es listes h√©t√©rog√®nes. Elles sont g√©n√©ralement d√©finies en Scala presque comme les listes classiques:\nfinal case class HNil() // La liste vide final case class HCons[Head,Tail](head: Head, tail: Tail) // L'operation: `head :: tail` val empty : HNil = HNil() val oneTrueToto : HCons[Int, HCons[Boolean, HCons[String, HNil]]] = HCons(1, HCons(true, HCons(\"toto\", HNil()))) val falseTrueFive: HCons[Boolean, HCons[Boolean, HCons[Int, HNil]]] = HCons(false, HCons(true, HCons(5, HNil()))) Comme vous pouvez le voir, il n‚Äôy a rien de vraiment sp√©cial √† propos de ces listes. Nous voulons d√©finir des relations d‚Äôordre sur les listes h√©t√©rog√®nes. Une relation d‚Äôordre est une fa√ßon de comparer deux valeurs (du m√™me type!): elles peuvent √™tres √©gales ou l‚Äôune peut √™tre strictement plus petite que l‚Äôautre. Une relation d‚Äôordre sur le type A peut se d√©finir en Scala comme une instance de Order[A] d√©fini comme suit:\ntrait Order[A] { // vrai si et seulement si a1 \u003c a2 def lesserThan(a1: A, a2: A): Boolean /* a1 et a2 sont √©gales si et seulement si aucune d'entre elles n'est strictement plus petite que l'autre */ final def areEqual(a1: A, a2: A): Boolean = !lesserThan(a1, a2) \u0026\u0026 !lesserThan(a2, a1) // a1 \u003e a2 si et seulement si a2 \u003c a1 final def greaterThan(a1: A, a2: A): Boolean = lesserThan(a2, a1) final def lesserThanOrEqual(a1: A, a2: A): Boolean = !lesserThan(a2, a1) final def greaterThanOrEqual(a1: A, a2: A): Boolean = !lesserThan(a1, a2) } object Order { def apply[A](implicit ev: Order[A]): ev.type = ev def make[A](lg_ : (A,A) =\u003e Boolean): Order[A] = new Order[A] { def lesserThan(a1: A, a2: A): Boolean = lg_(a1,a2) } } implicit val orderInt = Order.make[Int](_ \u003c _) implicit val orderString = Order.make[String](_ \u003c _) Pour rappel, nous ne comparerons que des listes de m√™me type:\nLes listes de type HNil seront uniquement compar√©es √† d‚Äôautres listes de type HNil. Les listes de type HCons[H,T] seront uniquement compar√©es √† d‚Äôautres listes de type HCons[H,T]. Comparer des listes de type HNil est trivial parce qu‚Äôil n‚Äôy a qu‚Äôune seule et unique valeur de type HNil (la liste vide HNil()). Mais il existe de nombreuses fa√ßon de comparer des listes de type HCons[H,T]. Voici deux relations d‚Äôordre possibles (il en existe de nombreuses autres!):\nL‚Äôordre lexicographique (c.-√†-d. l‚Äôordre du dictionnaire: de la gauche vers la droite)\nHCons(h1,t1) \u003c HCons(h2,t2) si et seulement si h1 \u003c h2 ou (h1 == h2 et t1 \u003c t2 par l‚Äôordre lexicographique).\nsealed trait Lex[A] { val order : Order[A] } object Lex { def apply[A](implicit ev: Lex[A]): ev.type = ev implicit val lexHNil: Lex[HNil] = new Lex[HNil] { val order = Order.make[HNil]((_,_) =\u003e false) } implicit def lexHCons[Head,Tail](implicit orderHead: Order[Head], lexTail: Lex[Tail] ): Lex[HCons[Head, Tail]] = new Lex[HCons[Head, Tail]] { val orderTail: Order[Tail] = lexTail.order val order = Order.make[HCons[Head, Tail]] { case (HCons(h1,t1), HCons(h2,t2)) =\u003e orderHead.lesserThan(h1,h2) || (orderHead.areEqual(h1,h2) \u0026\u0026 orderTail.lesserThan(t1,t2)) } } } L‚Äôordre lexicographique invers√© qui est la version √† l‚Äôenvers de l‚Äôordre lexicographique (c.-√†-d. de droite √† gauche)\nHCons(h1,t1) \u003c HCons(h2,t2) si et seulement si (t1 \u003c t2 par ordre lexicographique invers√©) ou (t1 == t2 et h1 \u003c h2).\nsealed trait RevLex[A] { val order : Order[A] } object RevLex { def apply[A](implicit ev: RevLex[A]): ev.type = ev implicit val revLexHNil: RevLex[HNil] = new RevLex[HNil] { val order = Order.make[HNil]((_,_) =\u003e false) } implicit def revLexHCons[Head,Tail](implicit orderHead: Order[Head], revLexTail: RevLex[Tail] ): RevLex[HCons[Head, Tail]] = new RevLex[HCons[Head, Tail]] { val orderTail: Order[Tail] = revLexTail.order val order = Order.make[HCons[Head, Tail]] { case (HCons(h1,t1), HCons(h2,t2)) =\u003e orderTail.lesserThan(t1,t2) || (orderTail.areEqual(t1,t2) \u0026\u0026 orderHead.lesserThan(h1,h2)) } } } Comme dit plus haut, il est possible de d√©finir davantage de relations d‚Äôordre:\nQuestion 1: L‚Äôordre Alternate est d√©fini par:\nHCons(h1,t1) \u003c HCons(h2,t2) si et seulement si h1 \u003c h2 ou (h1 == h2 et t1 \u003e t2 par ordre Alternate).\nEn suivant la m√©thoe employ√©e pour Lex and RevLex, impl√©mentez l‚Äôordre Alternate.\nSolution (cliquer pour d√©voiler) sealed trait Alternate[A] { val order : Order[A] } object Alternate { def apply[A](implicit ev: Alternate[A]): ev.type = ev implicit val alternateHNil: Alternate[HNil] = new Alternate[HNil] { val order = Order.make[HNil]((_,_) =\u003e false) } implicit def alternateHCons[Head,Tail](implicit orderHead: Order[Head], alternateTail: Alternate[Tail] ): Alternate[HCons[Head, Tail]] = new Alternate[HCons[Head, Tail]] { val orderTail: Order[Tail] = alternateTail.order val order = Order.make[HCons[Head, Tail]] { case (HCons(h1,t1), HCons(h2,t2)) =\u003e orderHead.lesserThan(h1,h2) || (orderHead.areEqual(h1,h2) \u0026\u0026 orderTail.greaterThan(t1,t2)) } } } Il existe de nombreuses mani√®res de d√©finir une relation d‚Äôordre valide sur les listes h√©t√©rog√®nes! Cr√©er une classe de type (type class) comme Lex, RevLex et Alternate pour chaque relation d‚Äôordre voulue est fatigant et propice aux erreurs. Nous pouvons faire bien mieux ‚Ä¶ avec un GADT üòâ\nsealed trait HListOrder[A] object HListOrder { final case object HNilOrder extends HListOrder[HNil] final case class HConsOrder[Head,Tail]( orderHead: Order[Head], hlistOrderTail: HListOrder[Tail] ) extends HListOrder[HCons[Head,Tail]] // D√©finitions des Implicites implicit val hnilOrder : HListOrder[HNil] = HNilOrder implicit def hconsOrder[Head,Tail](implicit orderHead: Order[Head], hlistOrderTail: HListOrder[Tail] ): HListOrder[HCons[Head,Tail]] = HConsOrder(orderHead, hlistOrderTail) def apply[A](implicit ev: HListOrder[A]): ev.type = ev } Il est √† noter que la d√©finition de ces implicites est du pur boilerplate. Leur seule raison d‚Äô√™tre est de passer leurs arguments au constructeur correspondant (c.-√†-d. final case class ou case object): hnilOrder √† HListOrder (O arguments) et hconsOrder √† HConsOrder (2 arguments).\nQuestion 2: √âcrivez une fonction def lex[A](implicit v : HListOrder[A]): Order[A] qui retourne l‚Äôordre lexicographique √† partir d‚Äôune valeur de type HListOrder[A].\nSolution (cliquer pour d√©voiler) def lex[A](implicit v : HListOrder[A]): Order[A] = v match { case HListOrder.HNilOrder =\u003e Order.make[HNil]((_,_) =\u003e false) case hc : HListOrder.HConsOrder[head,tail] =\u003e val orderHead: Order[head] = hc.orderHead val orderTail: Order[tail] = lex(hc.hlistOrderTail) Order.make[HCons[head, tail]] { case (HCons(h1,t1), HCons(h2,t2)) =\u003e orderHead.lesserThan(h1,h2) || (orderHead.areEqual(h1,h2) \u0026\u0026 orderTail.lesserThan(t1,t2)) } } Question 3: √âcrivez une fonction def revLex[A](implicit v : HListOrder[A]): Order[A] qui retourne l‚Äôordre lexicographique invers√© √† partir d‚Äôune valeur de type HListOrder[A].\nSolution (cliquer pour d√©voiler) def revLex[A](implicit v : HListOrder[A]): Order[A] = v match { case HListOrder.HNilOrder =\u003e Order.make[HNil]((_,_) =\u003e false) case hc : HListOrder.HConsOrder[head,tail] =\u003e val orderHead: Order[head] = hc.orderHead val orderTail: Order[tail] = revLex(hc.hlistOrderTail) Order.make[HCons[head, tail]] { case (HCons(h1,t1), HCons(h2,t2)) =\u003e orderTail.lesserThan(t1,t2) || (orderTail.areEqual(t1,t2) \u0026\u0026 orderHead.lesserThan(h1,h2)) } } Cette approche a de nombreux avantages. Alors que l‚Äôapproche initiale devait effectuer une recherche d‚Äôimplicites pour chaque relation d‚Äôordre, l‚Äôapproche par GADT n‚Äôa besoin de faire cette recherche qu‚Äôune seule fois! Sachant que la r√©solution d‚Äôimplicites est une op√©ration gourmande, la r√©duire signifie des temps de compilation plus courts. Lire le code des fonctions lex et revLex est √©galement plus simple que comprendre comment la r√©solution d‚Äôimplicites fonctionne pour les traits Lex et RevLex. De plus, ce ne sont que des fonctions, vous pouvez y utiliser tout ce que vous pouvez programmer afin de construire les instances de Order[A].\nConclusion Pas si trivial, n‚Äôest-ce pas? üòâ En fait, une grande part de la complexit√© √† laquelle vous venez de faire face vient du triste fait que les techniques de raisonnements sur les types et valeurs ne sont presque jamais enseign√©es dans les cours de programmation. Ce que vous trouvez simple maintenant (API Web, Streaming, Bases De Donn√©es, etc) terrifierait probablement la/le jeune programmeuse¬∑eur que vous √©tiez √† votre premier ‚ÄúHello World!‚Äù. Vous n‚Äôavez probablement pas appris tout ce que vous savez en programmation en trois heures, donc n‚Äôattendez pas des techniques de raisonnement sur des programmes d‚Äô√™tres magiquement plus simples.\nCet atelier avait pour but de vous inspirer, d‚Äôouvrir votre esprit √† ce nouvel univers de possibilit√©s. Si vous trouvez ces cas d‚Äôutilisation int√©ressants, alors prenez le temps de comprendre les techniques.\nAmusez vous bien et prenez bien soin de vous ‚ù§Ô∏è",
    "description": "D√©couvrez les ADT g√©n√©ralis√©s en vous amusant.",
    "tags": [],
    "title": "Les GADTs Par l'Exemple",
    "uri": "/posts/les_gadts_par_l_exemple/index.html"
  },
  {
    "breadcrumb": "Posts",
    "content": "This workshop will be presented at ScalaIO 2019, in Lyon (France), on Tuesday the 29th of October at 9am.\nWelcome. This session will introduce you to a very powerful tool in programming. Whereas most introduction start by presenting its theoretical foundations in a very formal way, we chose to present it via short examples and practical use cases.\nThis workshop is made of three parts. The last one presents three of the most valuable use cases. They are the real big powerful use cases. But do not go there unprepared! This is the last part for a reason: they rely massively on lessons you will learn in the previous parts. Start by First Contact, it will show you, via the simplest examples, the core ideas. Its goal is to open your mind to ways of using types and data you may have never imagined possible. Then go to Easy Useful Use Cases: Relations on Types, for the first real-life challenge. Then, you are ready for More Advanced Use Cases.\nBe sure to read README, it contains precious tips to ease your journey.\nAcknowledgements We would like to thank Laure Juglaret for having reviewed this presentation many times, for her precious remarks and corrections.\nREADME In this presentation we will assume that:\nnull does not exists! runtime-reflection does not exist! (i.e. isInstanceOf, getClass, etc) This presentation considers that these features do not exists at all.\nUsing these features will never lead to a valid answer.\nThis presentation expects you to have access to something where you can easily write, compile and run Scala code. The best way to do so is opening a R.E.P.L. session. If you have Scala installed on your system, you can easily start one from the command-line by executing scala:\nsystem-command-line# scala Welcome to Scala 2.13.1 (OpenJDK 64-Bit Server VM, Java 1.8.0_222). Type in expressions for evaluation. Or try :help. scala\u003e Remember that the R.E.P.L command :paste allows to paste code and :reset cleans the environment.\nIf you don‚Äôt have Scala installed, you can use the online-REPL https://scastie.scala-lang.org/ .\nStretching This section is a brief reminder of some definitions and properties about values and types.\nValues and Types? Values are actual piece of data your program manipulates like the integer 5, the boolean true, the string \"Hello World!\", the function (x: Double) =\u003e x / 7.5, the list List(1,2,3), etc. It is convenient to classify values into groups. These groups are called types. For example:\nInt is the group of integer values, i.e. values like 1, -7, 19, etc. Boolean is the group containing exactly the values true and false (no more, no less!). String is the group whose values are \"Hello World!\", \"\", \"I ‚ù§Ô∏è GADTs\", etc. Double =\u003e Double is the group whose values are functions taking any Double as argument and returning some Double. To indicate that the value v belongs to the type (i.e. group of values) T, we write v : T. In Scala, testing if a value v belongs to a type T is very simple: just type v : T in the REPL:\nscala\u003e 5 : Int res7: Int = 5 If Scala accepts it, then v belongs to T. If Scala complains, it most probably does not :\nscala\u003e 5 : String ^ error: type mismatch; found : Int(5) required: String How many types? Let‚Äôs now create some types and some of their values (when possible!).\nclass OneType Question 1: How many types does the line class OneType defines?\nSolution (click to expand) As the name suggests, class OneType defines only one type which is named OneType.\nLet‚Äôs now consider:\nclass OneTypeForEvery[A] Question 2: How many types does the line class OneTypeForEvery[A] defines?\nSolution (click to expand) As the name suggests, every concrete type A gives rise to a distinct type OneTypeForEvery[A].\nFor example, a list of integers is neither a list of booleans, nor a list of strings, nor a list of functions, nor ‚Ä¶ It means the types List[Int], List[Boolean], List[Int =\u003e Int], etc are all distinct types.\nThe line class OneTypeForEvery[A] defines a distinct type for every concrete type A. There is an infnity of concrete types A, so an infinity of distinct types OneTypeForEvery[A].\nQuestion 3: Give a value that belongs to both OneTypeForEvery[Int] and OneTypeForEvery[Boolean].\nRemember that null does not exist!\nSolution (click to expand) This is actually impossible. Every concrete type A give rise a distinct type OneTypeForEvery[A] that have no values in common with others types OneTypeForEvery[B] for B ‚â† A.\nHow many values? Considering the following type:\nfinal abstract class NoValueForThisType Question 1: Give a value belonging to the type NoValueForThisType? How many values belong to NoValueForThisType?\nHint (click to expand) What is a final class? How does it differ from a normal non-final class? What is an abstract class? How does it differ from a concrete class? Solution (click to expand) The class NoValueForThisType is declared abstract. It is then forbidden to create a direct instance of this class:\nscala\u003e new NoValueForThisType ^ error: class NoValueForThisType is abstract; cannot be instantiated The only way to create an instance of an abstract class is creating a concrete sub-class. But the keyword final forbids creating such sub-classes:\nscala\u003e class ConcreteSubClass extends NoValueForThisType ^ error: illegal inheritance from final class NoValueForThisType There is no way to create an instance of NoValueForThisType.\nLet‚Äôs take another example:\nsealed trait ExactlyOneValue case object TheOnlyValue extends ExactlyOneValue Question 2: Give a value belonging to the type ExactlyOneValue?\nSolution (click to expand) By definition, TheOnlyValue is a value of type ExactlyOneValue.\nQuestion 3: How many values belong to ExactlyOneValue?\nSolution (click to expand) Just like above, ExactlyOneValue, being a trait, is abstract. Being sealed, extending it outside of its defining file is forbidden. So TheOnlyValue is the only value of type ExactlyOneValue.\nFirst Contact This part presents the core ideas. There are actually only two ideas! What you will find here are stripped down examples to illustrate each of these ideas.\nUse Case: Evidence of some property Let‚Äôs define a simple sealed trait:\nsealed trait ATrait[A] case object AValue extends ATrait[Char] Question 1: Give a value of type ATrait[Char].\nSolution (click to expand) By definition, AValue is a value of type ATrait[Char].\nQuestion 2: Give a value of type ATrait[Double].\nSolution (click to expand) There is no way to have an instance of type ATrait[Double]. There is actually no way to have an instance of type ATrait[B] for B ‚â† Char, because the only possible value is AValue which is of type ATrait[Char].\nQuestion 3: What can you conclude about a type A if you have a value ev of type ATrait[A] (i.e. ev: ATrait[A])?\nSolution (click to expand) The only possible value is AValue, so ev == AValue. Furthermore AValue is of type ATrait[Char] so A = Char.\nQuestion 4: In the REPL, enter the following code:\ndef f[A](x: A, ev: ATrait[A]): Char = x Question 5: Now try pattern matching on ev: ATrait[A]\ndef f[A](x: A, ev: ATrait[A]): Char = ev match { case AValue =\u003e x } Is the pattern matching exhaustive?\nSolution (click to expand) The pattern matching is exhaustive because the only possible actual value for ev is AValue. Furthermore AValue is of type ATrait[Char] which means ev : ATrait[Char] because ev == AValue. So A = Char and x : Char.\nQuestion 6: Call f with x = 'w' : Char.\nSolution (click to expand) scala\u003e f[Char]('w', AValue) res0: Char = w Question 7: Call f with x = 5.2 : Double.\nSolution (click to expand) This is impossible because it would require to give a value ev : ATrait[Double], which does not exist!\nscala\u003e f[Double](5, AValue) ^ error: type mismatch; found : AValue.type required: ATrait[Double] Remark for people fluent in Scala (click to expand) Using all the nice features of Scala, the production-ready version of the code above is:\nsealed trait IsChar[A] object IsChar { implicit case object Evidence extends IsChar[Char] def apply[A](implicit evidence: IsChar[A]): IsChar[A] = evidence } def f[A: IsChar](x: A): Char = IsChar[A] match { case IsChar.Evidence =\u003e x } Use Case: The only thing I know is it exists What would you do if you wanted your codebase to log messages, but you want to be sure your codebase do not rely on any implementation details of the logger, so that you can change its implementation without risking breaking the codebase?\nTake the following logger type UnknownLogger:\nsealed trait UnknownLogger final case class LogWith[X](logs : X, appendMessage: (X, String) =\u003e X) extends UnknownLogger The first logger we will create stores the logs in a String:\nval loggerStr : UnknownLogger = LogWith[String](\"\", (logs: String, message: String) =\u003e logs ++ message) The second logger stores them in a List[String]:\nval loggerList : UnknownLogger = LogWith[List[String]](Nil, (logs: List[String], message: String) =\u003e message :: logs) The third logger directly prints the messages to the standard output:\nval loggerStdout : UnknownLogger = LogWith[Unit]((), (logs: Unit, message: String) =\u003e println(message)) Note that these three loggers all have the same type (i.e. UnknownLogger) but they store the logs using different types X (String, List[String] and Unit).\nQuestion 1: Let v be a value of type UnknownLogger. Clearly v has to be an instance of the class LogWith[X] for some type X. What can you say about the type X? Can you figure out which type X actually is?\nRemember that we refuse to use runtime-reflection! (i.e. isInstanceOf, getClass, etc)\nSolution (click to expand) We know almost nothing about X. The only thing we know is there exists at least one value (v.logs) of type X. Appart from that, X can be any type.\nNot knowing which type is actually X is very useful to guarantee that the code that will use v : UnknownLogger will never rely on the nature of X. If the code knew X was String for example, it could perform some operations we want to forbid like reversing the list, taking only the nth first characters, etc. By hiding the real type X, we force our codebase to not depend on what X is but to use the provided v.appendMessage. So changing the real implementation of the logger won‚Äôt break any code.\nQuestion 2: Write the function def log(message: String, v: UnknownLogger): UnknownLogger that uses v.appendMessage to append message to v.logs and returns a new UnknownLogger containing the new logs.\nRemember that in Scala, the pattern case ac : AClass[t] =\u003e (see below) is allowed in match/case in replacement of the pattern case AClass(v) =\u003e:\nfinal case class AClass[A](value : A) def f[A](v: AClass[A]): A = v match { case ac : AClass[t] =\u003e // The variable `t` is a type variable // The type `t` is equal to `A` val r : t = ac.value r } Its main benefit is introducing the type variable t. Type variables work like normal pattern variables except that they represent types instead of values. Having t enable us to help the compiler by giving explicit types (like just above, saying r is of type t).\nSolution (click to expand) def log(message: String, v: UnknownLogger): UnknownLogger = v match { case vx : LogWith[x] =\u003e LogWith[x](vx.appendMessage(vx.logs, message), vx.appendMessage) } Question 3: Execute log(\"Hello World\", loggerStr) and log(\"Hello World\", loggerList) and log(\"Hello World\", loggerStdout)\nSolution (click to expand) scala\u003e log(\"Hello World\", loggerStr) res0: UnknownLogger = LogWith(Hello World,$$Lambda$988/1455466014@421ead7e) scala\u003e log(\"Hello World\", loggerList) res1: UnknownLogger = LogWith(List(Hello World),$$Lambda$989/1705282731@655621fd) scala\u003e log(\"Hello World\", loggerStdout) Hello World res2: UnknownLogger = LogWith((),$$Lambda$990/1835105031@340c57e0) Remark for people fluent in Scala (click to expand) Once again, using all the nice features of Scala, the production-ready version of the code above is:\nsealed trait UnknownLogger { type LogsType val logs : LogsType def appendMessage(presentLogs: LogsType, message: String): LogsType } object UnknownLogger { final case class LogWith[X](logs : X, appendMessage_ : (X, String) =\u003e X) extends UnknownLogger { type LogsType = X def appendMessage(presentLogs: LogsType, message: String): LogsType = appendMessage_(presentLogs, message) } def apply[X](logs: X, appendMessage: (X, String) =\u003e X): UnknownLogger = LogWith[X](logs, appendMessage) } Intermediary Conclusion GADTs are actually only this: simple sealed trait with some case object (possibly none) and some final case class (possible none too!). In the following parts we will explore some major use cases of GADTs\nEasy Useful Use Cases: Relations on Types One easy, but very useful, benefit of GADTs is expressing relations about types such that:\nIs type A equal to type B? Is type A a sub-type of B? Note that, by definition, a type A is a sub-type of itself (i.e. A \u003c: A), very much like an integer x is also lesser-than-or-equal to itself x ‚â§ x.\nUse Case: Witnessing Type Equality sealed trait EqT[A,B] final case class Evidence[X]() extends EqT[X,X] Question 1: Give a value of type EqT[Int, Int]\nSolution (click to expand) scala\u003e Evidence[Int]() : EqT[Int, Int] res0: EqT[Int,Int] = Evidence() Question 2: Give a value of type EqT[String, Int]\nSolution (click to expand) The class Evidence is the only concrete sub-class of trait EqT and we cannot create another one because EqT is sealed. So any value v : EqT[A,B] has to be an instance of Evidence[X] for some type X, which is of type EqT[X,X]. Thus there is no way to get a value of type EqT[String, Int].\nQuestion 3: Given two (unknown) types A and B. What can you conclude if I give you a value of type EqT[A,B]?\nSolution (click to expand) If I give you a value v : EqT[A,B], then you know that v is an instance of Evidence[X] for some (unknown) type X because the class Evidence is the only concrete sub-class of the sealed trait EqT. Actually Evidence[X] is a sub-type of EqT[X,X]. Thus v : EqT[X,X]. Types EqT[A,B] and EqT[X,X] have no value in common if A ‚â† X or B ‚â† X, so A = X and B = X. Thus A = B.\nRemark for people fluent in Scala (click to expand) In production, it is convenient to write the following equivalent code:\nsealed trait EqT[A,B] object EqT { final case class Evidence[X]() extends EqT[X,X] implicit def evidence[X] : EqT[X,X] = Evidence[X]() def apply[A,B](implicit ev: EqT[A,B]): ev.type = ev } Switching between equal types If A and B are actually the same type, then List[A] is also the same type as List[B], Option[A] is also the same type as Option[B], etc. More generally, for any F[_], F[A] is also the same type as F[B].\nQuestion 4: Write the function def coerce[F[_],A,B](eqT: EqT[A,B])(fa: F[A]): F[B].\nSolution (click to expand) def coerce[F[_],A,B](eqT: EqT[A,B])(fa: F[A]): F[B] = eqT match { case _ : Evidence[x] =\u003e fa } The Scala standard library already defines a class, named =:=[A,B] (yes, its name is really =:=), representing type equality. You‚Äôre strongly encouraged to have a quick look at its documentation (click here). Thankfully, Scala enables to write A =:= B instead of =:=[A,B].\nGiven two types A and B, having an instance (i.e. object) of A =:= B means that A and B are actually the same type, just like with EqT[A,B]. Remember that A =:= B is just syntactic sugar for =:=[A,B].\nInstances of A =:= B can be created by the function (\u003c:\u003c).refl[X]: X =:= X (click for docs). The ‚Äúsymbol‚Äù \u003c:\u003c is indeed a valid name for an object.\nQuestion 5: Using the function coerce above, write the function def toScalaEq[A,B](eqT: EqT[A,B]): A =:= B.\nHint (click to expand) def toScalaEq[A,B](eqT: EqT[A,B]): A =:= B = { /* Find a definition for: - the type constructor `F` - the value `fa : F[A]` */ type F[X] = ??? val fa : F[A] = ??? /* Such that this call: */ coerce[F,A,B](eqT)(fa) // is of type `F[B]` } Solution (click to expand) def toScalaEq[A,B](eqT: EqT[A,B]): A =:= B = { type F[X] = A =:= X val fa: F[A] = (\u003c:\u003c).refl[A] coerce[F,A,B](eqT)(fa) } Question 6: Using the method substituteCo[F[_]](ff: F[A]): F[B] of objects of class A =:= B, whose documentation is here, write the function def fromScalaEq[A,B](scala: A =:= B): EqT[A,B].\nHint (click to expand) def fromScalaEq[A,B](scala: A =:= B): EqT[A,B] = { /* Find a definition for: - the type constructor `F` - the value `fa : F[A]` */ type F[X] = ??? val fa : F[A] = ??? /* Such that this call: */ scala.substituteCo[F](fa) // is of type `F[B]` } Solution (click to expand) def fromScalaEq[A,B](scala: A =:= B): EqT[A,B] = { type F[X] = EqT[A,X] val fa: F[A] = Evidence[A]() scala.substituteCo[F](fa) } Use Case: Witnessing Sub Typing In this section, we want to create types SubTypeOf[A,B] whose values prove that the type A is a sub-type of B (i.e. A \u003c: B). A similar but different class already exists in the Scala library. It is named \u003c:\u003c[A,B], which is often written A \u003c:\u003c B. Its documentation is here. Because this section is about implementing a variant of this class, please do not use \u003c:\u003c[A,B] to implement SubTypeOf.\nQuestion 1: Using only upper bounds (i.e. A \u003c: B) or lower bounds (i.e. A \u003e: B) and no variance annotation (i.e. [+A] and [-A]), create the trait SubTypeOf[A,B] (and all that is necessary) such that:\nThere exists a value of type SubType[A,B] if and only if A is a sub-type of B (i.e. A \u003c: B).\nRemember that, by definition, a type A is a sub-type of itself (i.e. A \u003c: A).\nRemember that you should not use the class \u003c:\u003c[A,B].\nSolution (click to expand) sealed trait SubTypeOf[A,B] final case class SubTypeEvidence[A \u003c: B, B]() extends SubTypeOf[A,B] Remark for people fluent in Scala (click to expand) In production, it is convenient to write the following equivalent code:\nsealed trait SubTypeOf[A,B] object SubTypeOf { final case class Evidence[A \u003c: B, B]() extends SubTypeOf[A,B] implicit def evidence[A \u003c: B, B]: SubTypeOf[A,B] = Evidence[A,B]() def apply[A,B](implicit ev: SubTypeOf[A,B]): ev.type = ev } Use Case: Avoiding annoying scalac error messages about bounds not respected In this example, we want to model the diet of some animals. We start by defining the Food type and some of its subtypes:\ntrait Food class Vegetable extends Food class Fruit extends Food and then the class representing animals eating food of type A (i.e. Vegetable, Fruit, etc):\nclass AnimalEating[A \u003c: Food] val elephant : AnimalEating[Vegetable] = new AnimalEating[Vegetable] Let‚Äôs define a function like there are so many in Functional Programming, and apply it to elephant:\ndef dummy[F[_],A](fa: F[A]): String = \"Ok!\" scala\u003e dummy[List, Int](List(1,2,3)) res0: String = Ok! scala\u003e dummy[Option, Boolean](Some(true)) res1: String = Ok! scala\u003e dummy[AnimalEating, Vegetable](elephant) ^ error: kinds of the type arguments (AnimalEating,Vegetable) do not conform to the expected kinds of the type parameters (type F,type A). AnimalEating's type parameters do not match type F's expected parameters: type A's bounds \u003c: Food are stricter than type _'s declared bounds \u003e: Nothing \u003c: Any Question 1: Why does scalac complains?\nSolution (click to expand) The function dummy requires its argument F, which is a type constructor like List, Option, Future, etc, to accept any type as argument so that we can write F[A] for any type A. On the contrary, AnimalEating requires its argument to be a sub-type of Food. Thus AnimalEating can not be used as dummy‚Äôs argument F.\nThe problem is that, when we defined class AnimalEating[A \u003c: Food], we gave the restriction that A \u003c: Food. So Scala, like Java, forbids us to give AnimalEating anything but a sub-type of Food (including Food itself):\nscala\u003e type T1 = AnimalEating[Int] ^ error: type arguments [Int] do not conform to class AnimalEating's type parameter bounds [A \u003c: Food] scala\u003e type T2 = AnimalEating[Food] defined type alias T2 We face a dilemma: to use the function dummy, that we really want to use because it‚Äôs a very nice function, we need to remove the constraint A \u003c: Food from the definition class AnimalEating[A \u003c: Food]. But we still want to say that animals eat food, not integers, boolean or strings!\nQuestion 2: How can you adapt the definition of AnimalEating so that:\nWe can call dummy on elephant! We want:\nscala\u003e dummy[AnimalEating, Vegetable](elephant) res0: String = Ok! If A is not a sub-type of Food (including Food itself), then it is impossible to create an instance of AnimalEating[A].\nThe class AnimalEating must remain an open class (i.e. neither sealed nor final)! It should be possible for anyone, anywhen, to create, freely, sub-classes of AnimalEating. Obviously those sub-classes must satisfy the constraints above.\nHint (click to expand) In Scala, Nothing is a type having no value. Can you create a value of type (Nothing, Int)? Why?\nSolution (click to expand) If, to create an instance of AnimalEating[A], we force every creation method to take an extra paramerer of type SubTypeOf[A, Food], then it will only be possible to create an instance of AnimalEating[A] when A is a sub-type of Food:\nclass AnimalEating[A](ev : SubTypeOf[A, Food]) val elephant : AnimalEating[Vegetable] = new AnimalEating[Vegetable](SubTypeEvidence[Vegetable, Food]) To create a value of type AnimalEating[A], we need to call AnimalEating‚Äôs constructor. And to call this constructor, we need to provide ev : SubTypeOf[A, Food].\nNow we can apply the dummy function on elephant:\nscala\u003e dummy[AnimalEating, Vegetable](elephant) res0: String = Ok! In practice, using implicits, we let the compiler fill the parameter ev : SubTypeOf[A, Food] itself.\nNote that you can now express the type AnimalEating[Int] but you won‚Äôt be able to create a value of this type.\nUse Case: Give the right data to the right chart This use case is about enforcing at compile-time that only values of the right type can be given to a function. In this example, we consider the design of a chart library. For simplicity‚Äôs sake, we will assume that our library only supports two kinds of charts: Pie charts and XY charts. This is written in Scala via the enumeration:\nsealed trait ChartType case object PieChart extends ChartType case object XYChart extends ChartType Obviously Pie and XY charts rely on different kinds of data. Once again for simplicity‚Äôs sake, we will assume that our two kinds of data are:\nclass PieData class XYData A pie chart (PieChart) plots only PieData, whereas an XY chart (XYChart) plots only XYData. Here is our drawing function draw:\ndef draw[A](chartType: ChartType)(data: A): Unit = chartType match { case PieChart =\u003e val pieData = data.asInstanceOf[PieData] // Do some stuff to draw pieData () case XYChart =\u003e val xyData = data.asInstanceOf[XYData] // Do some stuff to draw xyData () } It assumes that the user will only call draw on the right data. When chartType is PieChart, the function assumes, via data.asInstanceOf[PieData] that data is actually of type PieData. And when chartType is XYChart, it assumes that data is actually of type XYData.\nThe problem is that these assumptions rely on the hypothesis that users and developers will always make sure they are calling draw on the right data type. But nothing stops someone to call draw on a PieChart with XYData (or the opposite), crashing the system miserably at runtime!\nscala\u003e draw(PieChart)(new XYData) java.lang.ClassCastException: XYData cannot be cast to PieData at .draw(\u003cpastie\u003e:11) ... 28 elided As developers, we know mistakes do happen! We want a way to prevent theses annoying bugs to happen in production! We want to enforce at compile-time that only these two scenarii are possible:\nWhen draw is called with chartType == PieChart: the argument data can only be of type PieData When draw is called with chartType == XYChart: the argument data can only be of type XYData. Remember that these two constraints have to be enforced at compile-time!\nQuestion 1: Adapt the definition of ChartType, PieChart, XYChart and draw such that:\nAny scenario other than the two above will make the compilation fail on a type error.\nChartType must still be a sealed trait. It is now allowed to have type parameters (i.e. generics).\nPieChart and XYChar must still be two case object. They should still extends ChartType.\nChartType, PieChart and XYChar declarations must have no body at all (i.e. there should be no brackets { ... } in their declaration).\nHint (click to expand) The code looks like this:\nsealed trait ChartType[/*PUT SOME GENERICS HERE*/] case object PieChart extends ChartType[/*There is something to write here*/] case object XYChart extends ChartType[/*There is something to write here too*/] def draw[A](chartType: ChartType[/*Write something here*/])(data: A): Unit = chartType match { case PieChart =\u003e val pieData : PieData = data () case XYChart =\u003e val xyData: XYData = data () } Solution (click to expand) sealed trait ChartType[A] case object PieChart extends ChartType[PieData] case object XYChart extends ChartType[XYData] def draw[A](chartType: ChartType[A])(data: A): Unit = chartType match { case PieChart =\u003e val pieData : PieData = data () case XYChart =\u003e val xyData: XYData = data () } You can now sleep well knowing your production will not crash because of some bad inputs here üòâ\nMore Advanced Use Cases Now that you have seen what GADTs are about and how to use them in real-life, you are ready for the big use cases below. There are three of them. Each one illustrates one different way to use the power of GADTs. The first one is about expressing effects, which is widely used in every popular IO monads or algebraic effects. Do not worry if you do not know what they are, the section will clarifies it. The second one is about enforcing properties. This point is illustrated by the real-life use-case of enabling functional programming techniques support constructions that only work for a limited set of types (in the example, types supported by our fictional database). The third one is about simplifying the creation of implicits.\nUse Case: Effects! What we call an effect is sometimes just an interface declaring some functions with no implementation. For example we can define the trait below. Note that none of its functions has an implementation.\ntrait ExampleEffectSig { def echo[A](value: A): A def randomInt : Int def ignore[A](value: A): Unit } Implementations of these interfaces are given elsewhere and there can be many of them! This is useful to switch between implementations easily:\nobject ExampleEffectImpl extends ExampleEffectSig { def echo[A](value: A): A = value def randomInt : Int = scala.util.Random.nextInt() def ignore[A](value: A): Unit = () } Another equivalent way to define ExampleEffectSig is via a sealed trait with some final case class (possibly none!) and/or somecase object (possibly none too!):\nsealed trait ExampleEffect[A] final case class Echo[A](value: A) extends ExampleEffect[A] final case object RandomInt extends ExampleEffect[Int] final case class Ignore[A](value: A) extends ExampleEffect[Unit] Once again this is a declaration with no implementation! Once again implementations can be written elsewhere and there can also be many of them:\ndef runExampleEffect[A](effect: ExampleEffect[A]): A = effect match { case Echo(value) =\u003e value case RandomInt =\u003e scala.util.Random.nextInt() case Ignore(_) =\u003e () } Let‚Äôs consider a more realistic effect and one possible implementation:\ntrait EffectSig { def currentTimeMillis: Long def printLn(msg: String): Unit def mesure[X,A](fun: X =\u003e A, arg: X): A } object EffectImpl extends EffectSig { def currentTimeMillis: Long = System.currentTimeMillis() def printLn(msg: String): Unit = println(msg) def mesure[X,A](fun: X =\u003e A, arg: X): A = { val t0 = System.currentTimeMillis() val r = fun(arg) val t1 = System.currentTimeMillis() println(s\"Took ${t1 - t0} milli-seconds\") r } } Question 1: ExampleEffect is the equivalent of ExampleEffectSig, but using a sealed trait with some final case class and case object. Write the equivalent of EffectSig in the same way. Call this trait Effect.\nSolution (click to expand) sealed trait Effect[A] final case object CurrentTimeMillis extends Effect[Long] final case class PrintLn(msg: String) extends Effect[Unit] final case class Mesure[X,A](fun: X =\u003e A, arg: X) extends Effect[A] Question 2: Write the function def run[A](effect: Effect[A]): A that mimics the implementation of EffectImpl just like runExampleEffect mimics ExampleEffectImpl.\nSolution (click to expand) def run[A](effect: Effect[A]): A = effect match { case CurrentTimeMillis =\u003e System.currentTimeMillis() case PrintLn(msg) =\u003e println(msg) case Mesure(fun, arg) =\u003e val t0 = System.currentTimeMillis() val r = fun(arg) val t1 = System.currentTimeMillis() println(s\"Took ${t1 - t0} milli-seconds\") r } The type Effect[A] declares interesting effects (CurrentTimeMillis, PrintLn and Mesure) but to be really useful, we need to be able to chain effects! To do so, we want to have these two functions:\ndef pure[A](value: A): Effect[A] def flatMap[X,A](fx: Effect[X], f: X =\u003e Effect[A]): Effect[A] Once again we do not care yet about the implementation. Presently all we want is declaring these two operations, just like we declared CurrentTimeMillis, PrintLn and Mesure.\nQuestion 3: Add two final case classes, Pure and FlatMap, to Effect[A] declaring these operations.\nSolution (click to expand) sealed trait Effect[A] final case object CurrentTimeMillis extends Effect[Long] final case class PrintLn(msg: String) extends Effect[Unit] final case class Mesure[X,A](fun: X =\u003e A, arg: X) extends Effect[A] final case class Pure[A](value: A) extends Effect[A] final case class FlatMap[X,A](fx: Effect[X], f: X =\u003e Effect[A]) extends Effect[A] Question 4: Adapt the function run to handle these two new cases.\nSolution (click to expand) def run[A](effect: Effect[A]): A = effect match { case CurrentTimeMillis =\u003e System.currentTimeMillis() case PrintLn(msg) =\u003e println(msg) case Mesure(fun, arg) =\u003e val t0 = System.currentTimeMillis() val r = fun(arg) val t1 = System.currentTimeMillis() println(s\"Took ${t1 - t0} milli-seconds\") r case Pure(a) =\u003e a case FlatMap(fx, f) =\u003e val x = run(fx) val fa : Effect[A] = f(x) run(fa) } Question 5: Add the two following methods to trait Effect[A] to get:\nsealed trait Effect[A] { final def flatMap[B](f: A =\u003e Effect[B]): Effect[B] = FlatMap(this, f) final def map[B](f: A =\u003e B): Effect[B] = flatMap[B]((a:A) =\u003e Pure(f(a))) } And run the follwing code to see if it works:\nval effect1: Effect[Unit] = for { t0 \u003c- CurrentTimeMillis _ \u003c- PrintLn(s\"The current time is $t0\") } yield () run(effect1) Solution (click to expand) sealed trait Effect[A] { final def flatMap[B](f: A =\u003e Effect[B]): Effect[B] = FlatMap(this, f) final def map[B](f: A =\u003e B): Effect[B] = flatMap[B]((a:A) =\u003e Pure(f(a))) } final case object CurrentTimeMillis extends Effect[Long] final case class PrintLn(msg: String) extends Effect[Unit] final case class Mesure[X,A](fun: X =\u003e A, arg: X) extends Effect[A] final case class Pure[A](value: A) extends Effect[A] final case class FlatMap[X,A](fx: Effect[X], f: X =\u003e Effect[A]) extends Effect[A] def run[A](effect: Effect[A]): A = effect match { case CurrentTimeMillis =\u003e System.currentTimeMillis() case PrintLn(msg) =\u003e println(msg) case Mesure(fun, arg) =\u003e val t0 = System.currentTimeMillis() val r = fun(arg) val t1 = System.currentTimeMillis() println(s\"Took ${t1 - t0} milli-seconds\") r case Pure(a) =\u003e a case FlatMap(fx, f) =\u003e val x = run(fx) val fa : Effect[A] = f(x) run(fa) } val effect1: Effect[Unit] = for { t0 \u003c- CurrentTimeMillis _ \u003c- PrintLn(s\"The current time is $t0\") } yield () When we run run(effect1):\nscala\u003e run(effect1) The current time is 1569773175010 Congratulations! You just wrote your first IO monad! There is a lot of scientific words to name the sealed trait Effect[A]: you can call it an algebraic effect, a free monad, an IO, etc. But in the end, it is just a plain simple sealed trait with some final case class and case object that represent the functions we wanted to have, without providing their implementation (CurrentTimeMillis, PrintLn, Mesure, Pure and FlatMap). You can call them virtual methods if you like. What really matters is that we isolated the declaration of the functions from their implementation. Remember that a trait is just a interface after all.\nUse Case: Ensuring types are supported by the Database Databases are great. We can store tables, documents, key/values pairs, graphs, etc. But for any database, there is unfortunately only a limited set of supported types. Take a database you like, I am sure I can find some types it does not support.\nIn this section we consider the use case of data structures and code that do not work for (values of) any type but only for some! This problem is not limited to databases but concerns any API that only supports a limited set of types (the vast majority of APIs). How to enforce this constraint? How to adapt the patterns we like to work under this constraint? This is all this section is about.\nWe consider a fictional database that only supports the following types:\nString Double (A,B) where A and B are also types supported by the database. It means that the values stored by the database (in tables, key/value pairs, etc) must follow the rules above. It can store \"Hello World\" because it is a String which is a supported type by rule 1. Likewise, it can store 5.2 because it is a Double, but it can not store 5 : Int because it is an Int. It can store (\"Hello World\", 5.2) thanks to rule 3 and also ((\"Hello World\", 5.2) , 8.9) once again by rule 3.\nQuestion 1: Define the type DBType[A] such that:\nThere exists a value of type DBType[A] if and only if A is a type supported by the database.\nSolution (click to expand) Transposing the rules above in code, we get:\nsealed trait DBType[A] final case object DBString extends DBType[String] final case object DBDouble extends DBType[Double] final case class DBPair[A,B](first: DBType[A], second: DBType[B]) extends DBType[(A,B)] Remark for people fluent in Scala (click to expand) Using all the nice features of Scala, the production-ready version of the code above is:\nsealed trait DBType[A] object DBType { final case object DBString extends DBType[String] final case object DBDouble extends DBType[Double] final case class DBPair[A,B](first: DBType[A], second: DBType[B]) extends DBType[(A,B)] implicit val dbString : DBType[String] = DBString implicit val dbDouble : DBType[Double] = DBDouble implicit def dbPair[A,B](implicit first: DBType[A], second: DBType[B]): DBType[(A,B)] = DBPair(first, second) def apply[A](implicit ev: DBType[A]): ev.type = ev } Using DBType, we can pair a value of type A with a value of type DBType[A], which provides an evidence that the type A is supported by the database:\nfinal case class DBValue[A](value: A)(implicit val dbType: DBType[A]) Note that the parameter dbType does not need to be implicit! All that matters is that to create a value of type DBValue[A], we need to provide a value of type DBType[A] which forces A to be a supported type.\nA functor is, approximately, a type constructor F like List, Option, DBValue, ‚Ä¶ for which you can write an instance of the trait\ntrait Functor[F[_]] { def map[A,B](fa: F[A])(f: A =\u003e B): F[B] } where map(fa)(f) applies the function f to any value of type A contained in fa. For example:\nimplicit object OptionFunctor extends Functor[Option] { def map[A,B](fa: Option[A])(f: A =\u003e B): Option[B] = fa match { case Some(a) =\u003e Some(f(a)) case None =\u003e None } } Question 2: Write an instance of Functor[DBValue].\nSolution (click to expand) We actually can not! If we try to compile the following code:\nobject DBValueFunctor extends Functor[DBValue] { def map[A,B](fa: DBValue[A])(f: A =\u003e B): DBValue[B] = DBValue[B](f(fa.value)) } Scala complains: could not find implicit value for parameter dbType: DBType[B]. Indeed, booleans are not a supported type by the database: they are neither strings, nor doubles, not pairs. But if we could write a Functor instance for DBValue (i.e. if we could write a map function for DBValue), then we could write:\nval dbValueString : DBValue[String] = DBValue(\"A\")(DBString) val dbValueBoolean : DBValue[Boolean] = dbValueString.map(_ =\u003e true) val dbTypeBoolean : DBType[Boolean] = dbValueBoolean.dbType We would get a value (dbTypeBoolean) of type DBType[Boolean], which would mean that the type Boolean is supported by the database. But it is not! Furthermore, by definition:\nThere exists a value of type DBType[A] if and only if A is a type supported by the database.\nSo it is impossible to have a value of type DBType[Boolean] and thus it is impossible to write a function map for DBValue. So there is no way to write a Functor instance for DBValue.\nA Generalized Functor is very much like a regular Functor. But whereas the map function of functors have to work for every types A and B, the map function of generalized functor can be narrowed to only operate on a limited set of types A and B:\ntrait GenFunctor[P[_],F[_]] { def map[A,B](fa: F[A])(f: A =\u003e B)(implicit evA: P[A], evB: P[B]): F[B] } For example Set (more precisely TreeSet) is not a functor! Indeed there is no way to write a function map that works for any type B (because B need to have an ordering). But if we narrow map to the only types B having an ordering, we can write it.\nimport scala.collection.immutable._ object TreeSetFunctor extends GenFunctor[Ordering, TreeSet] { def map[A,B](fa: TreeSet[A])(f: A =\u003e B)(implicit evA: Ordering[A], evB: Ordering[B]): TreeSet[B] = TreeSet.empty[B](evB) ++ fa.toSeq.map(f) } Question 3: Write an instance of GenFunctor[DBType, DBValue].\nSolution (click to expand) object DBValueGenFunctor extends GenFunctor[DBType, DBValue] { def map[A,B](fa: DBValue[A])(f: A =\u003e B)(implicit evA: DBType[A], evB: DBType[B]): DBValue[B] = DBValue[B](f(fa.value))(evB) } What we have done to Functor can be done for many data-structures and patterns. We can often limit the types on which a data-structure or a type-class can operate by adding an extra parameter like ev : DBType[A] to constructors and methods.\nUse Case: Simplifying Implicits This use case is one the most interesting but unfortunately, not one of the easiest. It illustrates how it is possible to use GADTs to simplify the creation of implicit values. In this example we consider lists of values whose items can be of different types. Theses lists are called heterogeneous lists. They are usually defined in Scala almost like normal lists:\nfinal case class HNil() // The empty list final case class HCons[Head,Tail](head: Head, tail: Tail) // The `head :: tail` operation val empty : HNil = HNil() val oneTrueToto : HCons[Int, HCons[Boolean, HCons[String, HNil]]] = HCons(1, HCons(true, HCons(\"toto\", HNil()))) val falseTrueFive: HCons[Boolean, HCons[Boolean, HCons[Int, HNil]]] = HCons(false, HCons(true, HCons(5, HNil()))) As you can see, there is nothing special about it. We want to define orderings on heterogeneous lists. An ordering is a way to compare two values (of the same type!): they can be equal or one may be lesser than the other. In Scala we can define the trait Order:\ntrait Order[A] { // true if and only if a1 \u003c a2 def lesserThan(a1: A, a2: A): Boolean // a1 and a2 are equal if and only if none of them is lesser than the other. final def areEqual(a1: A, a2: A): Boolean = !lesserThan(a1, a2) \u0026\u0026 !lesserThan(a2, a1) // a1 \u003e a2 if and only if a2 \u003c a1 final def greaterThan(a1: A, a2: A): Boolean = lesserThan(a2, a1) final def lesserThanOrEqual(a1: A, a2: A): Boolean = !lesserThan(a2, a1) final def greaterThanOrEqual(a1: A, a2: A): Boolean = !lesserThan(a1, a2) } object Order { def apply[A](implicit ev: Order[A]): ev.type = ev def make[A](lg_ : (A,A) =\u003e Boolean): Order[A] = new Order[A] { def lesserThan(a1: A, a2: A): Boolean = lg_(a1,a2) } } implicit val orderInt = Order.make[Int](_ \u003c _) implicit val orderString = Order.make[String](_ \u003c _) Remember that we will only compare lists of the same type:\nLists of type HNil will only be compared to lists of type HNil. Lists of type HCons[H,T] will only be compared to lists of type HCons[H,T]. Comparing lists of type HNil is trivial because there is only one value of type HNil (the empty list HNil()). But there are many ways of comparing lists of type HCons[H,T]. Here are two possible orderings (there exists many more!):\nThe lexicographic ordering (i.e. dictionary order: from left to right)\nHCons(h1,t1) \u003c HCons(h2,t2) if and only if h1 \u003c h2 or (h1 == h2 and t1 \u003c t2 by lexicographic ordering).\nsealed trait Lex[A] { val order : Order[A] } object Lex { def apply[A](implicit ev: Lex[A]): ev.type = ev implicit val lexHNil: Lex[HNil] = new Lex[HNil] { val order = Order.make[HNil]((_,_) =\u003e false) } implicit def lexHCons[Head,Tail](implicit orderHead: Order[Head], lexTail: Lex[Tail] ): Lex[HCons[Head, Tail]] = new Lex[HCons[Head, Tail]] { val orderTail: Order[Tail] = lexTail.order val order = Order.make[HCons[Head, Tail]] { case (HCons(h1,t1), HCons(h2,t2)) =\u003e orderHead.lesserThan(h1,h2) || (orderHead.areEqual(h1,h2) \u0026\u0026 orderTail.lesserThan(t1,t2)) } } } The reverse-lexicographic ordering, which is the reverse version of the lexicographic ordering, (i.e. from right to left)\nHCons(h1,t1) \u003c HCons(h2,t2) if and only if t1 \u003c t2 by reverse-lexicographic ordering or (t1 == t2 and h1 \u003c h2).\nsealed trait RevLex[A] { val order : Order[A] } object RevLex { def apply[A](implicit ev: RevLex[A]): ev.type = ev implicit val revLexHNil: RevLex[HNil] = new RevLex[HNil] { val order = Order.make[HNil]((_,_) =\u003e false) } implicit def revLexHCons[Head,Tail](implicit orderHead: Order[Head], revLexTail: RevLex[Tail] ): RevLex[HCons[Head, Tail]] = new RevLex[HCons[Head, Tail]] { val orderTail: Order[Tail] = revLexTail.order val order = Order.make[HCons[Head, Tail]] { case (HCons(h1,t1), HCons(h2,t2)) =\u003e orderTail.lesserThan(t1,t2) || (orderTail.areEqual(t1,t2) \u0026\u0026 orderHead.lesserThan(h1,h2)) } } } As said above, it is possible to define more orderings:\nQuestion 1: The Alternate ordering is defined by:\nHCons(h1,t1) \u003c HCons(h2,t2) if and only if h1 \u003c h2 or (h1 == h2 and t1 \u003e t2 by alternate ordering).\nJust like what was done for Lex and RevLex, implement the Alternate ordering.\nSolution (click to expand) sealed trait Alternate[A] { val order : Order[A] } object Alternate { def apply[A](implicit ev: Alternate[A]): ev.type = ev implicit val alternateHNil: Alternate[HNil] = new Alternate[HNil] { val order = Order.make[HNil]((_,_) =\u003e false) } implicit def alternateHCons[Head,Tail](implicit orderHead: Order[Head], alternateTail: Alternate[Tail] ): Alternate[HCons[Head, Tail]] = new Alternate[HCons[Head, Tail]] { val orderTail: Order[Tail] = alternateTail.order val order = Order.make[HCons[Head, Tail]] { case (HCons(h1,t1), HCons(h2,t2)) =\u003e orderHead.lesserThan(h1,h2) || (orderHead.areEqual(h1,h2) \u0026\u0026 orderTail.greaterThan(t1,t2)) } } } There are lots of ways to define a valid ordering on heterogeneous lists! Defining type classes like Lex, RevLex and Alternate for every ordering we want to implement is clunky and messy. We can do much better than that ‚Ä¶ with a GADT üòâ\nsealed trait HListOrder[A] object HListOrder { final case object HNilOrder extends HListOrder[HNil] final case class HConsOrder[Head,Tail]( orderHead: Order[Head], hlistOrderTail: HListOrder[Tail] ) extends HListOrder[HCons[Head,Tail]] // Implicit definitions implicit val hnilOrder : HListOrder[HNil] = HNilOrder implicit def hconsOrder[Head,Tail](implicit orderHead: Order[Head], hlistOrderTail: HListOrder[Tail] ): HListOrder[HCons[Head,Tail]] = HConsOrder(orderHead, hlistOrderTail) def apply[A](implicit ev: HListOrder[A]): ev.type = ev } Note that these implicit definitions are boilerplate. Their only purpose is passing arguments to their corresponding constructor (i.e. final case class or case object): hnilOrder to HNilOrder (O arguments) and hconsOrder to HConsOrder (2 arguments).\nQuestion 2: Write the function def lex[A](implicit v : HListOrder[A]): Order[A] that computes the lexicographic ordering from a value of type HListOrder[A].\nSolution (click to expand) def lex[A](implicit v : HListOrder[A]): Order[A] = v match { case HListOrder.HNilOrder =\u003e Order.make[HNil]((_,_) =\u003e false) case hc : HListOrder.HConsOrder[head,tail] =\u003e val orderHead: Order[head] = hc.orderHead val orderTail: Order[tail] = lex(hc.hlistOrderTail) Order.make[HCons[head, tail]] { case (HCons(h1,t1), HCons(h2,t2)) =\u003e orderHead.lesserThan(h1,h2) || (orderHead.areEqual(h1,h2) \u0026\u0026 orderTail.lesserThan(t1,t2)) } } Question 3: Write the function def revLex[A](implicit v : HListOrder[A]): Order[A] that computes the reverse-lexicographic ordering from a value of type HListOrder[A].\nSolution (click to expand) def revLex[A](implicit v : HListOrder[A]): Order[A] = v match { case HListOrder.HNilOrder =\u003e Order.make[HNil]((_,_) =\u003e false) case hc : HListOrder.HConsOrder[head,tail] =\u003e val orderHead: Order[head] = hc.orderHead val orderTail: Order[tail] = revLex(hc.hlistOrderTail) Order.make[HCons[head, tail]] { case (HCons(h1,t1), HCons(h2,t2)) =\u003e orderTail.lesserThan(t1,t2) || (orderTail.areEqual(t1,t2) \u0026\u0026 orderHead.lesserThan(h1,h2)) } } This approach has several benefits. Whereas the initial approach had to find one implicit by ordering, the GADT approach only have to find one! Considering implicit resolution is a costly operation, reducing it means faster compilation times. Reading the code of functions lex and revLex is easier than understanding how implicit resolution works for traits Lex and RevLex. Furthermore, they are just functions, you can use all you can code in building the instance Order[A].\nConclusion Not so trivial, isn‚Äôt it? üòâ Actually a fair amount of the complexity you may have experienced comes to the fact that reasoning about values and types is almost never taught in programming courses. What you consider simple now (web APIs, Streaming, Databases, etc) would probably terrifies your younger self when you were introduced for the first time to ‚ÄúHello World!‚Äù. You probably did not learn all you know in programming in three hours so do not expect reasoning about programs to be magically easier.\nThis workshop aimed at inspiring you, opening your mind to this all new set of possibilities. If you found the use case interesting, then take the time to understand the techniques.\nHave fun and take care ‚ù§Ô∏è",
    "description": "Discover Generalized ADT through lots of practical examples.",
    "tags": [],
    "title": "GADTs By Use Cases",
    "uri": "/posts/gadts_by_use_cases/index.html"
  },
  {
    "breadcrumb": "Posts",
    "content": "The Scala source code is at github.com/chrilves/gadt.scala. The Haxe source code is at github.com/chrilves/Gadts.hx. The Web Application is here. Today we will explore the Curry‚ÄìHoward correspondence. Our mission is writing, in Scala‚Äôs type system, the property on natural number of being prime. Wikipedia defines it by:\nA natural number (1, 2, 3, 4, 5, 6, etc.) is called a prime number (or a prime) if it is greater than 1 and cannot be written as a product of two natural numbers that are both smaller than it.\nAn equivalent way to put it is:\nA natural number is prime if it is greater than 1 and cannot be divided by any natural number greater than 1 but smaller than it.\nThese definitions are equivalent as, by definition, any natural number n is divisible by k if and only if it can be written n = k √ó p for some natural number p.\nWriting a program whose execution checks whether a number is prime is easy. But we are not interested in executing programs, only compiling them! We want the compiler to verify that a number is indeed prime. At that point, you may wonder how it is even possible to use the compiler to ‚Äúprove‚Äù something about numbers. That‚Äôs exactly the point of the Curry‚ÄìHoward correspondence\nThe Challenge You can write any positive integer in the input bow below: Please write 3 in the input box above. A button shall appear letting you download Prime3.scala. Run it via\nscala Prime3.scala The file should compile and run flawlessly outputting ForAllRec(NotDivRec(NotDivBase(SIsPositive(),LTBase()),AddPlus1(AddZero())),ForAllBase()). Look into Prime3.scala, you should see a value prime3: Prime[_3] defined. The main method simply outputs this value.\nNow, write 4 in the input box. Download and run Prime4.scala via\nscala Prime4.scala The file should compile but execution should failed with the exception scala.NotImplementedError: an implementation is missing. Look into Prime4.scala, the value prime4: Prime[_4] is defined by ???.\nRead Prime4.scala carefully, starting from the beginning, and try to write a valid definition for val prime4: Prime[_4]. Remember to follow very scrupulously the rules stated in the first comment of Prime4.scala.\nDO NOT ALTER, IN ANY WAY, THE DEFINITION OF ANY TYPE IN THE FILE DO NOT ADD SUB CLASSES/OBJECTS TO TYPES IN THE FILE DO NOT USE NULL IN ANY WAY ONLY USE THE GIVEN CASE OBJECTS AND CASE CLASSES IN THE FILE THE GOAL IS TO PRODUCE A val prime4: Prime[_4], NOT A def prime4: Prime[_4], NOT A lazy val prime4: Prime[_4]! YOUR CODE SHOULD TYPE-CHECK AND RUN PRINTING THE VALUE prime4 Try to find valid values of type Prime[_N] when is not a prime number.\nWhat the hell is going on ??? To encode properties over natural number, we need to start by encoding natural numbers. To do so, we associate to any natural number a type. Natural numbers can be constructed by starting from the first one, 0, and creating new ones by adding 1 successively. For example, 1 = 0 + 1, 2 = 0 + 1 + 1, 3 = 0 + 1 + 1 + 1, etc. Our encoding will mimic this construction, starting from a base type encoding 0 and an operation \"+ 1\". The number 0 is encoded as the type _0 defined as the final abstract class _0 and the operation \"+ 1\" as the type function final abstract class S[N \u003c: Nat] which for every type N encoding a natural number n gives the type S[N] encoding the natural number n + 1. The type Nat can simply be defined as the alias type Nat = _0 | S[?] because a natural number is either 0 or obtained by some + 1 operations.\ntype Nat = _0 | S[?] final abstract class _0 final abstract class S[N \u003c: Nat] type _1 = S[_0] type _2 = S[_1] // S[S[_0]] type _3 = S[_2] // S[S[S[_0]]] type _4 = S[_3] // S[S[S[S[_0]]]] type _5 = S[_4] // S[S[S[S[S[_0]]]]] ... The next step is to define the type Prime[N] such that:\nThere exists a valid value of type Prime[N] if and only if N is (the type associated to) a prime number.\nProving that a Natural Number is Prime Let n be a natural number and N its associated type (for example n=3 and N = _3). Then:\nn is prime if and only if for all natural number m such that 2 ‚â§ m \u003c n, then m does not divide n.\nThe type ForAll[X, N] encodes this exact property. There exists a value of type ForAll[X,N] if and only if both:\nX ‚â§ N For all M such that X ‚â§ M \u003c N, M do not divide N Actually the type Prime[N] is an alias for ForAll[_2, N]. We need to encode two more properties:\nFor I and J two natural numbers, the property that I is less than or equal to J (I ‚â§ J). It is encoded as the type LessThan[I, J]. For I and J two natural numbers, the property that I does not divide J. It is encoded as the type NotDiv[I, J]. Read the file PrimeN.scala carefully, each step is described and explained in much details.\nConclusion Why asking you to build a value that not exists? Because the main point is not knowing whether there exists a value of type Prime[_4] but understanding why such a value (following all the rules!) cannot exists!\nIt is widely known and accepted in programming culture that every type has values. After all, types exists only to qualify values, right? And instantiating a type T is as simple as calling new! There is one huge problem with this claim: it is completely wrong!. The idea that a types can have no value, often called empty type or uninhabited type, is the cornerstone of a lot of techniques including logic, maths, programming with rich types, formal systems like Coq, etc.\nThis example is indeed both complicated and complex. It is neither a regular usage of GADTs nor something meant for production! It‚Äôs perfectly ok being confused about it or not understanding what is going on. As I said, it is an complicated and complex example!! But when you manage to understand it, consider you master the subject.",
    "description": "Let's do a bit of logic in Scala's type system.",
    "tags": [],
    "title": "Proving Primality with GADTs",
    "uri": "/posts/prime/index.html"
  },
  {
    "breadcrumb": "Posts",
    "content": "I gave a talk on Thursday the 28th of march 2019 at the 96th Paris Scala User Group session on about this. The slides are here.\nRecursion schemes are said to be a tough subject. Articles and presentations often flood the audience with lots of names such as Algebra, CoAlgebra, catamorphisms, anamorhpisms, hylomorphism, etc. Is knowing all these concepts required to understand recursion schemes? I have good news for you: it isn‚Äôt! All you need, to see what recursion schemes are and why there are useful, can be presented with just a single basic function, often taught as an introduction to programming: factorial. I‚Äôm glad to welcome you to to the high-school introduction to recursion scheme üòâ.\nLearning Recursion Schemes Before diving into the subject, let‚Äôs take a moment to contextualize. Recursion-schemes, like most of advanced functional programming techniques, is almost never taught in programming courses or books. It means there is a strong chance the subject, and the concepts it relies upon, is totally new to you. I want you to remember you haven‚Äôt learnt programming in one day, and you probably did not start learning programming by implementing a distributed steaming application over a spark cluster from scratch. Like most of us, you probably started by coding some sort of Hello, World!. Let‚Äôs face it, real business application are a lot more complex than this. Do you imagine what a first introduction to programming would be, if instead of asking people to write a simple Hello, World!, we would ask them to write a real state-of-the-art large-scale business application that meets all the requirements we expect in production nowadays? Learning takes time! Start with toy examples that are indeed far from real-word cases but enables you to grow your understanding, one step at a time.\nThe examples below are indeed toy examples. When i develop with recursion scheme, like any specialist in any field, i use specialist techniques and vocabulary (you know, the usual vocabulary from category and type theory). But if you‚Äôre reading this, it probably means you‚Äôre not a recursion-scheme specialist yet. Using complex words flatters our ego, which is very enjoyable, but developing a deep understanding of these notions is far better! So let‚Äôs put our ego aside for a moment and accept to start with the basics.\nIn Recursion Schemes, there is Recursion First of all, let me present you the famous factorial function. It is defined on non-negative numbers n as the product of all numbers between 1 and n included:\n$$fact(n) = 1 \\times 2 \\times 3 \\times \\cdots \\times n$$To ease the presentation we will take Int as the type of non-negative integers. Obviously in production code negative values should be handled appropriately but for simplicity‚Äôs sake, we will define fact in Scala and in Haskell as\ndef fact(n: Int): Int = if (n == 0) 1 else { val r = fact(n-1) n * r } fact :: Int -\u003e Int fact 0 = 1 fact n = let r = fact (n - 1) in n * r Factorial is written here as a recursive function. As you probably know, it can also be written as an iterative one (using a for or while loop) but the subject of this article is Recursion Schemes, not Iterative Schemes, so let‚Äôs use recursion. This function computes fact(2) as follows:\nfact(2) = 2 * fact(1) so it needs to compute fact(1) fact(1) = 1 * fact(0) so it needs to compute fact(0) fact(0) = 1 now that the result of fact(0) is known, it can replace the call of fact(0) by its result which gives fact(1) = 1 * fact(0) = 1 * 1 = 1 now that the result of fact(1) is known, it can replace the call of fact(1) by its result which gives fact(2) = 2 * fact(1) = 2 * 1 = 2. Look at how fact(n) is calling it-self: if n = 0 then it doesn‚Äôt call itself, otherwise it calls itself on n - 1. Let‚Äôs split this definition in two parts: the first one contains all the code relevant to how fact is calling itself but only it, the second one is made of the rest. There is no clear rule for what is relevant and what is not. Different splits may work, they will just give rise to different schemes, which is not a problem at all. You just need to find one that fits your needs.\nFor fact, the key element to note is it is not calling itself when n = 0 but otherwise calls itself with n - 1. The constant returned in the n = 0 case and the operation done in the other one have no impact on how fact recurses. So i choose to split it by taking all code not relevant to recursion out of its body:\n/* Part irrelevant to recursion: * The real definitions of these variables * have no impact on how fact is calling itself */ val baseCase: Int = 1 def recCase(n: Int, r: Int): Int = n * r /* Recursion-only part: * The only implementation details it contains * are about how fact it calling itself */ def fact(n: Int): Int = if (n == 0) baseCase else { val r = fact(n-1) recCase(n, r) } {- Part irrelevant to recursion: The real definitions of these variables Have no impact on how fact is calling itself -} baseCase :: Int baseCase = 1 recCase :: Int -\u003e Int -\u003e Int recCase n r = n * r {- Recursion-only part: The only implementation details it contains are about how fact it calling itself -} fact :: Int -\u003e Int fact 0 = baseCase fact n = let r = fact (n-1) in recCase n r Let me present you another function, also defined on non-negative numbers n, but that computes this time the sum of all numbers between 1 and n included:\n$$sum(n) = 1 + 2 + 3 + \\cdots + n$$def sum(n: Int): Int = if (n == 0) 0 else { val r = sum(n-1) n + r } sum :: Int -\u003e Int sum 0 = 0 sum n = let r = sum (n - 1) in n + r We can apply the same technique to sum: splitting the definition into two parts, one containing all but only recursion-relevant code, and the other the rest. It gives:\n/* Part irrelevant to recursion: * The real definitions of these variables * have no impact on how sum is recurs */ val baseCase: Int = 0 def recCase(n: Int, r: Int): Int = n + r /* Recursion-only part: * The only implementation details it contains * are about how fact it recurs */ def sum(n: Int): Int = if (n == 0) baseCase else { val r = sum(n-1) recCase(n, r) } {- Part irrelevant to recursion: The real definitions of these variables Have no impact on how fact is calling itself -} baseCase :: Int baseCase = 0 recCase :: Int -\u003e Int -\u003e Int recCase n r = n + r {- Recursion-only part: The only implementation details it contains are about how fact it calling itself -} sum :: Int -\u003e Int sum 0 = baseCase sum n = let r = sum (n-1) in recCase n r Do you see how similar the recursion-relevant parts of sum and fact are? They are actually identical! It means fact and sum have the same recursion structure. The recursion-irrelevant part differ: the constant baseCase which is 1 in fact but 0 in sum and operation recCase which is n * r in fact but n + r in sum. Note that if we replace, in each case, occurrences of baseRec and recCase by their definition, we get back the original functions. Look at the common recursive-relevant part:\ndef commonRecursiveRelevantPart(n: Int): Int = if (n == 0) baseCase else { val r = commonRecursiveRelevantPart(n-1) recCase(n, r) } commonRecursiveRelevantPart :: Int -\u003e Int commonRecursiveRelevantPart 0 = baseCase commonRecursiveRelevantPart n = let r = commonRecursiveRelevantPart (n-1) in recCase n r Obviously, for this code to be correct, baseCase and recCase have to be defined. Let‚Äôs fix this by taking them as arguments:\ndef scheme(baseCase: Int, recCase: (Int, Int) =\u003e Int): Int =\u003e Int = { def commonRecursiveRelevantPart(n: Int): Int = if (n == 0) baseCase else { val r = commonRecursiveRelevantPart(n-1) recCase(n, r) } commonRecursiveRelevantPart } scheme :: Int -\u003e (Int -\u003e Int -\u003e Int) -\u003e Int -\u003e Int scheme baseCase recCase = commonRecursiveRelevantPart where commonRecursiveRelevantPart :: Int -\u003e Int commonRecursiveRelevantPart 0 = baseCase commonRecursiveRelevantPart n = let r = commonRecursiveRelevantPart (n-1) in recCase n r It is then trivial to define both fact and sum by feeding scheme with corresponding definitions for baseCase and recCase:\ndef fact: Int =\u003e Int = scheme(1, (n: Int, r:Int) =\u003e n * r) def sum : Int =\u003e Int = scheme(0, (n: Int, r:Int) =\u003e n + r) fact :: Int -\u003e Int fact = scheme 1 (*) sum :: Int -\u003e Int sum = scheme 0 (+) We can now give a first answer to how recursion schemes can be useful. They enable to to write less code which is both easier and safer. But there is more! Recursive calls, like any function calls, consume the stack. If there are too many recursive calls (i.e. when n is to big), there is a risk of stack overflow. Some languages like Scala are smart enough to avoid, in some cases, this problem by transforming tail-recursive functions into iterative loops. Unfortunately not all recursive functions are tail-recursive. Writing recursive functions as iterative loops is not the solution either since it is intricate and error-prone. Fortunately it is enough to only write the recursion scheme once:\ndef scheme(baseCase: Int, recCase: (Int, Int) =\u003e Int)(n: Int): Int = { var res = baseCase var i: Int = 1 while (i \u003c= n) { res = recCase(i, res) i += 1 } res } scheme :: Int -\u003e (Int -\u003e Int -\u003e Int) -\u003e Int -\u003e Int scheme baseCase recCase n = aux baseCase 1 where aux res i = if i \u003c= n then aux (recCase i res) (i + 1) else res Note that the scheme is usually simpler to write as it only focuses on recursion, not business logic. Furthermore one scheme may fit many functions thus reducing the complexity and bugs in writing business functions. Remember that fact and sum are purposely trivial. They are just toy example to introduce the subject. In practice you will use much more complex recursive functions. Once you‚Äôve understood this example, you‚Äôll be able to scale this technique to any recursive one, however complex it is.\nScaling up! To be sure we have a good understanding of the techniqe, let‚Äôs apply it to the fibonacci function we all love. It is defined on non-negative integers by\n$$fib(0) = 1$$ $$fib(1) = 1$$ $$fib(n+2) = fib(n+1) + fib(n)$$def fib(n: Int): Int = n match { case 0 =\u003e 1 case 1 =\u003e 1 case n =\u003e val r1 = fib(n-1) val r2 = fib(n-2) r1 + r2 } fib :: Int -\u003e Int fib 0 = 1 fib 1 = 1 fib n = r1 + r2 where r1 = fib (n - 1) r2 = fib (n - 2) The function fib does not call itself when n is 0 or 1 but calls itself twice, on n-1 and n-2 otherwise. So we can, like fact and sum, split fib into two pieces: one containing only recursion-relevant code and the other one the rest. Once again the split is done by taking recursion-irrelevant code out of the function‚Äôs body. Remember they are many ways to split it up. This one is just one of many sensible way of doing so:\n/* Part irrelevant to recursion: * The real definitions of these variables * have no impact on how fact is calling itself */ val baseCase0: Int = 1 val baseCase1: Int = 1 def recCase(r1: Int, r2: Int): Int = r1 + r2 /* Recursion-only part: * The only implementation details it contains * are about how fib it calling itself */ def fib(n: Int): Int = n match { case 0 =\u003e baseCase0 case 1 =\u003e baseCase1 case n =\u003e val r1 = fib(n-1) val r2 = fib(n-2) recCase(r1, r2) } {- Part irrelevant to recursion: The real definitions of these variables Have no impact on how fact is calling itself -} baseCase0 :: Int baseCase0 = 1 baseCase1 :: Int baseCase1 = 1 recCase :: Int -\u003e Int -\u003e Int recCase n r = n + r {- Recursion-only part: The only implementation details it contains are about how fact it calling itself -} fib :: Int -\u003e Int fib 0 = baseCase0 fib 1 = baseCase1 fib n = recCase r1 r2 where r1 = fib (n - 1) r2 = fib (n - 2) Which leads to the recursion scheme:\ndef scheme(baseCase0: Int, baseCase1: Int, recCase: (Int, Int) =\u003e Int)(n: Int): Int = n match { case 0 =\u003e baseCase0 case 1 =\u003e baseCase1 case n =\u003e val r1 = fib(n-1) val r2 = fib(n-2) recCase(r1, r2) } scheme :: Int -\u003e Int -\u003e (Int -\u003e Int -\u003e Int) -\u003e Int -\u003e Int scheme baseCase0 baseCase1 recCase = aux where aux 0 = baseCase0 aux 1 = baseCase1 aux n = recCase r1 r2 where r1 = aux (n - 1) r2 = aux (n - 2) It is then trivial to define fib by giving appropriate definition to scheme arguments: baseCase0, baseCase1 and recCase.\ndef fib: Int =\u003e Int = scheme(1, 1, (r1: Int, r2: Int) =\u003e r1 + r2) fib :: Int -\u003e Int fib = scheme 1 1 (+) Once again this implementation is not optimal as each call of fib can make to 2 recursive calls which leads to an exponential time complexity. While computing fib(5) is fast, computing fib(1000) may take much longer. As you already probably guessed, writing the recursion scheme as an iterative loop, which sadly makes it more intricate, solves the problem:\ndef scheme(baseCase0: Int, baseCase1: Int, recCase: (Int, Int) =\u003e Int)(n: Int): Int = if (n == 0) baseCase0 else { var b0 = baseCase0 var b1 = baseCase1 var i = 2 while (i \u003c= n) { val b2 = recCase(b0, b1) b0 = b1 b1 = b2 i += 1 } b1 } scheme :: Int -\u003e Int -\u003e (Int -\u003e Int -\u003e Int) -\u003e Int -\u003e Int scheme baseCase0 baseCase1 recCase 0 = baseCase0 scheme baseCase0 baseCase1 recCase n = aux baseCase0 baseCase1 2 where aux b0 b1 i = if i \u003c= n then aux b1 (recCase b0 b1) (i + 1) else b1 By now you should get a good grasp on what recursion schemes are. But we have only seen a tiny fraction of how useful they are. It‚Äôs about time to consider the real power of fact, sum and fib‚Äôs schemes.\nTime to take off! Previously we defined fact and sum‚Äôs schemes as\ndef scheme(baseCase: Int, recCase: (Int, Int) =\u003e Int)(n: Int): Int = { var res = baseCase var i: Int = 1 while (i \u003c= n) { res = recCase(i, res) i += 1 } res } scheme :: Int -\u003e (Int -\u003e Int -\u003e Int) -\u003e Int -\u003e Int scheme baseCase recCase n = aux baseCase 1 where aux res i = if i \u003c= n then aux (recCase i res) (i + 1) else res I have a small exercise for you: find where this code relies on baseCase to be an Int? It‚Äôs important, take the time to figure it out. The answer is simple: it does not! baseCase can actually be any of type A! We don‚Äôt even have to modify the code (only the type signature):\ndef scheme[A](baseCase: A, recCase: (Int, A) =\u003e A)(n: Int): A = { var res = baseCase var i: Int = 1 while (i \u003c= n) { res = recCase(i, res) i += 1 } res } scheme :: a -\u003e (Int -\u003e a -\u003e a) -\u003e Int -\u003e a scheme baseCase recCase n = aux baseCase 1 where aux res i = if i \u003c= n then aux (recCase i res) (i + 1) else res Not only can we still define fact (and sum) like above but it makes trivial defining the functions like list which returns the list of integers between n and 1:\ndef list: Int =\u003e List[Int] = scheme[List[Int]](Nil, (n: Int, r: List[Int]) =\u003e n :: r) list :: Int -\u003e [Int] list = scheme [] (:) Unsurprisingly fib‚Äôs recursion scheme can also be generalized without changing a single line of code (only type signature):\ndef scheme[A](baseCase0: A, baseCase1: A, recCase: (A, A) =\u003e A)(n: Int): A = if (n == 0) baseCase0 else { var b0 = baseCase0 var b1 = baseCase1 var i = 2 while (i \u003c= n) { val b2 = recCase(b0, b1) b0 = b1 b1 = b2 i += 1 } b1 } scheme :: a -\u003e a -\u003e (a -\u003e a -\u003e a) -\u003e Int -\u003e a scheme baseCase0 baseCase1 recCase 0 = baseCase0 scheme baseCase0 baseCase1 recCase n = aux baseCase0 baseCase1 2 where aux b0 b1 i = if i \u003c= n then aux b1 (recCase b0 b1) (i + 1) else b1 While fact‚Äôs scheme is related to lists, fib‚Äôs one is related to trees:\nsealed abstract class Tree[+A] final case class Leaf[+A](value: A) extends Tree[A] final case class Node[A](left: Tree[A], right: Tree[A]) extends Tree[A] def tree: Int =\u003e Tree[Boolean] = scheme( Leaf(false), Leaf(true), (r1: Tree[Boolean], r2: Tree[Boolean]) =\u003e Node(r1,r2) ) data Tree a = Leaf a | Node (Tree a) (Tree a) tree :: Int -\u003e Tree Bool tree = scheme (Leaf False) (Leaf True) Node I have few real exercises for you this time:\nfind in your production code several spots where this scheme could be useful. write schemes, as general as possible, for at least 5 recursive functions in our production code. Obviously I won‚Äôt check you did the exercises but you should really do them. Reading is not sufficient to develop your understanding of the technique, you need to experiment! Try things, play with these notions until it clicks. Learning recursion schemes is like going on expeditions: preparation time may seem the easier part but if you did not prepare well enough, you‚Äôll get lost.\nYeah! Buzzwords! As we have seen, fact‚Äôs scheme takes 2 arguments:\ndef scheme[A](baseCase: A, recCase: (Int, A) =\u003e A): Int =\u003e A scheme :: a -\u003e (Int -\u003e a -\u003e a) -\u003e Int -\u003e a While this definition is perfectly ok, we can regroup these argument in any structure that can hold both values like a pair, an interface or a trait:\ntrait FactorialSchemeArguments[A] { val baseCase: A def recCase(n: Int, r: A): A } def scheme[A](arguments: FactorialSchemeArguments[A]): Int =\u003e A class FactorialSchemeArguments a where baseCase :: a recCase :: Int -\u003e a -\u003e a scheme :: FactorialSchemeArguments a =\u003e Int -\u003e a Note that scheme is still the same: it still takes the same two arguments. But even if the code didn‚Äôt change, this transformation makes us see scheme from a different perspective. It shows scheme as a functions transforming an integer to an A provided that we give some structure to A: a constant baseCase and an operation recCase. Let‚Äôs give this structure and the scheme names: i decide to call the structure a AkolovioaAlgebra (don‚Äôt look for it in literature, i just coined the term) and the scheme an akolovioaMorphism:\ntrait AkolovioaAlgebra[A] { val initial: A def action(n: Int, r: A): A } def akolovioaMorphism[A: AkolovioaAlgebra]: Int =\u003e A class AkolovioaAlgebra a where initial :: a action :: Int -\u003e a -\u003e a akolovioaMorphism :: AkolovioaAlgebra a =\u003e Int -\u003e a This looks smart, doesn‚Äôt it? üòâ It is actually very close to a very common structure in programming! Will you find which one? Obviously the same can be done for fibonacci‚Äôs scheme. As an exercise, apply this technique to fibonacci‚Äôs scheme and give them pretty names.\nWhere to go from here? As you know this is not the end of the story: the subject is closely related to pervasive notions such as (co)algebras, inductive types, categories, initial-objects, fixed-points, algebraic data types, etc. Whichever next subject you choose to dive into, the approach this article follows, i.e. experimenting on toy examples, really helps developing a solid understanding. I want you to realize each definition you read in books, articles, talks, etc is the result of people experimenting. The common trap in this field is looking at definitions as sacred pieces of unquestionable truth no mortal can see through. It is actually the exact opposite! Science is by essence experimentation. This is by investigating and trying things you end up figuring out how things work. But, like in science, for your investigation to be productive your tests need to be done in a controlled environment with as few variables as possible so that it is easy for you to see what‚Äôs going on. That‚Äôs why toy examples are so important: they contain the essence of what makes things work without all the noise real examples have.\nTake care and spread recursion schemes around üòâ",
    "description": "Presentation of recursion schemes from simple examples without the complex vocabulary in the way.",
    "tags": [],
    "title": "Recursion Schemes: the high-school introduction",
    "uri": "/posts/recursion_schemes_intro/index.html"
  },
  {
    "breadcrumb": "Posts",
    "content": "Generalized Algebraic Data Types (GADT) is certainly one of the most feared concept in programming nowadays. Very few mainstream languages support GADTs. The only ones i know which does are Haskell, Scala, OCaml and Haxe. The idea is actually very simple but often presented in complicated ways. In fact, if you‚Äôre familiar to both basic Object-Oriented-with-Generics and basic functional programming, then you most probably are already familiar with GADTs without even knowing you are. But if GADTs are so simple, why so many people feel terrified by them? Well GADTs rely on two fundamental ideas, one of them is known by every Object-Oriented-with-Generics programmer while the other is known by every functional programmer. The problem is most people make the huge mistake of opposing them even though they are complementary. So before diving into GADTs, let me remind you of these elementary notions from Object-Oriented and functional programming.\nObject-Oriented Programming 101 Let‚Äôs start by some plain old Java (the examples works in probably all Object-Oriented language which supports generics). We want to define an abstract class for sequences:\npublic abstract class Sequence\u003cA\u003e { abstract public int length(); abstract public A getNthElement(int nth); } In Java it would be better to define Sequence\u003cA\u003e as an interface but i want this example to be as simple as possible. Would you be surprised if told you a String is a sequence of characters ? ;) As i said, GADTs rely on very basic programming knowledge.\npublic class MyString extends Sequence\u003cCharacter\u003e { private String str; public MyString(String s) { this.str = s; } public int length() { return this.str.length(); } public Character getNthElement(int nth) { return this.str.charAt(nth); } } Likewise, bytes are sequences of 8 bits (we represent a bit by a Boolean):\npublic final class MyByte extends Sequence\u003cBoolean\u003e { private byte bte; public MyByte(byte x) { this.bte = x; } public int length() { return 8; } public Boolean getNthElement(int nth) { if (nth \u003e= 0 \u0026\u0026 nth \u003c= 7) return ((bte \u003e\u003e\u003e nth \u0026 1) == 1); else throw new java.lang.IndexOutOfBoundsException(\"\"); } } Have you noticed how MyByte and MyString declares themselves being respectively a sequence of booleans (Sequence\u003cBoolean\u003e) and a sequence of characters (Sequence\u003cCharacter\u003e) but not sequences of A (Sequence\u003cA\u003e) for any type A? Let‚Äôs try to make it work for any type A:\npublic final class MyByte\u003cA\u003e extends Sequence\u003cA\u003e { private byte bte; public MyByte(byte x) { this.bte = x; } public int length() { ??? } public A getNthElement(int nth) { ??? } } How would you write the methods length and getNthElement? Do you really imagine what would be a MyByte\u003cGraphics2D\u003e? It just doesn‚Äôt make any sense at all. You could argue that a string is also a sequence of byte and a byte a sequence of one byte. Indeed this relation is not unique, but it does not change the fact that it works for only a small selection of type A and not every one! We can go even deeper in Object-Oriented Programming:\npublic final class MyArray\u003cA extends Number\u003e extends Sequence\u003cNumber\u003e { private A[] array; public MyArray(A[] a) { this.array = a; } public int length() { return this.array.length; } public Number getNthElement(int nth) { return this.array[nth]; } } Note how the generics A, which is required to be a sub-class of Number, is present as argument of MyArray but not in extends Sequence\u003cNumber\u003e. Now what do you think about this code? Do you think it can be wrong?\npublic static \u003cA\u003e void guess(Sequence\u003cA\u003e x) { if (x instanceof MyByte) { System.out.println(\"I guess A is actually Boolean, let's check!\"); System.out.println(((Sequence\u003cBoolean\u003e)x).getNthElement(0).getClass().getName()); } else if (x instanceof MyString) { System.out.println(\"I guess A is actually Character\"); System.out.println(((Sequence\u003cCharacter\u003e)x).getNthElement(0).getClass().getName()); } else if (x instanceof MyArray\u003c?\u003e) { System.out.println(\"I guess A is a sub-class of Number but i can not guess which one\"); System.out.println(((Sequence\u003c?\u003e) x).getNthElement(0).getClass().getName()); } else System.out.println(\"I don't know what A is\"); } If x is an instance of MyByte, which is a sub-class of Sequence\u003cBoolean\u003e, then by trivial inheritance x is also an instance of Sequence\u003cBoolean\u003e. In this case A is forced to be Boolean. If x is an instance of MyString, which is a sub-class of Sequence\u003cCharacter\u003e, then again by trivial inheritance x is also an instance of Sequence\u003cCharacter\u003e . In this case A has to be Character. If x is an instance of MyArray\u003cA\u003e for some type A, which is a sub-class of Sequence\u003cNumber\u003e, then once again by trivial inheritance x is an instance of Sequence\u003cNumber\u003e. In this case we know A is a sub-class of Number but we don‚Äôt know which one. This is the essence of Generalized Algebraic Data Types. It you understand the code above, then you understand how GADTs work. As you see this is very basic Oriented-Object with Generics. You can find lots of examples of this kind in almost every Java/C#/etc project (search for the instanceof keyword).\nFunctional Programming 101 Functional languages often support a feature called Algebraic Data Types (ADT) which is essentially enumerations on steroids. Like enumerations this is a disjoint union of a fixed number of cases but unlike enumerations, where each case is a constant, ADTs cases can have parameters. As an example, the type of lists whose elements are of type a, written List a in Haskell, is defined:\ndata List a = Nil | Cons a (List a) It means any value of type List a belong to exactly one of the following cases:\neither the value is the constant Nil which represents the empty list. or the value is Cons hd tl which represent the list whose first element is hd (of type a) and whose tail is tl (of type List a). The list [1,2,3,4] is encoded by Cons 1 (Cons 2 (Cons 3 (Cons 4 Nil))). Where ADTs really shine is pattern-matching which is a very powerful and flexible switch (as i said above, ADTs are enumerations on steroids). ADTs being made of a fixed number of distinct cases, pattern-matching enable to inspect values and perform computations based on a case by case analysis of the form of the value. Here is how to implement the merge sort algorithm on this type:\nsplit :: List a -\u003e (List a, List a) split l = case l of Cons x (Cons y tl) -\u003e (case split tl of (l1, l2) -\u003e (Cons x l1, Cons y l2) ) Cons _ Nil -\u003e (l , Nil) Nil -\u003e (Nil, Nil) merge :: (a -\u003e a -\u003e Bool) -\u003e List a -\u003e List a -\u003e List a merge isLessThan l1 l2 = case (l1, l2) of (_ , Nil ) -\u003e l1 (Nil , _ ) -\u003e l2 (Cons hd1 tl1, Cons hd2 _ ) | hd1 `isLessThan` hd2 -\u003e Cons hd1 (merge isLessThan tl1 l2) (_ , Cons hd2 tl2) -\u003e Cons hd2 (merge isLessThan l1 tl2) sort :: (a -\u003e a -\u003e Bool) -\u003e List a -\u003e List a sort isLessThan l = case l of Nil -\u003e Nil Cons _ Nil -\u003e l _ -\u003e case split l of (l1, l2) -\u003e merge isLessThan (sort isLessThan l1) (sort isLessThan l2) I know there are smarter ways to write it in Haskell but this article is not about it. The code above could be translated trivially in OCaml by replacing case ... of by match ... with, in Scala by ... match { ... }, etc. This style is valid is probably all languages supporting pattern-matching so it fits our goal.\nThe case l of expressions are pattern-matching. They are a sequence of pattern | condition -\u003e code. The code being executed is the right-hand side of the first case for which the value l is of the form of its pattern and satisfy the condition. l is then said to match this case. For example, the case Cons x (Cons y tl) -\u003e (case split tl of (l1, l2) -\u003e (Cons x l1, Cons y l2)) states that if l is of the form Cons x (Cons y tl), which means that there are three values x, y and tl such that l == Cons x (Cons y tl), then the code executed is (case split tl of (l1, l2) -\u003e (Cons x l1, Cons y l2)). One very important condition is that pattern-matching must be exhaustive! It means that the sequence of cases must cover all possible value of l.\nIf your understand the previous section, the type List a and how pattern-matching works in the example above, then i am very glad to inform you that you already understand GADTs! Well done :)\nSumming up! In this section i assume previous sections are ok for you. If you do not understand previous examples, don‚Äôt go further but go back to the basics of generics and pattern-matching. Likewise, if you find what follows complicated, go back to the basics generics and pattern-matching. There is no shame in doing so! Difficulties in understanding advanced notion is often the reflect of a lack of understanding in the ones they rely upon. As i said, there is no shame in it, if you think programming paradigms are ‚Äúsimple‚Äù then write a compiler ;)\nIt‚Äôs about time to sum up everything. First, note that List a is not one single type. Each type a actually gives rise to a distinct type List a. For example List Int, List String, List (List Bool), etc are all distinct types. Indeed the list Cons 1 Nil is neither a list of strings nor of booleans! For each type a, the type List a have two constructors: the constant Nil and the function Cons :: a -\u003e List a -\u003e List a which builds a List a from a value of type a and other List a.\nThere is another equivalent way to define List a in Haskell which makes the nature of the constructor more apparent:\ndata List a where Nil :: List a Cons :: a -\u003e List a -\u003e List a Indeed, for each type a, Nil is constant of type List a while Cons is a function of type a -\u003e List a -\u003e List a. Note that it is actually very close to the way to define it in Scala:\nsealed abstract class List[A] final case class Nil[A]() extends List[A] final case class Cons[A](head: A, tail: List[A]) extends List[A] Do you remember the example of the first section Sequence\u003cA\u003e? There was three sub-classes of Sequence\u003cA: MyString which is actually a sub-class of Sequence\u003cCharacter\u003e, MyByte which is a sub-class of Sequence\u003cBoolean\u003e and MyArray\u003cA extends Number\u003e which is a sub-class of Sequence\u003cNumber\u003e. What is the type of their constructors? Some admissible type for them is (in Scala notation):\ndef MyString : String =\u003e Sequence[Character] def MyByte : Byte =\u003e Sequence[Boolean] def MyArray[A \u003c: Number] : Array[A] =\u003e Sequence[Number] From this, this is trivial to write:\nsealed abstract class Sequence[A] final case class MyString(str: String) extends Sequence[Character] final case class MyByte(bte: Byte) extends Sequence[Boolean] final case class MyArray[A \u003c: Number](array: Array[A]) extends Sequence[Number] or in Haskell:\ndata Number where MkNum :: forall a. Num a =\u003e Number data Sequence a where MyString :: String -\u003e Sequence Char MyByte :: Word8 -\u003e Sequence Bool MyArray :: forall a. Num a =\u003e List a -\u003e Sequence Number Sequence is a GADT. What makes it different from List above? For any type a, values of type List a are build using the two constructors Nil and Cons. Note that it does not depend on what a is. Values of type List Int are build using the exact same constructors than List Bool, List String, List (List Char), etc. Sequence have three constructors MyString, MyByte and MyArray. But values of type Sequence[Character] can only be built by the constructor MyString while values of type Sequence[Boolean] can only be built by the constructor MyByte and values of type Sequence[Number] can only be built by the constructor MyArray. What about values of type Sequence[Unit] or Sequence[String], etc? There is simply no constructor to build values of these types, so there is no values of these types!\nWe can rewrite the methods on Sequence and the guess function to use patten-matching:\ndef length[A](x: Sequence[A]): Int = x match { case MyByte(_) =\u003e 8 case MyString(str) =\u003e str.length case MyArray(arr) =\u003e arr.size } def getNthElement[A](x: Sequence[A], nth: Int): A = x match { case MyByte(bte) =\u003e // So A is actually Boolean if (nth \u003e= 0 \u0026\u0026 nth \u003c= 7) (bte \u003e\u003e\u003e nth \u0026 1) == 1 else throw new java.lang.IndexOutOfBoundsException(\"\") case MyString(str) =\u003e // So A is actually Character str.charAt(nth) case MyArray(array) =\u003e // So A is actually a sub-class of Number array(nth) } def guess[A](x : Sequence[A]): Unit = x match { case MyByte(bte) =\u003e println(\"I guess A is actually Boolean, let's check!\") println(getNthElement(x, 0).getClass.getName) case MyString(str) =\u003e println(\"I guess A is actually Character\") println(getNthElement(x, 0).getClass.getName) case MyArray(array) =\u003e println(\"I guess A is a sub-class of Number but i can not guess which one\") println(getNthElement(x, 0).getClass.getName) } As you can see getNthElement must returns a value of type A but the case MyByte returns a Boolean. It means Scala is aware that in this case A is actually Boolean. Likewise in the case MyString, Scala knowns that the only possible concrete type for A is Character so it accepts we return one. Scala is (most of the time) able to guess, depending on the case, what are the constraints on A. This is all the magic behind GADTs: specialized constructors like in object-oriented-with-generics programming and closed types (i.e. with a fixed number of cases) on which we can pattern-match like in usual functional programming.\nHow are GADTs useful? First of all, there are handy when you have a specialized constructor like in every day life object-oriented programming. It makes sense for a byte (resp. string) to be sequence of booleans (resp. characters) but not a sequence of anything. A prolific use of this is writing implicits in Scala as GADTs. This way we can pattern-match on the structure of the implicits to derive instances (see this gist for more details). They are also very useful to encode properties on types. As i said above, not all types Sequence[A] have (non-null) values! There is no (non-null) value of type Sequence[Unit] or Sequence[String] etc but there are values of type Sequence[Boolean], Sequence[Character] and Sequence[Number]. So if i give you a value of type Sequence[A], then you know A is either Boolean, Character or Number. If you don‚Äôt believe me, try to call the function guess on a type A which is neither Boolean nor Character nor Number (without using null)! Let me give you some useful examples.\nThe first one is restricting a generic type like in the code below. The GADT IsIntOrString forces A to be either String or Int in the function and the case class.\nsealed abstract class IsIntOrString[A] implicit final case object IsInt extends IsIntOrString[Int] implicit final case object IsString extends IsIntOrString[String] def canOnlyBeCalledOnIntOrString[A](a: A)(implicit ev: IsIntOrString[A]): A = ev match { case IsInt =\u003e // A is Int a + 7 case IsString =\u003e // A is String a.reverse } final case class AStringOrAnIntButNothingElse[A](value: A)(implicit val proof : IsIntOrString[A]) Another handy use is encoding effects:\ntrait UserId trait User sealed abstract class BusinessEffect[A] final case class GetUser(userId: UserId) extends BusinessEffect[User] final case class SetUser(user: User) extends BusinessEffect[UserId] final case class DelUser(userId: UserId) extends BusinessEffect[Unit] Have you ever heard that Set is not a functor? With the usual definition of a functor, indeed Set is not one.\ntrait Functor[F[_]] { def map[A,B](fa: F[A])(f: A =\u003e B): F[B] } The reason is you can only have a Set[A] for types A such that you can compare values. As an example let A be Int =\u003e Int. The two following functions are arguably equal:\nval doubleByMult: Int =\u003e Int = (x: Int) =\u003e 2 * x val doubleByPlus: Int =\u003e Int = (x: Int) =\u003e x + x scala\u003e Set(doubleByMult).contains(doubleByPlus) res0: Boolean = false This is just impossible, in the general case, to know if two functions compute the same thing. I didn‚Äôt just say we don‚Äôt know how to do it. It is actually proven that this is impossible (like no one can, and no one could for ever!). Have a look at this List of undecidable problems for more information on the subject. Using extensional equality (the one where f == g if and only f(x) == g(x) for all x), there is just no implementation of Set[Int =\u003e Int]. But if Set was a functor, it would be trivial using map to get a Set[Int =\u003e Int]:\nSet[Boolean](true, false).map { case true =\u003e doubleByMult case false =\u003e doubleByPlus }: Set[Int =\u003e Int] The conclusion is that Set is not a functor ‚Ä¶ in the usual (i.e. Scal) category. But it is in for some categories. The problem with Functor is map can be applied on any A and B which is impossible for Set. But if we restrict A and B such that they have interesting properties (like having an Ordering), then it works. In the code below, the GADT predicate is used to restrict on which A and B map can be applied on:\ntrait GenFunctor[predicate[_],F[_]] { def map[A,B](fa: F[A])(f: A =\u003e B)(implicit proofA: predicate[A], proofB: predicate[B]): F[B] } Then Set is becomes a functor with Ordering as predicate:\nobject SetInstance extends GenFunctor[Ordering, Set] { def map[A,B](fa: Set[A])(f: A =\u003e B)(implicit orderingA: Ordering[A], orderingB: Ordering[B]): Set[B] = { val set = TreeSet.newBuilder(orderingB) for (a \u003c- fa) set += f(a) set.result } } Surprisingly even String can be a functor (with A and B being both Char)!!!\nsealed abstract class IsItChar[A] implicit final case object YesItIsChar extends IsItChar[Char] type StringK[A] = String object StringInstance extends GenFunctor[IsItChar, StringK] { def map[A,B](fa: String)(f: A =\u003e B)(implicit proofA: IsItChar[A], proofB: IsItChar[B]): String = (proofA, proofB) match { case (YesItIsChar, YesItIsChar) =\u003e // A and B are both Char! fa.toList.map(f).mkString } } GADTs are an example of Bushnell‚Äôs law. As you can see, they are easy to learn but can be used in very tricky situations which makes them hard to master. They are clearly very helpful in many situations but it seems they are still unfortunately very little used. Haskell supports them very well! Scala‚Äôs support is actually very good but not as good as Haskell‚Äôs. Scala 3 will probably support them as well as Haskell since Dotty‚Äôs support is excellent. The only two other mainstream languages i know supporting them are OCaml and Haxe. Even if those two have a very good support, their lack of Higer-Kinded types forbids the most interesting uses.\nAs you probably know, it is possible to define a fold functor for every Algebraic Data Type. It is also possible to define fold functions for every GADT. As an exercise, try to define fold functions for the following GADTs:\nThis GADT encode the equality between two types A and B:\nsealed abstract class Eq[A,B] final case class Refl[A]() extends Eq[A,A] This GADT represent an unknown type for which we have an instance of a type-class:\nsealed abstract class Ex[TypeClass[_]] final case class MakeEx[TypeClass[_],A](value:A, instance: TypeClass[A]) extends Ex[TypeClass] You‚Äôll find how to define such fold functions here. Have fun and spread the love of GADTs everywhere :)",
    "description": "Introduction to catamorphisms on Algebraic Data Types",
    "tags": [],
    "title": "Demystifying GADTs",
    "uri": "/posts/gadts_intro/index.html"
  },
  {
    "breadcrumb": "Introduction to Types",
    "content": "We have seen many types but we still don‚Äôt know how to represent numbers, lists, trees, free monads, or any type with an infinite number of values. One again we will start by simple examples. Like always, do no skim through them but take the time to develop a deep understanding. If you feel uncomfortable with complex examples, it means you missed something important in the simple ones.\nA simple example We will take as example an encoding of non-negative integers, also called natural numbers, i.e. numbers 0, 1, 2, 3 and so on. There are actually many encodings possible, but we will take a simple encoding known as Peano numbers. Did you ever wonder how natural numbers are built? There can actually be built starting from 0 then adding 1 to 0 to make 1, then adding 1 to 1 to make 2, then adding 1 to 2 to make 3, then adding 1 to 3 to make 4, and so on. Our encoding will mimic this construction. We need two constructors: one of represent 0 and the other to represent the operation of adding 1 to the previous number to make a new one.\nLet‚Äôs call Nat the type of natural numbers. The first constructor, representing 0 should be a constant of type Nat while the second one, representing the operation of adding 1 should be a function of type Nat =\u003e Nat. Remember that constructors need to be injective, but we are lucky, this operation is actually injective. Let call the first constructor Zero:Nat and the second one Succ:Nat =\u003e Nat (for successor). This is easy to translate into Scala and Haskell:\nsealed abstract class Nat { def fold[A](zero: A, succ: A =\u003e A): A = this match { case Zero =\u003e zero case Succ(p) =\u003e val a = p.fold(zero, succ) succ(a) } } final case object Zero extends Nat final case class Succ(n: Nat) extends Nat data Nat where Zero :: Nat Succ :: Nat -\u003e Nat Note that all the constructors we have seen in the previous episodes took as argument already defined types, but the first argument of Succ is of type Nat, the very same type we are defining. This is the reason why Nat is called a recursive data type: some of its constructors take as arguments values of type Nat itself. As usual:\nconstructors are injective different constructors produces different value every value of type Nat is either a Zero or a Succ(n) for some n:Nat The problem is, unlike enumerations, products and coproducts where these properties are enough to define their respective type (up to equivalence) without ambiguity. With recursive data types there can be several non-equivalent types for which these three properties hold. For example, the type {0, 1, 2, ...} of natural numbers and {O, 1, 2, ..., ‚àû} in which we added one special number called infinity such that Succ(‚àû) = ‚àû both have the three properties above. So wee need to add a new constraint, which is that: among all the types for which these properties hold, Nat is taken as the smallest one.\nRecursive types have amazing properties. For example the types Nat and Option[Nat] are equivalent! Indeed nat2opt and opt2nat are inverse bijections:\ndef opt2nat: Option[Nat] =\u003e Nat = { case Some(n) =\u003e Succ(n) case None =\u003e Zero } def nat2opt: Nat =\u003e Option[Nat] = { case Succ(n) =\u003e Some(n) case Zero =\u003e None } opt2nat :: Maybe Nat -\u003e Nat opt2nat (Just n) = Succ n opt2nat Nothing = Zero nat2opt :: Nat -\u003e Maybe Nat nat2opt (Succ n) = Just n nat2opt Zero = Nothing It means that Nat ‚âÖ Option[Nat]. Note that Option[T] ‚âÖ Either[Unit, T] ‚âÖ 1 + T in Type Theory notation, so Nat is actually one of the solution of the type equation T ‚âÖ 1 + T. Such an equation means we are looking for types T such that T and Option[T] are equivalent. Regarding Option as a function from types to type, where the type Option[T] is the one obtained by applying the argument T to the function Option, Nat is one of the fixed-point of this function. More precisely, Nat is the least fixed-point of Option.\nLet Œº: (Type -\u003e Type) -\u003e Type be the operator taking a type function F as argument (written F[_] in Scala and f :: * -\u003e * in haskell) and returning the least fixed-point of F, which is defined as the smallest type T (up to equivalence) which is solution of the equation T ‚âÖ F[T]. To simplify the notations, we may also write ŒºT.F[T] instead of Œº(F).\nAs an example Nat = Œº(Option) which we also write Nat = ŒºT.Either[Unit, T] and also Nat = ŒºT.(1 + T).\nAnother solution to the equation, which is, this time the greatest fixed-point of Option is the type NatInf, representing {0, 1, 2, ..., ‚àû}, defined as below. It is the biggest type which is solution (up to equivalence) of the equation T ‚âÖ 1 + T. The two inverse functions opt2natInf and natInf2opt proves the equivalence:\ntrait NatInf { def unfold: Option[NatInf] } val zero: NatInf = new NatInf { def unfold: Option[NatInf] = None } def succ(n: NatInf): NatInf = new NatInf { def unfold: Option[NatInf] = Some(n) } val ‚àû : NatInf = new NatInf { def unfold: Option[NatInf] = Some(‚àû) } def opt2natInf: Option[NatInf] =\u003e NatInf = { case Some(n) =\u003e succ(n) case None =\u003e zero } def natInf2opt: NatInf =\u003e Option[NatInf] = (n: NatInf) =\u003e n.unfold newtype NatInf = NatInf { unfold :: Maybe NatInf } zero :: NatInf zero = NatInf Nothing succ :: NatInf -\u003e NatInf succ n = NatInf (Just n) inf :: NatInf inf = NatInf (Just inf) opt2natInf :: Maybe NatInf -\u003e NatInf opt2natInf (Just n) = succ n opt2natInf Nothing = zero natInf2opt :: NatInf -\u003e Maybe NatInf natInf2opt = unfold Equivalence of inductive and functional definitions Nat can be equivalently defined as a data type NatInd as well as a function type NatFun. Inverse bijections ind2fun and fun2ind prove NatInf and NarInd are equivalent:\nsealed abstract class NatInd final case object ZeroInd extends NatInd final case class SuccInd(n: NatInd) extends NatInd trait NatFun { def fold[A](zero: A, succ: A =\u003e A): A } val zeroFun : NatFun = new NatFun { def fold[A](zero: A, succ: A =\u003e A): A = zero } def succFun(n: NatFun) : NatFun = new NatFun { def fold[A](zero: A, succ: A =\u003e A): A = { val a = n.fold[A](zero, succ) succ(a) } } def ind2fun: NatInd =\u003e NatFun = (i: NatInd) =\u003e i match { case ZeroInd =\u003e zeroFun case SuccInd(p) =\u003e val n = ind2fun(p) succFun(n) } def fun2ind: NatFun =\u003e NatInd = (n: NatFun) =\u003e n.fold[NatInd](ZeroInd, SuccInd(_)) data NatInd where ZeroInd :: NatInd SuccInd :: NatInd -\u003e NatInd type NatFun = forall a. a -\u003e (a -\u003e a) -\u003e a zeroFun :: NatFun zeroFun z _ = z succFun :: NatFun -\u003e NatFun succFun n z s = s (n z s) ind2fun :: NatInd -\u003e NatFun ind2fun ZeroInd = zeroFun ind2fun (SuccInd n) = succFun (ind2fun n) fun2ind :: NatFun -\u003e NatInd fun2ind n = n ZeroInd SuccInd Lists Similarly, given a type A, we want to define the the type of lists whose elements are of type A, written List[A]. Let l:List[A] be a list whose elements are of type A. There are two cases: either the list is empty or it is not. Let‚Äôs call the the empty list Nil. If the list is not empty, let head be its first element and tail the rest of the list (i.e. the same list as l but without the first element head). Then tail is also a list of type List[A] and l can be obtained by prepending head to tail. We will write this prepending operation Cons :: (A, List[A]) =\u003e List[A] such that l = Cons(head, tail).\nOnce again we see we have two constructors: Nil of type List[A] and Cons of type (A, List[A]) =\u003e List[A]. Besides, these constructors satisfy the usual thee properties:\nconstructors are injective different constructors produces different value every value of type List[A] is either a Nil or a Cons(head, tail) for some head:A and some tail:List[A] Furthermore List[A] is the smallest type satisfying these properties. It can easily be defined in Scala as\nsealed abstract class List[+A] { def fold[R](nil: R, cons: (A,R) =\u003e R): R = this match { case Nil =\u003e nil case Cons(head,tail) =\u003e val r = tail.fold[R](nil, cons) cons(head, r) } } final case object Nil extends List[Nothing] final case class Cons[+A](head: A, tail: List[A]) extends List[A] Like any recursive data type, List[A] is the smallest solution of a type equation. This time the equation is T ‚âÖ 1 + (A, T) which in a more Scalaish syntax is T ‚âÖ Option[(A, T)]. Equivalently, List[A] is also the least fixed-point of the type-function:\ntype F[T] = Option[(A, T)] Which means List[A] = ŒºT.(1 + A √ó T). The biggest type which is solution (up to equivalence) of the equation, which is the greatest fixed-point of F is the type of streams whose elements are of type A, written Stream[A]:\ntrait Steam[A] { def unfold: Option[(A, Stream[A])] } newtype Stream a = Stream { runStream :: forall c. (Maybe (a, Stream a) -\u003e c) -\u003e c } Exercise: write the bijections proving Stream[A] ‚âÖ Option[(A, Stream[A])]\nEquivalence of inductive and functional definitions List[A] can equivalently be defined as the data type ListInd[A] as well as the type function ListFun[A]. The two inverse functions ind2fun and fun2ind prove ListInd[A] and ListFun[A] are equivalent:\nsealed abstract class ListInd[+A] final case object NilInd extends ListInd[Nothing] final case class ConsInd[+A](head: A, tail: ListInd[A]) extends ListInd[A] trait ListFun[+A] { def fold[R](nil: R, cons: (A,R) =\u003e R): R } def nilFun[A]: ListFun[A] = new ListFun[A] { def fold[R](nil: R, cons: (A,R) =\u003e R): R = nil } def consFun[A](head: A, tail: ListFun[A]): ListFun[A] = new ListFun[A] { def fold[R](nil: R, cons: (A,R) =\u003e R): R = { val r = tail.fold[R](nil, cons) cons(head, r) } } def ind2fun[A]: ListInd[A] =\u003e ListFun[A] = (i: ListInd[A]) =\u003e i match { case NilInd =\u003e nilFun[A] case ConsInd(head, tail) =\u003e val tailFun = ind2fun(tail) consFun(head, tailFun) } def fun2ind[A]: ListFun[A] =\u003e ListInd[A] = (f: ListFun[A]) =\u003e f.fold[ListInd[A]](NilInd, ConsInd(_,_)) data ListInd a where NilInd :: ListInd a ConsInd :: a -\u003e ListInd a -\u003e ListInd a type ListFun a = forall r. r -\u003e (a -\u003e r -\u003e r) -\u003e r nilFun :: ListFun a nilFun nil _ = nil consFun :: a -\u003e ListFun a -\u003e ListFun a consFun head tail nil cons = cons head (tail nil cons) ind2fun :: ListInd a -\u003e ListFun a ind2fun NilInd = nilFun ind2fun (ConsInd head tail) = consFun head (ind2fun tail) fun2ind :: ListFun a -\u003e ListInd a fun2ind f = f NilInd ConsInd Algebraic Data Types Algebraic Data Types are types that can be expressed using only False, Unit, products, coproducts and the least fixed-point operator Œº. For example, binary trees whose elements are of type A, defined in Scala by\nsealed abstract class Tree[+A] { def fold[R](empty: R, leaf: A =\u003e R, node: (R, R) =\u003e R): R = this match { case Empty =\u003e empty case Leaf(a) =\u003e leaf(a) case Node(l, r) =\u003e val al = l.fold[R](empty, leaf, node) val ar = r.fold[R](empty, leaf, node) node(al, ar) } } final case object Empty extends Tree[Nothing] final case class Leaf[+A](value: A) extends Tree[A] final case class Node[+A](left: Tree[A], right: Tree[A]) extends Tree[A] can be expressed as the type Tree[A] = ŒºT.(1 + A + (T √ó T)), which is the smallest type (up to equivalence) solution of the equation T ‚âÖ Either3[Unit, A, (T, T)].\nExercise: write the bijection proving the equivalence.",
    "description": "In today's episodes, let's see how to type recursive data such as lists and trees.",
    "tags": [],
    "title": "Episode 5 - Recursive Data Types",
    "uri": "/types/5-rectypes/index.html"
  },
  {
    "breadcrumb": "Introduction to Types",
    "content": "CoProducts, often called sum types, discriminated unions or disjoint unions, are a convenient way to express an alternative between different types. The coproduct of n types (with n being 0, 1, 2, etc) A_1, A_2, ‚Ä¶, A_n is precisely the type whose values are (i, a_i) where i is a number, called the tag, between 1 and n both included (1 ‚â§ i ‚â§ n) and a_i is a value of type A_i (the actual type then depends on the value of i). Is is often written Either[A_1, ..., A_n] in programming and A_1 + ... + A_n in Type Theory.\nLet‚Äôs take, as an example, n = 4, A_1 = Char, A_2 = Boolean, A_3 = Char and A_4 = Double. The following values are all valid and distinct values of type Either4[Char, Boolean, Char, Double]: (1, 'C'), (2, true), (3, 'D'), (4, 3.2), (3, 'C'). Note that (1, 'C') and (3, 'C') are different values because the tag is different.\nInstead of writing the tag explicitly, programming languages often let us write n constructors: Inj_i: A_i =\u003e Either_n[A_1, ..., A_n] such that $$\\forall i\\in{1,\\dots,n},\\quad \\texttt{Inj}_i : \\texttt{A}_i \\rightarrow \\texttt{Either}_n[\\texttt{A}_1,\\dots,\\texttt{A}_n]$$ $$\\forall i\\in{1,\\dots,n},\\quad \\forall a_i:\\texttt{A}_i,\\quad \\texttt{Inj}_i(a_i) = (i, a_i)$$Note that:\nAs usual constructors are injective functions $$\\forall i\\in{1,\\dots,n},\\quad \\forall a_i,a'_i:\\texttt{A}_i,\\quad \\texttt{Inj}_i(a_i) = \\texttt{Inj}_i(a'_i) \\Leftrightarrow a_i = a'_i$$ The only way to get a value of type Either_n[A_1, ... , A_n] is by using one of the constructors $$\\forall v:\\texttt{Either}_n[\\texttt{A}_1,\\dots,\\texttt{A}_n],\\quad \\exists! i\\in{1,\\dots,n},\\quad \\texttt{Inj}_i(a_i) = v$$ Two different constructors produce different values (hense the disjoint and discriminated unions) $$\\forall i,j\\in{1,\\dots,n},\\quad \\forall a_i:\\texttt{A}_i,\\quad \\forall a_j:\\texttt{A}_j,\\quad \\texttt{Inj}_i(a_i) = \\texttt{Inj}_j(a_j) \\Leftrightarrow i = j \\textbf{ and } a_i = a_j$$ For example with n = 2, the coproduct of two types A and B is defined as\nsealed abstract class Either2[A,B] { def fold[R](inj1: A =\u003e R, inj2: B =\u003e R): R = this match { case Inj1(a) =\u003e inj1(a) case Inj2(b) =\u003e inj2(b) } } final case class Inj1[A,B](value: A) extends Either2[A,B] final case class Inj2[A,B](value: B) extends Either2[A,B] Saying the pattern matching above is exhaustive is exactly equivalent to say a value of type Either2[A,B] has to be either Inj1(a) for some a:A or Inj2(b) for some b:B. Requiring that Inj1 and Inj2 produce different values is also mandatory as Eirher2[Error, Result] is often used to model computation that may fail. A failed computation would produce a Inj1(e) with e being the error that occurred while a successful computation would produce a Inj2(r) with r the result of the computation. We want to be able to discriminate these two cases, even when the types Error and Result are the same as it is usually the case when the computation need to compute a string or fail with an error message. Likewise, the injectivity of the constructors is mandatory to be able to the result produced r or the error that occurred e.\nEquivalence of inductive and functional forms Once again any *coproduct√π can be equivalently expressed as a data type Either_n_Ind[A_1, ..., A_n] and as a function type Either_n_Fun[A_1, ..., A_n] with inverse functions ind2fun and fun2ind converting back and forth types Either_n_Ind[A_1, ..., A_n] and Either_n_Fun[A_1, ..., A_n]. For example with n = 2:\nsealed abstract class Either2Ind[A,B] final case class Inj1_Ind[A,B](value: A) extends Either2Ind[A,B] final case class Inj2_Ind[A,B](value: B) extends Either2Ind[A,B] trait Either2Fun[A,B] { def fold[R](inj1: A =\u003e R, inj2: B =\u003e R): R } def inj1_fun[A,B]: A =\u003e Either2Fun[A,B] = (a: A) =\u003e new Either2Fun[A,B] { def fold[R](inj1: A =\u003e R, inj2: B =\u003e R): R = inj1(a) } def inj2_fun[A,B]: B =\u003e Either2Fun[A,B] = (b: B) =\u003e new Either2Fun[A,B] { def fold[R](inj1: A =\u003e R, inj2: B =\u003e R): R = inj2(b) } def ind2fun[A,B]: Either2Ind[A,B] =\u003e Either2Fun[A,B] = (i: Either2Ind[A,B]) =\u003e i match { case Inj1_Ind(a) =\u003e inj1_fun(a) case Inj2_Ind(b) =\u003e inj2_fun(b) } def fun2ind[A,B]: Either2Fun[A,B] =\u003e Either2Ind[A,B] = (f: Either2Fun[A,B]) =\u003e f.fold[Either2Ind[A,B]](Inj1_Ind[A,B] _, Inj2_Ind[A,B] _) data Either2Ind a b where Inj1_Ind :: a -\u003e Either2Ind a b Inj2_Ind :: b -\u003e Either2Ind a b type Either2Fun a b = forall c. (a -\u003e c) -\u003e (b -\u003e c) -\u003e c inj1_fun :: a -\u003e Either2Fun a b inj1_fun a f _ = f a inj2_fun :: b -\u003e Either2Fun a b inj2_fun b _ g = g b ind2fun :: Either2Ind a b -\u003e Either2Fun a b ind2fun (Inj1_Ind a) = inj1_fun a ind2fun (Inj2_Ind a) = inj2_fun a fun2ind :: Either2Fun a b -\u003e Either2Ind a b fun2ind f = f Inj1_Ind Inj2_Ind Generalization to a product of any number of types The definition of Either2 above can be adapted to Either_n[A_1, ..., A_n] for any value of n (i.e. 0, 1, 2, 3, 4, ‚Ä¶). With n = 0, which means a coproduct of zero types, there is no constructor, which means it is impossible to build a value of this type. Thus Either_0 is equivalent to False (i.e. Either_0 ‚âÖ False). With n = 1, Either_n[A] ‚âÖ A.\nFurther more for any types A, B and C we have the following properties\nEither2[A,B] is equivalent to Either2[B,A] Either2[Either2[A,B], C] and Either2[A, Either2[B,C]] and Either3[A,B,C] are all equivalent Eithr2[False,A] and Either2[A,False] and A are all equivalent Either_1[A] is equivalent to A (C, Either2[A,B]) is equivalent to Either2[(C,A), (C,B)] Exercise: write conversion functions from and tofor each of these equivalence, such that from and to are inverse functions.\nRemember that in Type Theory, False is written 0, Unit is written 1, the product (A_1, ..., A_n) is written A_1 √ó ... A_n and the coproduct Either_n[A_1, ..., A_n] is written A_1 + ... + A_n. If we express the above properties using Type Theory notation, we get\nA + B ‚âÖ B + A (A + B) + C ‚âÖ A + (B + C) ‚âÖ A + B + C 0 + A ‚âÖ A + 0 ‚âÖ A C √ó (A + B) ‚âÖ (C √ó A) + (C √ó B) 1 √ó A ‚âÖ A 0 √ó A ‚âÖ A √ó 0 ‚âÖ 0 Is arithmetic familiar to you? If so such equations should be familiar too. But these times there are not between numbers but between equivalent types. If you ever wonder why Algebraic Data Types are called this way, this should give you some hints.\nNext Episode: Recursive Data Types In the next episode, we will see Recursive Data Types.",
    "description": "CoProducts, often called sum types, discriminated unions or disjoint unions, are a convenient way to express an alternative between different types. The coproduct of n types (with n being 0, 1, 2, etc) A_1, A_2, ‚Ä¶, A_n is precisely the type whose values are (i, a_i) where i is a number, called the tag, between 1 and n both included (1 ‚â§ i ‚â§ n) and a_i is a value of type A_i (the actual type then depends on the value of i). Is is often written Either[A_1, ..., A_n] in programming and A_1 + ... + A_n in Type Theory.",
    "tags": [],
    "title": "Episode 4 - CoProducts",
    "uri": "/types/4-coproducts/index.html"
  },
  {
    "breadcrumb": "Introduction to Types",
    "content": "Products, often called tuples, records or case classes, are a convenient way to bundle values of different types into a single value. The product of n types (with n being 0, 1, 2, etc) A_1, A_2, ‚Ä¶, A_n is precisely the type whose values are formed with exactly one value of each type A_i for 1 ‚â§ i ‚â§ n. It is written (A_1, A_2, ..., A_n) in many languages, Product_n[A_1, A_2, ..., A_n] in Scala and A_1 √ó ... √ó A_n in Type Theory. As an example, the product of two types A and B would be defined as\nfinal case class Product2[A, B](a: A, b: B) { def fold[R](f: (A, B) =\u003e R): R = f(a,b) } data Product2 a b = Constructor a b Although in practice this is the preferred way to define the product of two types A and B, we will in this presentation prefer the equivalent definition below:\nsealed abstract class Product2[A,B] { def fold[C](f: (A, B) =\u003e C): C = this match { case Constructor(a,b) =\u003e f(a,b) } } final case class Constructor[A,B](a: A, b: B) extends Product2[A,B] data Product2 a b where Constructor :: a -\u003e b -\u003e Product2 a b This equivalent definition makes clear the distinction between the type Product2[A,B] and the constructor Constructor[A,B]. the constructor is a function taking as argument one value of type A, another value of type B and returning a value of type Product2[A,B]. Its type in Haskell is A -\u003e B -\u003e Product2 A B and in Scala (A, B) =\u003e Product2[A,B]. Note than in Scala functions of type (A, B) =\u003e C are functions of two arguments (precisely Function2[A,B,C]) and not of one argument (A,B) (which would be Function1[(A,B), C]):\nscala\u003e Constructor[Int, String] _ : ( (Int, String) =\u003e Product2[Int, String] ) res0: (Int, String) =\u003e Product2[Int,String] = $$Lambda$1620/2032136633@55be2608 Prelude\u003e :t Constructor Constructor :: a -\u003e b -\u003e Product2 a b Besides, by definition constructors are injective functions, which means that for any values a1:A, a2:A, b1:B and b2:B, Constructor[A,B](a1,b1) == Constructor[A,B](a2,b2) if and only if a1 == a2 and b1 == b2 $$\\forall a1,\\ a2:\\texttt{A},\\ b1,\\ b2:\\texttt{B},\\quad \\texttt{Constructor[A,B]}(a1,b1) = \\texttt{Constructor[A,B]}(a2,b2) \\Longleftrightarrow a1 = a2 \\textbf{ and } b1 = b2$$Besides, Constructor[A,B] being the only constructor of Product2[A,B] then for any value v of type Product2[A,B], there is a unique value a of type A and a unique value b of type B such that v = Constructor[A,B](a,b) $$\\forall v:\\texttt{Product2[A,B]}\\ \\exists!\\ (a:\\texttt{A} \\textrm{ and } b:\\texttt{B}),\\quad v = \\texttt{Constructor[A,B]}(a,b)$$Equivalence of inductive and functional forms Once again any product can be equivalently expressed as a data type Product_n_Ind[A_1, ..., A_n] and as a function type Product_n_Fun[A_1, ..., A_n] with inverse functions ind2fun and fun2ind converting back and forth types Product_n_Ind[A_1, ..., A_n] and Product_n_Fun[A_1, ..., A_n]. For example with n = 2:\nsealed abstract class Product2Ind[A,B] final case class ConstructorInd[A,B](a: A, b: B) extends Product2Ind[A,B] trait Product2Fun[A,B] { def fold[C](f: (A, B) =\u003e C): C } def constructorFun[A,B](a: A, b: B): Product2Fun[A,B] = new Product2Fun[A,B] { def fold[C](f: (A, B) =\u003e C): C = f(a, b) } def ind2fun[A,B]: Product2Ind[A,B] =\u003e Product2Fun[A,B] = (i: Product2Ind[A,B]) =\u003e i match { case ConstructorInd(a,b) =\u003e constructorFun(a,b) } def fun2ind[A,B]: Product2Fun[A,B] =\u003e Product2Ind[A,B] = (f: Product2Fun[A,B]) =\u003e f.fold[Product2Ind[A,B]](ConstructorInd[A,B] _) data Product2Ind a b where ConstructorInd :: a -\u003e b -\u003e Product2Ind a b type Product2Fun a b = forall c. (a -\u003e b -\u003e c) -\u003e c constructorFun :: a -\u003e b -\u003e Product2Fun a b constructorFun a b f = f a b ind2fun :: Product2Ind a b -\u003e Product2Fun a b ind2fun (ConstructorInd a b) = constructorFun a b fun2ind :: Product2Fun a b -\u003e Product2Ind a b fun2ind f = f ConstructorInd Generalization to a product of any number of types The definition of Product2 above can be adapted to Product_n[A_1, ..., A_n] for any value of n (i.e. 0, 1, 2, 3, 4, ‚Ä¶). With n = 0, which means a product of zero types, the constructor takes zero argument, which means it is a constant. Thus Product_0 is equivalent to Unit (i.e. Product_0 ‚âÖ Unit). This is the reason why Unit is sometimes written (). With n = 1, Product_n[A] ‚âÖ A.\nFurther more for any types A, B and C we have the following properties\n(A , B) is equivalent to (B , A) ((A, B), C) and (A, (B, C)) and (A, B, C) are all equivalent (Unit, A) and (A, Unit) and A are all equivalent (A) is equivalent to A (False, A) and (A, False) and False are all equivalent Exercise: write conversion functions from and tofor each of these equivalence, such that from and to are inverse functions.\nNext Episode: CoProducts In the next episode, we will a convenient way to express alternatives: CoProducts.",
    "description": "Products, often called tuples, records or case classes, are a convenient way to bundle values of different types into a single value. The product of n types (with n being 0, 1, 2, etc) A_1, A_2, ‚Ä¶, A_n is precisely the type whose values are formed with exactly one value of each type A_i for 1 ‚â§ i ‚â§ n. It is written (A_1, A_2, ..., A_n) in many languages, Product_n[A_1, A_2, ..., A_n] in Scala and A_1 √ó ... √ó A_n in Type Theory. As an example, the product of two types A and B would be defined as",
    "tags": [],
    "title": "Episode 3 - Products",
    "uri": "/types/3-products/index.html"
  },
  {
    "breadcrumb": "Introduction to Types",
    "content": "Now that we know what types are and why there are useful, it is about time to meet some remarkable ones. But before we start, there is some important things to state. As a developer i know how tempting it is to search ready-to-paste answers. But the subject of these post series is nothing like a ready-to-paste answers cookbook. On the contrary, this is a presentation of deep, difficult but rewarding concepts. Do not see them as patterns to follow blindly, like it is unfortunately too often the case in our field. Instead, take the time to develop a deep understanding of what is really going on.\nAs such, the example i give may look simple. They are indeed much simpler than in real-life applications. They are not meant to be applicable as-is but to shed light on the core ideas. If you understand the principles they rely on, you‚Äôll be able to apply these powerful concepts in your day to day code. Do not skim through this but take the time to develop your understanding.\nIn this whole series is we will assume null (in Scala), undefined (in Haskell) and side-effects do not exist. null, undefined and side-effects are absurd in every possible way. They make interesting properties collapse and should be avoided at all costs! We will consider all functions from A to B to be mathematical functions:\nthey always return a valid value of type B of any input input value of type A on the same argument (or an equal argument), they always return the same result (or an equal result) the only effect of executing them is obtaining a result, no side-effect allowed If b:B = f(a:A) we can always replace b by f(a) and vice-versa, anywhere in the program, without altering its behavior (apart from computation time and memory consumption) Formally it means we will consider all functions referentially transparent and total. That being said, let the journey begin with a very useful concept.\nMany equivalent ways to express it There is often many ways to express the same idea. How would you represent a piece of text? The types List[Char] and String are two different ways to do so. These types are indeed not equal: they are not encoded the same way and have distinct performance properties. But despite their differences, they can be considered equivalent. There is indeed a one-to-one correspondence between them: we can define two functions list2string: List[Char] =\u003e String and string2list: String =\u003e List[Char]:\ndef list2string: List[Char] =\u003e String = (l:List[Char]) =\u003e l.foldLeft(\"\") { case (str,char) =\u003e s\"$str$char\" } def string2list: String =\u003e List[Char] = (str: String) =\u003e str.toList such that list2string and string2list are the inverse of each other $$\\forall s:\\texttt{String},\\quad \\texttt{string2list}(\\texttt{list2string}(s)) = s$$ $$\\forall l:\\texttt{List[Char]},\\quad \\texttt{list2string}(\\texttt{string2list}(l)) = l$$which also means\nfor any list there is a unique string $$\\forall l:\\texttt{List[Char]}\\ \\exists! s:\\texttt{String} ,\\quad \\texttt{string2list}(s) = l$$ for any string there is a unique list $$\\forall s:\\texttt{String}\\ \\exists! l:\\texttt{List[Char]},\\quad \\texttt{string2list}(\\texttt{list2string}(s)) = s$$ list2string and string2list are injective $$\\forall l1, l2:\\texttt{List[Char]},\\ \\texttt{list2string}(l1) = \\texttt{list2string}(l2) \\implies l1 = l2$$ $$\\forall s1, s2:\\texttt{String},\\ \\texttt{string2list}(s1) = \\texttt{string2list}(s2) \\implies s1 = s2$$ Basically it means we can always convert from one type to the other without loss of generality.\nFor any function f: A =\u003e B (i.e. from A to B), f is called a bjection if and only if there exists a function g: B =\u003e A (i.e. from B to A) such that f and g are inverse of each other: $$\\forall a:\\texttt{A},\\quad \\texttt{g}(\\texttt{f}(a)) = a$$ $$\\forall b:\\texttt{B},\\quad \\texttt{f}(\\texttt{g}(b)) = b$$ Two types A and B are called equivalent, which is written A ‚âÖ B, if and only if there exists a bijection f: A =\u003e B.\nThis notion is fundamental as it tells us that similarity between types is how closely they behave, not how closely they look. Two types of apparent very different form may actually be equivalent while two whose form may seem close may be fundamentally at odds. Focus on properties, not on looks.\nThe empty type The first type i want to present has many names. Scala names it Nothing, Elm calls it Never, Coq uses the name it usually has in Proof Theory which is False while Type Theory refers to it as 0. This is an uninhabited type which means there is no value of this type. You may look at it as the empty set (hence the name 0):\nfinal abstract class False { def fold[A]: A } This class being final we cannot define sub-classes, but being also abstract we cannot instantiate it either! And even if we could, how would we write a function fold which meets the specification that it provides a value of type A for any A? Remember, null does not exists.\nHow a type without values can be useful? By representing impossible cases in the type-system. Let v be a value of type Either[False, Int]. v has to be Right(i) for some integer i because otherwise it would be Left(f) for some value f of type False which is impossible! It means the following pattern-matching is exhaustive.\ndef extractRight[A](v: Either[False,A]): A = v match { case Right(a) =\u003e a } Unfortunately Scala protests it‚Äôs not, demanding we cover the case v = Left(f: False) by returning a value of type A. We know, assuming null does not exists, there can not be such a value f:False. How to make Scala happy? Fortunately, every hypothetical value of type False comes with a handy fold function able to return anything. It corresponds in logic to the principle of explosion stating that from a contradicton (having a value of an empty type for example), you can conclude anything:\ndef extractRight[A](v: Either[False,A]): A = v match { case Right(a) =\u003e a case Left(f) =\u003e f.fold[A] } Note that extractRight and Right:A =\u003e Either[False, A] being inverse functions it means Either[False, A] is equivalent to A. This one is of the main properties of False: Either[False, A], Either[A, False] and A are all equivalent (i.e. Either[False, A] ‚âÖ A ‚âÖ Either[A, False]).\nYou could argue using Either[False, A] is pointless as it is equivalent to A which is true, but bare in mind it is just a toy example. A more realistic one would involve complex types such as bifunctors like IO[E,A]. The ability to express impossible cases let us write IO computations that never fails IO[False, A] and IO computation that never returns IO[E,False] with the same code and API instead of relying on code/API duplication which is a waste of time, effort and complexity.\nThe idea being False can be expressed in many equivalent ways. The three types False, FalseInd and FalseFun are equivalent (``False ‚âÖ FalseInd ‚âÖ FalseFun`):\nfinal abstract class FalseInd trait FalseFun { def fold[A]: A } This is even clearer in Haskell as shown below where ind2fun and fun2ind are inverse functions.\n{-# LANGUAGE RankNTypes, EmptyCase #-} module Iso where data FalseInd type FalseFun = forall a. a ind2fun :: FalseInd -\u003e FalseFun ind2fun x = case x of { } fun2ind :: FalseFun -\u003e FalseInd fun2ind x = x In Scala like in Haskell FalseInd express the idea of a data type with no constructor (i.e. to way to build a value) while FalseFun is the type of a function with no argument (i.e. a constant) returning values of type A for any A, but such a function does not exists. It may seem weird having functions between empty types but it actually makes a lot of sense: there is indeed a one-to-one correspondence between these two types as both have no values at all.\nThe singleton type Often called unit, () or 1, it is the type with only one value.\nsealed abstract class Unit { def fold[A](x: A): A = this match { case Unique =\u003e x } } final case object Unique extends Unit Note that the type Unit admits one and exactly one value which is UniqueInd. UniqueInd is called a constructor of the data type Unit as it one way (the only one actually) to build a value of type Unit. Unit is useful everywhere you have to fill a value and/or a type but you actually don‚Äôt care which. For example, let v = println(\"Hello World\"):IO[Unit] be the value printing a message to the screen. We don‚Äôt care what the execution v returns, we are only interested into what is printed, but it still needs to return something for the program to continue.\nOnce again Unit can be equivalently expressed as both the data type UnitInd and the function type UnitFun. Indeed ind2fun and fun2ind are inverse functions showing Unit ‚âÖ UnitInd ‚âÖ UnitFun.\nsealed abstract class UnitInd final case object UniqueInd extends UnitInd trait UnitFun { def fold[A](x: A): A } val uniqueFun: UnitFun = new UnitFun { def fold[A](x: A): A = x } def ind2fun: UnitInd =\u003e UnitFun = (i: UnitInd) =\u003e i match { case UniqueInd =\u003e uniqueFun } def fun2ind: UnitFun =\u003e UnitInd = (f: UnitFun) =\u003e f.fold[UnitInd](UniqueInd) data UnitInd where UniqueInd :: UnitInd type UnitFun = forall a. a -\u003e a uniqueFun :: UnitFun uniqueFun x = x ind2fun :: UnitInd -\u003e UnitFun ind2fun UniqueInd = uniqueFun fun2ind :: UnitFun -\u003e UnitInd fun2ind u = u UniqueInd The type UnitFun may surprise you. How is it possible that a function type like it has only one possible value? Try to write a referentially transparent and total instance of UnitFun. You will see there is only one way to do so.\nOne of the main properties of Unit is that (Unit, A), (A, Unit) and A are equivalent (i.e. (Unit, A) ‚âÖ A ‚âÖ (A, Unit)). Exercise: write the inverse functions between these types.\nThe two values type: Booleans Here comes one of the most well known type: the one with exactly two values often called Boolean in programming and 2 in Type Theory. Its values are generally named true and false:\nsealed abstract class Boolean { def fold[A](tt: A, ff: A): A = this match { case True =\u003e tt case False =\u003e ff } } final case object True extends Boolean final case object False extends Boolean I‚Äôm sure you‚Äôre already familiar with booleans, but did you recognize the fold function? It is generally named if-then-else:\ndef ifThenElse[A](b: Boolean)(tt: A, ff: A): A = b.fold[A](tt, ff) True and False are called the constructors of Boolean because they are the only way to build values of type Boolean. Once again this idea of a type with two values is equivalently expressed both as the data type BoolInd and as the function type BoolFun . Functions ind2fun and fun2ind are indeed inverse of each other.\nsealed abstract class BoolInd final case object TrueInd extends BoolInd final case object FalseInd extends BoolInd trait BoolFun { def fold[A](tt: A, ff: A): A } val trueFun: BoolFun = new BoolFun { def fold[A](tt: A, ff: A): A = tt } val falseFun: BoolFun = new BoolFun { def fold[A](tt: A, ff: A): A = ff } def ind2fun: BoolInd =\u003e BoolFun = (i: BoolInd) =\u003e i match { case TrueInd =\u003e trueFun case FalseInd =\u003e falseFun } def fun2ind: BoolFun =\u003e BoolInd = (f: BoolFun) =\u003e f.fold[BoolInd](TrueInd, FalseInd) data BoolInd where TrueInd :: BoolInd FalseInd :: BoolInd type BoolFun = forall a. a -\u003e a -\u003e a trueFun :: BoolFun trueFun tt _ = tt falseFun :: BoolFun falseFun _ ff = ff ind2fun :: BoolInd -\u003e BoolFun ind2fun TrueInd = trueFun ind2fun FalseInd = falseFun fun2ind :: BoolFun -\u003e BoolInd fun2ind u = u TrueInd FalseInd Once again the type BoolFun may surprise you. Once again try to write a referentially transparent and total instance of BoolFun. You will see there are only two ways to do so.\nI could continue forever presenting types with 3, 4, ‚Ä¶ values but by now you must see the same pattern repeating and repeating again.\nNext Episode: Products In the next episode, we will a convenient way to combine types: Products.",
    "description": "This episode is about one of the simplest types: enumeations.",
    "tags": [],
    "title": "Episode 2 - Enumerations",
    "uri": "/types/2-enums/index.html"
  },
  {
    "breadcrumb": "Introduction to Types",
    "content": "Why using types? When are they useful? Why we should care about types? What are types? These are the questions this series of posts give some answers to. Let‚Äôs start by realizing a fundamental fact: types are everywhere! Business models are all about types: users, shipments, orders, etc. Placing a user in the cart or shipping a client just makes no sense. Types are specification, discriminating what makes sense from what makes not.\nA real life example They can be simple like the well known strings, integers, booleans, lists, chars and floating-point numbers. But these six are far from covering the whole picture. Take as an example, a business application about finding the best deal amount a list of prices expressed in various currencies. To do so it would need currency conversion rates. Which data structure would you use to store these rates? One euro (EUR) worths when i write these lines 1.13 dollars (USD) which i could represent as the triple (\"EUR\", 1.13 ,\"USD\"). To store many rates, using a list is straightforward:\nscala\u003e val rates = List( (\"EUR\", 1.13, \"USD\"), (\"GBP\", 142.79, \"JPY\") ) rates: List[(String, Double, String)] = List((EUR,1.13,USD), (GBP,142.79,JPY)) Are you sure the type (String, Double, String) is a faithful representation for rates? Among all the possible values of this type is (\"EUR\", -3.0, \"USD\") meaning when you give one euro, you have to pay three dollars more to get nothing. This is silly, currency trading don‚Äôt work that way. Another problematic value is (\"EUR\", 0, \"USD\"). What is the point in exchanging one euro for nothing? Using Double to encode rates is wrong as not all floating point number makes a valid rate, only those strictly positive! A faithful representation of rates is the type r:Double{r \u003e 0} which is the types of value r:Double such that r \u003e 0. Such types are called refinement types and used heavily in F*.\nWe‚Äôre not done yet! Are you sure String is faithful representation of currencies? The empty string \"\" is not a currency, neither are \"‚õ±\", \"‚õè\", etc but they are all valid strings. Assuming currencies:Set[String] is the set of all valid currency names, the type of currencies would be cur:String{currencies.contains(cur)} if it was expressible in Scala. But it is in F*:\nopen FStar.Set val currencies: set string let currencies = Set.as_set [\"EUR\"; \"USD\"; \"JPY\"] type currency = cur:string{Set.mem cur currencies} For the rest of this section, we will assume Scala has refinement types so that we can write:\ntype Rate = r:Double{r \u003e 0} val currencies: Set[String] = Set(\"EUR\", \"USD\", \"JPY\") type Currency = cur:String{currencies.contains(cur)} We‚Äôre still not done yet as the type (Currency, Rate, Currency) still does not faithfully encode a conversion rate: (\"EUR\", 2.0, \"EUR\") is a value of this type but one euro can not worth two euros, this would not make sense! We could define the type Rate such that the only possible value is 1.0 when there is the same currency on both sides, but for simplicity‚Äôs sake and without loss of generality, we will just forbid converting into the same currency. Once again, in a version of Scala with refinement and dependent types, conversion rates would be:\nfinal case class ConvRate( from: Currency, rate: Rate, to:Currency{from != to} ) We‚Äôre almost there! Now every value of ConvRate makes sense from a business perspective: currencies from and to are valid distinct currencies and rate is a strictly positive exchange rate. Does the type List[ConvRate] faithfully represents a valid set of conversion rates? Values like List(ConvRate(\"EUR\", 2.0, \"USD\"), ConvRate(\"EUR\", 1.13, \"USB\")), where there are several distinct rates for the same conversion, do not make sense. Likewise, there is a relation between a conversion rate and its opposite direction. If one euros worth 1.13 dollars, then one dollar worths 0.88 euros. Values like List(ConvRate(\"EUR\", 1.13, \"USD\"), ConvRate(\"USD\", 2.0, \"EUR\")) do not respect this rule, so are invalid business values. To be sure values do respect these business rules we can use the data structure Map and only allow one side of the conversion (from \u003c to) in the type ConversionRates:\nval currencies: Set[String] = Set(\"EUR\", \"USD\", \"JPY\") final case class Conversion( from: String{currencies.contains(from)}, to: String{currencies.contains(to) \u0026\u0026 from \u003c to } ) type ConversionRates = Map[Conversion, rate:Double{rate \u003e 0}] The type ConversionRates is certainly more complex than List[(String, Double, String)] but we gained several major benefits:\nevery piece of code taking ConversionRates values as input is sure they respect business rules. every piece of code outputting ConversionRates values is guaranteed to respect business rules. division by zero is impossible! no need to check! no risk of exceptions! no need to write tests! no need to test the tests! Conclusion You may think you are such an excellent developer than all of this is useless because you would never define a negative rate or an empty string currency. But how could you be sure that the previous developers on the project were as perfect as you? Have you written the thousands of tests required to reach the same level of confidence types provide? Will you be happy refactoring those thousands of test every time the specification change? Are you sure you know perfectly every one of the millions ones of the project? Even the one you never had to work with?\nIf we were as good as we think we are, there would not be null pointer exceptions, segfaults, exploits, undefined-is-not-a-function, java.util.NoSuchElementException: None.get and all the other so common bugs and vulnerabilities we see far too often! Software are complex beasts, made usually by many people, some who leave, some who join. Relying of people being perfect (perfect knowledge, perfect understanding, perfect execution) is not realistic.\nYou can see type systems as powerful linters whose job is to check your code. Types get more and more complex as business rules do from simple properties to heavy mathematical theorems.\nTypes are specification, so in an ideal world a program well-typed would be, by definition, a program without bugs. If you still find bugs in your application, it either means you need to tighten your types to fit the specification or your language‚Äôs type-system is not expressive enough to encode the specification.\nNext Episode In the next episode, we will see enumerations like you probably have never seen them before.",
    "description": "Types are more complex and nuanced than you may think. Let me show you.",
    "tags": [],
    "title": "Episode 1 - Why Types?",
    "uri": "/types/1-why/index.html"
  },
  {
    "breadcrumb": "",
    "content": "Why using types? When are they useful? Why we should care about types? What are types? These are the questions this series of posts give some answers to.\nEpisode 1 - Why Types? 16 Dec 2018 - 1100 Words\nTypes are more complex and nuanced than you may think. Let me show you.\nRead more ‚Üí Episode 2 - Enumerations 16 Dec 2018 - 2100 Words\nThis episode is about one of the simplest types: enumeations.\nRead more ‚Üí Episode 3 - Products 16 Dec 2018 - 800 Words\nRead more ‚Üí Episode 4 - CoProducts 16 Dec 2018 - 1100 Words\nRead more ‚Üí Episode 5 - Recursive Data Types 16 Dec 2018 - 2000 Words\nIn today's episodes, let's see how to type recursive data such as lists and trees.\nRead more ‚Üí",
    "description": "A short and informal introduction to type theory.",
    "tags": [],
    "title": "Introduction to Types",
    "uri": "/types/index.html"
  },
  {
    "breadcrumb": "Posts",
    "content": "Today we will meet an amazing family: the fold functions!\nThe well known foldRight Lists is one of the first data structure every developer/computer scientist meet in her/his journey into programming:\nsealed abstract class List[+A] final case object Nil extends List[Nothing] final case class Cons[+A](head: A, tail: List[A]) extends List[A] It means means values of type List[A] can be of (only) two forms:\neither Nil or Cons(head, tail) for some values head of type A and tail of type List[A] For example we can define the following lists:\nval empty : List[Int] = Nil val l1 : List[Int] = Cons(61, Nil) val l2 : List[Int] = Cons(34, Cons(61, Nil)) val l3 : List[String] = Cons(\"a\", Cons(\"b\", Cons(\"c\", Nil))) In addition, Nil and Cons can be seen as constants and functions returning List[A]:\ndef nil[A]: List[A] = Nil def cons[A](head: A, tail: List[A]): Lis[A] = Cons(head, tail) The fold function, often called foldRight, answers the question:\nWhat would have happened if, instead of having used Nil and Cons in the construction of a list l:List[A], we would have used another constant z:T and another function f:(A, T) =\u003e T for some type T?\nLet‚Äôs illustrate this using the previous examples:\nval empty : Int = 0 // z = 0 val v1 : Int = max(61, 0) // z = 0, f = max val v2 : Int = mult(34, mult(61, 1)) // z = 1, f = mult val v3 : String = concat(\"a\", concat(\"b\", concat(\"c\", \"\"))) -- z = \"\", f = concat The definition of foldRight illustrates well the transformation process. It deconstructs the list l:List[A] and replace Nil by z and Cons by f:\ndef foldList[A,T](z: T, f: (A,T) =\u003e T): List[A] =\u003e T = { def transform(l: List[A]): T = l match { case Nil =\u003e z case Cons(head, tail) =\u003e val transformedTail = transform(tail) f(head, transformedTail) } transform _ } The simple cases: Enum Types fold functions can be defined for a wide range of data structures. As a first example, let‚Äôs take this type:\nsealed abstract class SingletonType final case object SingleValue extends SingletonType The type SingletonType admits one and only one value: SingleValue. Folding over SingletonType means, replacing SingleValue by a constant z:T for some type T :\ndef foldSingletonType[T](z:T): SingletonType =\u003e T = { def transform(v: SingletonType): T = v match { case SingleValue =\u003e z } transform _ } While SingletonType has only one value, the type Boolean have exactly two values True and False:\nsealed abstract class Boolean final case object True extends Boolean final case object False extends Boolean So folding over Booleans mean, given a type T and two constants tt:T and ff:T, replacing True by tt and False by ff:\ndef foldBoolean[T](tt:T, ff:T): Boolean =\u003e T = { def transform(v: Boolean): T = v match { case True =\u003e tt case False =\u003e ff } transform _ } And so on for every enum type.\nBeyond enums You may start the see general process. If values of type C are build using constructors (Nil and Cons[A] for List[A], SingleValue for SingletonType, True and False for Boolean), then folding is all about transforming values of type C into another type T by replacing each constructor of C by a constant or function on T of the same shape. Let‚Äôs consider the type Either[A,B]:\nsealed abstract class Either[A,B] final case class Left[A,B](value: A) extends Either[A,B] final case class Right[A,B](value: B) extends Either[A,B] To transform values of type Either[A,B] into T we need two functions on T:\nLeft being of type A =\u003e Either[A,B] we need a function f: A =\u003e T. Right being of type B =\u003e Either[A,B] we need a function g: B =\u003e T. Then we can operate the transformation:\ndef foldEither[A,B,T](f: A =\u003e T, g: B =\u003e T): Either[A,B] =\u003e T = { def transform(v: Either[A,B]): T = v match { case Left(a) =\u003e f(a) case Right(b) =\u003e g(b) } transform _ } Recursive Types Folding over recursive types obey the previous rules. Recursion is handled by transforming sub-terms first. Let‚Äôs consider the type of binary trees:\nsealed abstract class Tree[+A] final case object Empty extends Tree[Nothing] final case class Node[+A](value:A, left: Tree[A], right: Tree[A]) extends Tree[A] To transform values of type Tree[A] into T we need:\nEmpty being a constant of type Tree[A], we need a constant z:T. Node being a function of type (A, Tree[A], Tree[A]) =\u003e Tree[A] we need a function f: (A, T, T) =\u003e T. Note how all occurrences of Tree[A] have been replaced by T in the type. Then we can operate the transformation:\ndef foldTree[A,T](z: T, f: (A, T, T) =\u003e T): Tree[A] =\u003e T = { def transform(v: Tree[A]): T = v match { case Empty =\u003e z case Node(a,l,r) =\u003e val g: T = transform(l) // Transforming sub-term l val d: T = transform(r) // Transforming sub-term r f(a,g,d) } transform _ } Generalized Algebraic Data Types (GADT) Instead of giving a formal definition of what Generalized Algebraic Data Types i will show you some examples.\nType Equalities Consider the type:\nsealed abstract class EmptyOrSingleton[A] final case object SingleValueIfAisInt extends EmptyOrSingleton[Int] This type looks very similar to SingletonType but, while SingleValue was always a value of SingletonType, SingleValueIfAisInt is only a value of EmptyOrSingleton[Int], i.e. when A is Int. So what happens to EmptyOrSingleton[A] when A is not Int? Then there is no constructor for EmptyOrSingleton[A] so no value for SingletonIfInt[A] (excluding null which we will pretend no to exist).\nGADTs are very useful to encode predicates over types. Imagine you have a value v:EmptyOrSingleton[A] for some type A (remember we pretend null does not exist). What could you say about A? The only way to get a value of type EmptyOrSingleton[A] is through SingleValueIfAisInt. Thus v is SingleValueIfAisInt which is of type EmptyOrSingleton[Int] so is v. We can conclude that A is actually Int. Not convinced? Let A be String, can you build a value of type EmptyOrSingleton[String] without using null? Try it.\nTo find how to fold EmptyOrSingleton[A] into T, let‚Äôs apply the technique we used in the previous sections. EmptyOrSingleton[A] has only one constructor, SingleValueIfAisInt, so we need a constant z:T. But SingleValueIfAisInt is not of type EmptyOrSingleton[A] but EmptyOrSingleton[Int]. The argument A matters so let T depend on A: we want to transform values of type EmptyOrSingleton[A] into T[A].\nSingleValueIfAisInt being of type EmptyOrSingleton[Int] we need a constant z:T[Int] Then we can operate the transformation:\ndef foldEmptyOrSingleton[A, T[_]](z: T[Int]): EmptyOrSingleton[A] =\u003e T[A] = { def transform(v: EmptyOrSingleton[A]): T[A] = v match { case SingleValueIfAisInt =\u003e z // Because we know A = Int } transform _ } foldEmptyOrSingleton means that, for some T[_], if you have a value z:T[Int] then you can transform any value EmptyOrSingleton[A] into T[A]. For example, let‚Äôs take\ntype T[X] = X =:= Int val z:T[Int] = implicitly[Int =:= Int] Then foldEmptyOrSingleton[A,T](z) gives us, for any value v:EmptyOrSingleton[A] a proof that A =:= Int. Another important use case is asserting type equality:\nsealed abstract class Eq[A,B] final case class Refl[X]() extends Eq[X,X] Any non-null value v:Eq[A,B] must be a Refl[X]() : Eq[X,X] for some X, then Eq[A,B] = Eq[X,X] proving that A = X = B. To transform a value of type Eq[A,B] into T[A,B] we need:\nRefl[X]() is essentially a constant of type Eq[X,X] for all type X (note: Scala write this type [X]Eq[X,X]). We need a constant z:T[X,X] for all type X (so the type [X]T[X,X]). Scala does not support transparent higher-ranked types, we need to emulate them with a trait: trait ElimRefl[T[_,_]] { def apply[X]: T[X,X] } Then we could have hoped to be able to operate the transformation like previous section. But given a value v:Eq[A,B], convincing Scala that A = B is a bit tough. Instead we can write the fold as a method:\nsealed abstract class Eq[A,B] { def fold[T[_,_]](z: ElimRefl[T]): T[A,B] } final case class Refl[X]() extends Eq[X,X] { def fold[T[_,_]](z: ElimRefl[T]): T[X,X] = z[X] } def foldEq[A, B, T[_,_]](z: ElimRefl[T]): Eq[A,B] =\u003e T[A,B] = (v:Eq[A,B]) =\u003e v.fold[T](z) Ingenious definition of T[_,_] leads to interesting results:\ntrait C[X] type T1[A,B] = C[A] =:= C[B] val z1: ElimRefl[T1] = new ElimRefl[T1] { def apply[X]: T1[X,X] = implicitly[C[X] =:= C[X]] } def transform[A,B]: Eq[A,B] =\u003e C[A] =:= C[B] = foldEq[A,B,T1](z1) Existential Quantification GADTs not only provide useful type equalities, they also offer existential quantification!\nsealed abstract class Ex[F[_]] { type hidden val value: hidden val evidence: F[hidden] } final case class MakeEx[F[_],A](value: A, evidence: F[A]) extends Ex[F] { type hidden = A } Any value v:Ex[F] has to be an instance of MakeEx[F,A] for some type A. Which means we have a value, v.value, of type A and an instance of the type-class F for A (for example an instance of Monoid[A] with F[X] = Monoid[X]).\nTo transform values of type Ex[F] into T we need:\nMakeEx[F[_],?] being of type [A](A, F[A]) =\u003e Ex[F] meaning: For_all_type A, (A, F[A]) =\u003e Ex[F], we need a function f of type [A](A, F[A]) =\u003e T. Scala still does not support transparent higher ranked types, we need to emulate them with another trait: trait ElimMakeEx[F[_],T] { def apply[A](value: A, evidence: F[A]): T } Then we can operate the transformation:\ndef foldEx[F[_], T](f: ElimMakeEx[F, T]): Ex[F] =\u003e T = { def transform(v: Ex[F]): T = v match { case w@MakeEx(value, evidence) =\u003e f[w.hidden](value, evidence) } transform _ } Duality In this post we have deduced the fold functions from the definition of each type. It is possible to do the opposite: each constructor can be derived from the fold function of its type. For example:\ntrait List[+A] { def fold[T](z:T, f: (A,T) =\u003e T): T } def nil[A]: List[A] = new List[A] { def fold[T](z:T, f: (A,T) =\u003e T): T = z } def cons[A](head:A, tail: List[A]): List[A] = new List[A] { def fold[T](z:T, f: (A,T) =\u003e T): T = f(head, tail.fold(z,f)) } def equality[A](l1: List[A], l2:List[A]): Boolean = ??? // Difficult but worthy exercice Conclusion I hope i convinced you folds are immensely useful. First, they let us write simply complex transform functions. But this not the most interesting property. It is sometimes easier to define a type by its fold function. Java, for example, does not have support for neither sealed classes nor pattern-matching. How could we define the List type so that Nil and Cons are the two only cases? The fold function forces any instance of List to fit into the desired shape (if some rules are obeyed like no null and no runtime-reflection). It can also happen that type-inference is not smart enough, fold function provide an alternative way which is often easier for the Scala type-checker.",
    "description": "Introduction to catamorphisms on Algebraic Data Types",
    "tags": [],
    "title": "Let's meet the charming fold family",
    "uri": "/posts/folds/index.html"
  },
  {
    "breadcrumb": "Posts",
    "content": "A few month ago, the Paris Scala User Group kindly invited me present a workshop introducing [Scala.js(https://www.scala-js.org/). Even better, i had the chance to present it at ScalaIO 2018. The workshop materials are here.\nI will present how to develop a web application in Scala.js. This talk is for Scala developers having a penchant for web development but rebuffed by JavaScript. It goes from ScalaJS basics to the implementation of a naive virtual DOM written in Scala. It presents:\nhow to setup Sbt for cross compilation what is the DOM and how to manipulate it events and their propagation the Model/View/Update architecture (a.k.a the ELM architecture) The final result can be experimented with at slimetrail. The english material for the ScalaIO workshop are not yet available but the ones for the PSUG workshop, in french are here.\nThe Application",
    "description": "ScalaIO.2018 Workshop",
    "tags": [],
    "title": "How to make game in the browser thanks to ScalaJS",
    "uri": "/posts/slimetrail/index.html"
  },
  {
    "breadcrumb": "Posts",
    "content": "The complete code of the article. You need Cats and Play-Json in order to run it.\nThe Slides are here\nIt happens regularly in software development that we have to connect systems speaking different languages. JSON is nowadays ubiquitous in service communication, especially in web development but XML still has its fair amount of bastions. Imagine you need to pass information provided by a JSON API through an XML layer, you need a converter.\nThe easy way This translation is actually pretty trivial, it takes essentially 6 lines of simple pattern-matching code in Scala:\nimport play.api.libs.json._ import scala.xml._ def json2xml(json: JsValue, rootLabel: String): Elem = { // XML node creation helper def mkElem(jsType: String, children: Node*): Elem = Elem(null, rootLabel, new UnprefixedAttribute(\"type\", jsType, scala.xml.Null), TopScope, true, children: _* ) // The real translation json match { case JsNull =\u003e mkElem(\"null\") case JsString(s) =\u003e mkElem(\"string\", PCData(s)) case JsNumber(n) =\u003e mkElem(\"number\", Text(n.toString)) case JsBoolean(b) =\u003e mkElem(\"boolean\", Text(b.toString)) case JsArray(l) =\u003e mkElem(\"array\", l.map(json2xml(_, s\"${rootLabel}Item\")):_*) case JsObject(m) =\u003e mkElem(\"object\", m.toList.map { case (k,v) =\u003e json2xml(v, k) }: _*) } } The trickiest part of this example is figuring out how to build XML nodes in Scala. It translates the following JSON:\n[ { \"title\": \"2001 : A Space Odyssey\", \"release\": { \"day\": 27, \"month\": 9, \"year\": 1968 }, \"genres\" : [ \"Science fiction\" ], \"actors\": [ { \"lastName\": \"Dullea\", \"firstName\": \"Keir\", \"role\": \"Dr. David Bowman\" } ], \"directors\": [ { \"lastName\": \"Kubrick\", \"firstName\": \"Stanley\" } ] } ] into\n\u003cfilms type=\"array\"\u003e \u003cfilmsItem type=\"object\"\u003e \u003ctitle type=\"string\"\u003e\u003c![CDATA[2001 : A Space Odyssey]]\u003e\u003c/title\u003e \u003crelease type=\"object\"\u003e \u003cday type=\"number\"\u003e27\u003c/day\u003e \u003cmonth type=\"number\"\u003e9\u003c/month\u003e \u003cyear type=\"number\"\u003e1968\u003c/year\u003e \u003c/release\u003e \u003cgenres type=\"array\"\u003e \u003cgenresItem type=\"string\"\u003e\u003c![CDATA[Science fiction]]\u003e\u003c/genresItem\u003e \u003c/genres\u003e \u003cactors type=\"array\"\u003e \u003cactorsItem type=\"object\"\u003e \u003clastName type=\"string\"\u003e\u003c![CDATA[Dullea]]\u003e\u003c/lastName\u003e \u003cfirstName type=\"string\"\u003e\u003c![CDATA[Keir]]\u003e\u003c/firstName\u003e \u003crole type=\"string\"\u003e\u003c![CDATA[Dr. David Bowman]]\u003e\u003c/role\u003e \u003c/actorsItem\u003e \u003c/actors\u003e \u003cdirectors type=\"array\"\u003e \u003cdirectorsItem type=\"object\"\u003e \u003clastName type=\"string\"\u003e\u003c![CDATA[Kubrick]]\u003e\u003c/lastName\u003e \u003cfirstName type=\"string\"\u003e\u003c![CDATA[Stanley]]\u003e\u003c/firstName\u003e \u003c/directorsItem\u003e \u003c/directors\u003e \u003c/filmsItem\u003e \u003c/films\u003e Note that, unlike JSON, XML have no notion of booleans, number or null, so we add type information as attribute on each node. This has the benefit of enabling us to convert such XML back to their former JSON form. Also note that, we need CDATA sections to preserve spaces.\nProblem solved? Yes! But we can go much much further on this subject‚Ä¶\nThe Rocket Science way There much more thing to say about this example, first let‚Äôs expose some properties of JSON values.\nInviting (Co)Algebras to the Party JSON values can be modelled with an Algebraic Data Type or ADT for short. Play-Json represents them by the type JsValue:\nsealed abstract class JsValue final case object JsNull extends JsValue final case class JsNumber(value: BigDecimal) extends JsValue final case class JsBoolean(value: Boolean) extends JsValue final case class JsString(value: String) extends JsValue final case class JsArray(value: List[JsValue]) extends JsValue final case class JsObject(value: Map[String, JsValue]) extends JsValue But in order to simplify the presentation, we will use slightly different, but equivalent, definition of JSON values:\nsealed abstract class Atomic final case object Null extends Atomic final case class Bool(value: Boolean) extends Atomic final case class Number(value: BigDecimal) extends Atomic final case class Str(value: String) extends Atomic sealed abstract class JsValue final case class JsAtom(value: Atomic) extends JsValue final case class JsArray(value: List[JsValue]) extends JsValue final case class JsObject(value: Map[String, JsValue]) extends JsValue Like in any Algebraic Data Type, the constructors of JsValues can be seen as operations on it. JsAtom informs us that every number, boolean, string and null give rise to a distinct JSON value. JsArray and JsObject tells us that each (qualified) list of JSON values forms a distinct JSON value itself. Considering that JSON values are defined in terms of these operations, and that we want to translate JSON into XML, it would make sense to define them on XML as well. First, let‚Äôs explicit these operations:\nsealed abstract class JsLike[+R] final case class Atom(value: Atomic) extends JsLike[Nothing] final case class Arr[+R](value: List[R]) extends JsLike[R] final case class Obj[+R](value: Map[String, R]) extends JsLike[R] The interesting point here is we can translate back and forth between JsValue and JsLike[JsValue]. These translations are even the inverse of each other, meaning both types are totally equivalent!\nval jsLike2JsValue: JsLike[JsValue] =\u003e JsValue = { case Atom(a) =\u003e JsAtom(a) case Arr(a) =\u003e JsArray(a) case Obj(m) =\u003e JsObject(m) } val jsValue2JsLike: JsValue =\u003e JsLike[JsValue] = { case JsAtom(a) =\u003e Atom(a) case JsArray(a) =\u003e Arr(a.toList) case JsObject(m) =\u003e Obj(m) } jsLike2JsValue is called a JsLike-Algebra because it has the form JsLike[X] =\u003e X. It means jsLike2JsValue is a way ‚Äúcompute‚Äù JsLike operation, i.e. it composes values to form new ones. On the opposite, jsValue2JsLike is called a JsLike-CoAlgebra because it has the form X =\u003e JsLike[X]. It is a way to expose how a value is built, i.e. it deconstructs values to expose their structure.\nCan we find such functions for XML values? We are looking for two functions:\nval jsLike2Elem: JsLike[Elem] =\u003e Elem = ??? val elem2JsLike: Elem =\u003e JsLike[Elem] = ??? It would certainly be nice, but unfortunately this is not that simple! 5, true and null are valid JSON values, So jsLike2Elem(Atom(Number(5))), jsLike2Elem(Atom(Bool(true))) and jsLike2Elem(Atom(Null))) should be valid XML value! But what should be the root tag of the resulting elements? How to translate 5 into a valid XML? We know that it would have the form:\n\u003csomeRootTag type=\"number\"\u003e5\u003c/someRootTag\u003e But what someRootTag should be? We could pick an arbitrary one, but it would break composability (try it, you‚Äôll see!). There‚Äôs no escape, all XML values need tags but not every JSON value have some! The situation suggest JSON values are closer to ‚ÄúXML values with unknown root tags‚Äù \u003cX type=\"number\"\u003e5\u003c/X\u003e where X as the unknown, i.e. the functional space String =\u003e Elem:\nval _5: String =\u003e Elem = (someRootTag: String) =\u003e \u003csomeRootTag type=\"number\"\u003e5\u003c/someRootTag\u003e Do you think we can define meaningful functions?\nval jsLike2xml: JsLike[String =\u003e Elem] =\u003e (String =\u003e Elem) = ??? val xml2JsLike: (String =\u003e Elem) =\u003e JsLike[String =\u003e Elem] = ??? Yes we can ‚Ä¶ partially. We can define jsLike2xml:\nval jsLike2xml: JsLike[String =\u003e Elem] =\u003e (String =\u003e Elem) = { def mkRoot(jsType: String, children: Node*): String =\u003e Elem = (someRootTag: String) =\u003e Elem(null, someRootTag, new UnprefixedAttribute(\"type\", jsType, scala.xml.Null), TopScope, true, children: _* ) (j: JsLike[String =\u003e Elem]) =\u003e j match { case Atom(Null) =\u003e mkRoot(\"null\") case Atom(Str(s)) =\u003e mkRoot(\"string\", PCData(s)) case Atom(Bool(b)) =\u003e mkRoot(\"boolean\", Text(b.toString)) case Atom(Number(n)) =\u003e mkRoot(\"number\", Text(n.toString)) case Arr(a) =\u003e (root: String) =\u003e { mkRoot(\"array\", a.map(_(s\"${root}Item\")): _*)(root) } case Obj(m) =\u003e mkRoot(\"object\", m.toList.map { case (k, v) =\u003e v(k) }: _*) } } but for xml2JsLike, we‚Äôre facing two not-that-small issues:\nFirst, unlikejsValue2JsLike, we can not pattern-match on functions. We have no sane way to know that\n(someRootTag: String) =\u003e \u003csomeRootTag type=\"number\"\u003e5\u003c/someRootTag\u003e is built from Atom(Number(5)).\nEven if we could pattern-match on functions, jsLike2xml is not surjective, i.e. not every XML element is the result of jsLike2xml(f) for some f. To deal with invalid input, the return type of xml2JsLike can not be JsLike[String =\u003e Elem] but F[JsLike[String =\u003e Elem]] for some functor F able to deal with errors like Option, Either, etc. For simplicity‚Äôs sake, let‚Äôs consider F to be Option.\nLet‚Äôs once again take a step back. We want to decompose a function (f: String =\u003e Elem) into an Option[JsLike[String =\u003e Elem]] without pattern-matching it. The only reasonable thing we can do with functions is pass them some arguments:\ndef xml2JsLike(f: (String =\u003e Elem)): String =\u003e Option[JsLike[Elem =\u003e String]] = (someRootTag: String) =\u003e ... f(someRootTag) ... The type String =\u003e Option[A] is actually a monad, known as a ReaderT[Option, String, A]. Which makes xml2JsLike a monadic coalgebra. Let‚Äôs give it a name:\nimport cats.data.ReaderT type TagOpt[A] = ReaderT[Option, String, A] As an exercise try to implement xml2JsLike. *To that end, it may be useful to notice that JsLike is a Traverse, i.e. that an instance of Traverse[JsLike] can be defined. Such an instance defines a function:\ndef `traverse[G[_]: Applicative, A, B](ja: JsLike[A])(f: A =\u003e G[B]): G[JsLike[B]]` To summarize this part, we have these four functions:\nval jsLike2JsValue: JsLike[JsValue] =\u003e JsValue val jsValue2JsLike: JsValue =\u003e JsLike[JsValue] val jsLike2xml: JsLike[String =\u003e Elem] =\u003e (String =\u003e Elem) val xml2JsLike: (String =\u003e Elem) =\u003e TagOpt[JsLike[String =\u003e Elem]] Now we want to convert JsValue from/into String =\u003e Elem.\nConverting back and forth Now that we know how to compose and decompose both JSON and XML values. How do we write converters? For simplify‚Äôs sake, let‚Äôs be a bit more abstract. Let A and B be to types (like JsValue and String =\u003e Elem) and F[_] a type constructor (like JsLike) that have the nice property of being a functor (i.e. it has function map: F[A] =\u003e (A =\u003e B) =\u003e F[B]). In addition, let decomposeA: A =\u003e F[A] and recomposeB: F[B] =\u003e B (like jsValue2JsLike and jsLike2xml). We want a function convert: A =\u003e B:\ntrait Direct { import cats.Functor import cats.syntax.functor._ type A type B type F[_] implicit val fHasMap: Functor[F] val decomposeA: A =\u003e F[A] val recomposeB: F[B] =\u003e B final def convert(a: A): B = { val fa: F[A] = decomposeA(a) val fb: F[B] = fa.map(convert) recomposeB(fb): B } } Or in a more compact way:\ndef hylo[A,B, F[_]: Functor](decompose: A =\u003e F[A], recompose: F[B] =\u003e B): A =\u003e B = { def convert(a: A): B = recompose(decompose(a).map(convert)) convert _ } And voila, a converter in just 1 lines of code:\ndef json2xml(json: JsValue): String =\u003e Elem = hylo(jsValue2JsLike, jsLike2xml).apply(json) The way back is only a bit more involving. This time we require F to be Traverse and the function decomposeA to be of type A =\u003e M[F[A]] for some monad M:\ntrait WayBack { type A type B type F[_] implicit val fHasTraverse: Traverse[F] type M[_] implicit val mIsAMonad: Monad[M] val decomposeA: A =\u003e M[F[A]] val recomposeB: F[B] =\u003e B final def convert(a: A): M[B] = for { fa \u003c- decomposeA(a) fb \u003c- fa.traverse(convert) } yield recomposeB(fb) } Again, in a more compact way:\ndef hyloish[A,B, F[_]: Traverse, M[_]: Monad](decompose: A =\u003e M[F[A]], recompose: F[B] =\u003e B): A =\u003e M[B] = { def convert(a: A): M[B] = for { fa \u003c- decompose(a) fb \u003c- fa.traverse(convert) } yield recompose(fb) convert _ } which gives the way back as the oneliner:\ndef xml2json(f: String =\u003e Elem): TagOpt[JsValue] = hyloish(xml2JsLike, jsLike2JsValue).apply(f) Reorganizing a bit, it leads to the two conversion functions between (String, JsValue) and Elem:\nval json2xmlBetter: ((String, JsValue)) =\u003e Elem = (jsonPlusTag: (String, JsValue)) =\u003e json2xml(jsonPlusTag._2)(jsonPlusTag._1) val xml2jsonBetter: Elem =\u003e TagOpt[(String, JsValue)] = (e: Elem) =\u003e xml2json((s: String) =\u003e e.copy(label = s)).map(e.label -\u003e _) What‚Äôs the point? Apart from being so much more complicated that the trivial approach, is there some benefits? Actually yes.\nFirstly, given n formats, there are n¬≤ converters. Writing and testing n¬≤ functions is a lot of tedious and error-prone work. But if you find some common operations F[_], you only need 2n functions (one X =\u003e F[X] and one F[X] =\u003e X for each format X) to achieve the same goal. Furthermore, each of those functions will be easier to test, which is not to neglect. Secondly, algebras (functions X =\u003e F[X]) and coalgebras (functions F[X] =\u003e X) operate one level at a time. They enable to treat format X as if it was an algebraic data type over operations F. Pattern-matching is such a nice feature! Thirdly, you can write generic functions taking any type X for which you can provide functions X =\u003e F[X] and F[X] =\u003e X. These functions also have higher chances of being correct because there is less space for unexpected behaviour. If want to dive deeper in this subject, you can look at Matryoshka, read Functional programming with bananas, lenses, envelopes and barbed wire or any resource on F-Algebras and recursion schemes.\nSolution to exercises JsLike instance for Traverse implicit val jsLikeInstances: Traverse[JsLike] = new Traverse[JsLike] { import cats.Eval def traverse[G[_], A, B](fa: JsLike[A])(f: A =\u003e G[B])( implicit G: Applicative[G]): G[JsLike[B]] = fa match { case Atom(a) =\u003e G.point(Atom(a)) case Arr(a) =\u003e a.traverse[G, B](f).map(Arr(_)) case Obj(m) =\u003e m.toList .traverse[G, (String, B)] { case (s, a) =\u003e f(a).map(s -\u003e _) } .map(i =\u003e Obj(i.toMap)) } def foldLeft[A, B](fa: JsLike[A], b: B)(f: (B, A) =\u003e B): B = fa match { case Atom(_) =\u003e b case Arr(a) =\u003e a.foldLeft(b)(f) case Obj(m) =\u003e m.values.foldLeft(b)(f) } def foldRight[A, B](fa: JsLike[A], lb: Eval[B])( f: (A, Eval[B]) =\u003e Eval[B]): Eval[B] = fa match { case Atom(_) =\u003e lb case Arr(a) =\u003e a.foldRight(lb)(f) case Obj(m) =\u003e m.values.foldRight(lb)(f) } } xml2JsLike def xml2JsLike(f: String =\u003e Elem): TagOpt[JsLike[String =\u003e Elem]] = ReaderT[Option, String, JsLike[String =\u003e Elem]] { (s: String) =\u003e val elem: Elem = f(s) elem .attributes .asAttrMap .get(\"type\") .flatMap[JsLike[String =\u003e Elem]] { case \"null\" =\u003e Some(Atom(Null)) case \"boolean\" =\u003e elem.text match { case \"true\" =\u003e Some(Atom(Bool(true))) case \"false\" =\u003e Some(Atom(Bool(false))) case _ =\u003e None } case \"number\" =\u003e import scala.util.Try Try(BigDecimal(elem.text)) .toOption .map(n =\u003e Atom(Number(n))) case \"string\" =\u003e Some(Atom(Str(elem.text))) case \"array\" =\u003e Some(Arr( elem .child .toList .flatMap { case e: Elem =\u003e List((s: String) =\u003e e.copy(label = s)) case _ =\u003e Nil } )) case \"object\" =\u003e Some(Obj( elem .child .toList .flatMap { case e: Elem =\u003e List(e.label -\u003e ((s: String) =\u003e e.copy(label = s))) case _ =\u003e Nil }.toMap )) case _ =\u003e None } }",
    "description": "Conversion from/to JSON and XML using advanced concepts",
    "tags": [],
    "title": "JSON to XML: the probably a tiny bit over engineered way",
    "uri": "/posts/json2xml/index.html"
  },
  {
    "breadcrumb": "Posts",
    "content": "I had the chance to present a talk about F-Algebras at ScalaIO 2017.\nThe Video The Slides",
    "description": "ScalaIO.2017 Talk",
    "tags": [],
    "title": "F-Algebra talk at ScalaIO 2017: Mod√©liser astucieusement vos donn√©es",
    "uri": "/posts/falgebra_scalaio_2017/index.html"
  },
  {
    "breadcrumb": "",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Categories",
    "uri": "/categories/index.html"
  },
  {
    "breadcrumb": "",
    "content": "",
    "description": "",
    "tags": [],
    "title": "frontmatter",
    "uri": "/frontmatter/index.html"
  },
  {
    "breadcrumb": "",
    "content": "",
    "description": "",
    "tags": [],
    "title": "options",
    "uri": "/options/index.html"
  },
  {
    "breadcrumb": "",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tags",
    "uri": "/tags/index.html"
  }
]
